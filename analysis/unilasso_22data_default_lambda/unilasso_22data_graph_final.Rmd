
# Final version for 22 datasets 
```{r}
### setup####

if (R.home() != "/scratch/users/aqwang/conda/envs/r_package/lib/R") {
  system("/scratch/users/aqwang/conda/envs/r_package/bin/Rscript -e 'rmarkdown::render(\"unilasso_22data_graph_final.Rmd\")'")
  quit("no")
}

# check the R environment is r_package
R.home()

# set working directory
setwd("/accounts/grad/aqwang/unilasso/analysis/unilasso_22data_default_lambda")

# load packages 
library(uniLasso) # for unilasso 
library(glmnet) # for cv lasso 
library(dplyr)
library(tidyr)



####################load results: comparing LS, uniReg, unilasso (loo=True) and polish unilasso with loo=TRUE with 50-50 train/test splits updated for 22 datasets (choose one target for datasets with multiple targets )####################
results_all_splits <- read.csv("/accounts/grad/aqwang/unilasso/analysis/unilasso_22data_default_lambda/unilasso_22datasets_100splits_train50percent_results.csv")

# print the unique names in results_all_splits$dataset to verify
print(unique(results_all_splits$dataset))


# using results_all_splits data frame to graph boxplot of MSE on the left and boxplot of support on the right for each dataset 
library(ggplot2)
library(tidyr)
library(dplyr)

# Reshape data for plotting
plot_long <- results_all_splits %>%
  select(dataset, unilasso_loo_true_mse, polish_unilasso_mse, lasso_cv_mse, unireg_mse, least_squares_mse,
         unilasso_loo_true_support, polish_unilasso_support, lasso_cv_support,unireg_support, least_squares_support,
         unilasso_loo_true_sign_diff, polish_unilasso_sign_diff,lasso_cv_sign_diff,unireg_sign_diff, least_squares_sign_diff) %>%
  pivot_longer(
    cols = c(unilasso_loo_true_mse, polish_unilasso_mse, lasso_cv_mse, unireg_mse, least_squares_mse,
             unilasso_loo_true_support, polish_unilasso_support, lasso_cv_support, unireg_support, least_squares_support,
             unilasso_loo_true_sign_diff, polish_unilasso_sign_diff, lasso_cv_sign_diff, unireg_sign_diff, least_squares_sign_diff),
    names_to = c("method", ".value"),
    names_pattern = "(unilasso_loo_true|polish_unilasso|lasso_cv|unireg|least_squares)_(mse|support|sign_diff)"
  )

# Order datasets for consistent facetting
plot_long$dataset <- factor(plot_long$dataset, levels = sort(unique(plot_long$dataset)))
# rename unilasso_loo_true to unilasso
plot_long$method <- recode(plot_long$method, unilasso_loo_true = "uniLasso", polish_unilasso = "Polish", lasso_cv = "Lasso", unireg = "uniReg", least_squares = "LS")
plot_long$method <- factor(plot_long$method, levels = c("LS", "Lasso", "uniReg", "uniLasso", "Polish"))


dataset_names <- c(
  "airfoil", "appliances_energy", "auto_mpg", "automobile", "beijing_pm2.5",
  "bike_sharing", "concrete", "crime", "crime_unnormalized", "daily_demand", "facebook_metrics", "forest_fires", "infrared_thermo_temp",
   "liver_disorders", "metro_traffic", "parkinsons", "power_consumption", "power_plant", "real_estate",
  "servo", "stock_portfolio", "superconductivity")

# rename all daasets to have first letter capitalized and underscores replaced with spaces
plot_long$dataset <- recode(plot_long$dataset,
                            "airfoil" = "Airfoil",
                            "appliances_energy" = "Appliances energy",
                            "auto_mpg" = "Auto MPG",
                            "automobile" = "Automobile",
                            "beijing_pm2.5" = "Beijing PM2.5",
                            "bike_sharing" = "Bike sharing",
                            "concrete" = "Concrete",
                            "crime" = "Crime",
                            "crime_unnormalized" = "Crime unnormalized",
                            "daily_demand" = "Daily demand",
                            "facebook_metrics" = "Facebook metrics",
                            "forest_fires" = "Forest fires",
                            "infrared_thermo_temp" = "Infrared thermo temp",
                            "liver_disorders" = "Liver disorders",
                            "metro_traffic" = "Metro traffic",
                            "parkinsons" = "Parkinsons",
                            "power_consumption" = "Power consumption",
                            "power_plant" = "Power plant",
                            "real_estate" = "Real estate",
                            "servo" = "Servo",
                            "stock_portfolio" = "Stock portfolio",
                            "superconductivity" = "Superconductivity"
)

plot_combined_long <- plot_long %>%
  pivot_longer(
    cols = c(mse, support, sign_diff),
    names_to = "metric",
    values_to = "value"
  ) %>%
  mutate(
    metric = recode(metric, 
                   "mse" = "MSE", 
                   "support" = "Support",
                   "sign_diff" = "Number of violations"),
    metric = factor(metric, levels = c("MSE", "Support", "Number of violations"))
  )

######################################2)calculate stabilty using all coeffcients 
library(dplyr)
library(utils)  # for combn function

# Function to calculate stability for a given method - returns all pairwise values
calculate_stability_full <- function(data, method_name) {
  # Filter data for the specific method
  method_data <- data %>% filter(method == method_name)
  
  # Extract coefficient columns (starting from column 4)
  coef_matrix <- as.matrix(method_data[, 4:ncol(method_data)])
  
  # Number of models for this method
  n_models <- nrow(coef_matrix)
  
  if (n_models < 2) {
    return(c())  # Return empty vector if not enough models
  }
  
  # Generate all pairs of models (100 choose 2)
  model_pairs <- combn(1:n_models, 2, simplify = FALSE)
  
  # Calculate stability for each pair
  stability_values <- sapply(model_pairs, function(pair) {
    model_i <- pair[1]
    model_j <- pair[2]
    
    # Find selected features (non-zero coefficients) for each model. returns the indices (column numbers) where the coefficients are nonzero.
    features_i <- which(coef_matrix[model_i, ] != 0)
    features_j <- which(coef_matrix[model_j, ] != 0)
    
    # Calculate Jaccard similarity: |intersection| / |union|
    common_features <- length(intersect(features_i, features_j))
    total_unique_features <- length(union(features_i, features_j))
    
    # Handle case where both models select no features
    if (total_unique_features == 0) {
      return(1)  # Perfect stability if both select nothing
    } else {
      return(common_features / total_unique_features)
    }
  })
  
  # Return the entire vector of stability values
  return(stability_values)
}

# Get all CSV files in the coef_csv directory
coef_csv_dir <- "/accounts/grad/aqwang/unilasso/analysis/unilasso_22data_default_lambda/coef_csv_22data"
csv_files <- list.files(coef_csv_dir, pattern = "coefficients_.*\\.csv$", full.names = TRUE)

# check dataset names from file names
dataset_names <- gsub("coefficients_(.+)\\.csv", "\\1", basename(csv_files))
print(dataset_names)  # Verify dataset names

# Initialize storage for all results
all_stability_results <- data.frame(
  dataset = character(),
  method = character(),
  mean_stability = numeric(),
  sd_stability = numeric(),
  min_stability = numeric(),
  max_stability = numeric(),
  n_pairs = integer(),
  stringsAsFactors = FALSE
)

# Initialize storage for detailed results (optional - if you want all pairwise values)
all_stability_detailed <- list()

# Loop through all datasets
for (i in seq_along(csv_files)) {
  dataset_name <- dataset_names[i]
  csv_file <- csv_files[i]
  
  cat("\n", strrep("=", 60), "\n")
  cat("Processing dataset:", dataset_name, "(", i, "/", length(csv_files), ")\n")
  cat(strrep("=", 60), "\n")
  
  # Read coefficient data
  tryCatch({
    coefficients_data <- read.csv(csv_file)
    # Remove rows with method=unilasso_loo_false
    coefficients_data <- coefficients_data[coefficients_data$method != "unilasso_loo_false", ]
    coefficients_data <- coefficients_data[coefficients_data$method != "uni_loo", ]
    
    # Get unique methods in this dataset
    unique_methods <- unique(coefficients_data$method)
    cat("Found methods:", paste(unique_methods, collapse = ", "), "\n")
    
    # Calculate stability for each method in this dataset
    dataset_stability_detailed <- list()
    
    for (method in unique_methods) {
      cat("  Processing method:", method, "...")
      
      # Calculate full stability vector for this method
      stability_vector <- calculate_stability_full(coefficients_data, method)
      
      if (length(stability_vector) > 0) {
        # Clean method name
        clean_method <- recode(method,
          "unilasso_loo_true" = "uniLasso",
          "polish_unilasso" = "Polish",
          "lasso_cv" = "Lasso",
          "unireg" = "uniReg", 
          "least_squares" = "LS"
        )
        
        # Calculate summary statistics
        summary_stats <- data.frame(
          dataset = dataset_name,
          method = clean_method,
          mean_stability = mean(stability_vector, na.rm = TRUE),
          sd_stability = sd(stability_vector, na.rm = TRUE),
          min_stability = min(stability_vector, na.rm = TRUE),
          max_stability = max(stability_vector, na.rm = TRUE),
          n_pairs = length(stability_vector),
          stringsAsFactors = FALSE
        )
        
        # Add to main results dataframe
        all_stability_results <- rbind(all_stability_results, summary_stats)
        
        # Store detailed results (optional)
        dataset_stability_detailed[[clean_method]] <- stability_vector
        
        cat(" Done (", length(stability_vector), " pairs)\n")
        
      } else {
        cat(" Skipped (insufficient data)\n")
      }
    }
    
    # Store detailed results for this dataset
    all_stability_detailed[[dataset_name]] <- dataset_stability_detailed
    
    # Print summary for this dataset
    dataset_results <- all_stability_results[all_stability_results$dataset == dataset_name, ]
    if (nrow(dataset_results) > 0) {
      cat("\nSummary for", dataset_name, ":\n")
      for (j in 1:nrow(dataset_results)) {
        row <- dataset_results[j, ]
        cat(sprintf("  %-10s: Mean = %.3f (SD = %.3f) Range = [%.3f, %.3f] [%d pairs]\n",
                    row$method, row$mean_stability, row$sd_stability,
                    row$min_stability, row$max_stability, row$n_pairs))
      }
    }
    
  }, error = function(e) {
    cat("ERROR processing", dataset_name, ":", e$message, "\n")
  })
}

# Final summary
cat("\n", strrep("=", 80), "\n")
cat("STABILITY ANALYSIS COMPLETE!\n")
cat("Total datasets processed:", length(unique(all_stability_results$dataset)), "\n")
cat("Total method-dataset combinations:", nrow(all_stability_results), "\n")
cat(strrep("=", 80), "\n")

# Display overall results
print(all_stability_results)

# Save results
write.csv(all_stability_results, "stability_across100ransplits_22_data_summary.csv", row.names = FALSE)
save(all_stability_results, all_stability_detailed, file = "stability_across100ransplits_22_data_summary.RData")


################# prepare stability data #################
library(ggplot2)

# Build one long data.frame: dataset, method, stability
make_long <- function(all_stability_detailed) {
  do.call(rbind, lapply(names(all_stability_detailed), function(ds) {
    methods <- all_stability_detailed[[ds]]
    if (length(methods) == 0) return(NULL)
    do.call(rbind, lapply(names(methods), function(m) {
      v <- methods[[m]]
      v <- v[is.finite(v)]                 # drop NA/Inf if present
      if (length(v) == 0) return(NULL)
      data.frame(dataset = ds, method = m, stability = v, 
                 stringsAsFactors = FALSE)
    }))
  }))
}

plot_data <- make_long(all_stability_detailed)

plot_data$dataset <- factor(plot_data$dataset, levels = sort(unique(plot_data$dataset)))
#rename all datasets to have first letter capitalized and underscores replaced with spaces
plot_data$dataset <- recode(plot_data$dataset,
                            "airfoil" = "Airfoil",
                            "appliances_energy" = "Appliances energy",
                            "auto_mpg" = "Auto MPG",
                            "automobile" = "Automobile",
                            "beijing_pm2.5" = "Beijing PM2.5",
                            "bike_sharing" = "Bike sharing",
                            "concrete" = "Concrete",
                            "crime" = "Crime",
                            "crime_unnormalized" = "Crime unnormalized",
                            "daily_demand" = "Daily demand",
                            "facebook_metrics" = "Facebook metrics",
                            "forest_fires" = "Forest fires",
                            "infrared_thermo_temp" = "Infrared thermo temp",
                            "liver_disorders" = "Liver disorders",
                            "metro_traffic" = "Metro traffic",
                            "parkinsons" = "Parkinsons",
                            "power_consumption" = "Power consumption",
                            "power_plant" = "Power plant",
                            "real_estate" = "Real estate",
                            "servo" = "Servo",
                            "stock_portfolio" = "Stock portfolio",
                            "superconductivity" = "Superconductivity"
)

# Use similar colors for Polish, uniLasso, and uniReg
method_colors <- c(
  "uniLasso" = "#e75480",      # medium pink
  "Polish" = "#f7b6d2",        # light pink
  "uniReg" = "#c71585",        # dark pink/magenta
  "Lasso" = "#1f77b4",      # medium blue
  "LS" = "#aec7e8"           # light blue
)


########################(3) combine stability with mse, support, sign_diff########################
library(ggh4x)

stability_data_formatted <- plot_data %>%
  rename(value = stability) %>%
  mutate(metric = "Stability") %>%
  select(dataset, method, metric, value)

# Combine all four metrics into one dataset
plot_combined_long_with_stability <- bind_rows(
  plot_combined_long,  # This has MSE, Support, and Number of violations
  stability_data_formatted  # This adds Stability
) %>%
  mutate(
    metric = factor(metric, levels = c("MSE", "Support", "Number of violations", "Stability"))
  ) %>%
  mutate(
    method = factor(method, levels = c("LS", "Lasso", "uniReg", "uniLasso", "Polish"))
  ) 


# Choose first 8datasets (now with stability included)
plot_combined_long1_with_stability <- plot_combined_long_with_stability %>%
  filter(dataset %in% c("Airfoil", "Appliances energy", "Auto MPG", "Automobile", "Beijing PM2.5", "Bike sharing", "Concrete", "Crime"))
# Choose next 8 datasets (now with stability included)
plot_combined_long2_with_stability <- plot_combined_long_with_stability %>%
  filter(dataset %in% c("Crime unnormalized", "Daily demand", "Facebook metrics", "Forest fires", "Infrared thermo temp", "Liver disorders", "Metro traffic", "Parkinsons"))
# Choose last 6 datasets (now with stability included)
plot_combined_long3_with_stability <- plot_combined_long_with_stability %>%
  filter(dataset %in% c("Power consumption", "Power plant", "Real estate", "Servo", "Stock portfolio", "Superconductivity"))


# Create the enhanced plot with 4 columns (MSE, Support, Number of violations, Stability)
p_combined_facet1_with_stability <- ggplot(plot_combined_long1_with_stability, aes(x = method, y = value, fill = method)) +
  geom_boxplot() +
  facet_grid2(
    dataset ~ metric,
    switch = "y",
    scales = "free_y",     # <-- make y free
    independent = "y"      # <-- now each dataset×metric panel gets its own y-scale
  ) +
  labs(x = "Method", y = NULL, fill = "Method") +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 18, family = "Times New Roman", face = "bold"),
    axis.text.y = element_text(size = 16, family = "Times New Roman", face = "bold"),  # ADD THIS LINE
    axis.title = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.position = "bottom",
    legend.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.title = element_text(size = 20, family = "Times New  Roman", face = "bold"),
    strip.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    strip.placement = "outside",
    panel.spacing.y = unit(0.7, "cm")  # Increase vertical spacing between rows
  )
print(p_combined_facet1_with_stability)
# Save the enhanced plot
ggsave("/accounts/grad/aqwang/unilasso/figures_22data_default_lambda/appendix_22data_4metrics1.png", 
       plot = p_combined_facet1_with_stability, width = 18, height = 26, dpi = 300)

# Do the same for the second set of datasets
p_combined_facet2_with_stability <- ggplot(plot_combined_long2_with_stability, aes(x = method, y = value, fill = method)) +
  geom_boxplot() +
  facet_grid2(
    dataset ~ metric,
    switch = "y",
    scales = "free_y",     # <-- make y free
    independent = "y"      # <-- now each dataset×metric panel gets its own y-scale
  ) +
  labs(x = "Method", y = NULL, fill = "Method") +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 18, family = "Times New Roman", face = "bold"),
    axis.text.y = element_text(size = 16, family = "Times New Roman", face = "bold"),  # ADD THIS LINE
    axis.title = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.position = "bottom",
    legend.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.title = element_text(size = 20, family = "Times New  Roman", face = "bold"),
    strip.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    strip.placement = "outside",
    panel.spacing.y = unit(0.7, "cm")  # Increase vertical spacing between rows
  )
print(p_combined_facet2_with_stability)
# Save the enhanced plot
ggsave("/accounts/grad/aqwang/unilasso/figures_22data_default_lambda/appendix_22data_4metrics2.png", 
       plot = p_combined_facet2_with_stability, width = 18, height = 26, dpi = 300)

# Do the same for the third set of datasets
p_combined_facet3_with_stability <- ggplot(plot_combined_long3_with_stability, aes(x = method, y = value, fill = method)) +
  geom_boxplot() +
  facet_grid2(
    dataset ~ metric,
    switch = "y",
    scales = "free_y",     # <-- make y free
    independent = "y"      # <-- now each dataset×metric panel gets its own y-scale
  ) +
  labs(x = "Method", y = NULL, fill = "Method") +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 18, family = "Times New Roman", face = "bold"),
    axis.text.y = element_text(size = 16, family = "Times New Roman", face = "bold"),  # ADD THIS LINE
    axis.title = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.position = "bottom",
    legend.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.title = element_text(size = 20, family = "Times New  Roman", face = "bold"),
    strip.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    strip.placement = "outside",
    panel.spacing.y = unit(0.7, "cm")  # Increase vertical spacing between rows
  )
print(p_combined_facet3_with_stability)
# Save the enhanced plot
ggsave("/accounts/grad/aqwang/unilasso/figures_22data_default_lambda/appendix_22data_4metrics3.png", 
       plot = p_combined_facet3_with_stability, width = 18, height = 20, dpi = 300)
```



# final version: updated bootstrap results with uniReg for 22 datasets 9/16 Tuesday
```{r load updated bootstrap results and make some plots}
boot_results <- read.csv("/accounts/grad/aqwang/unilasso/analysis/unilasso_22data_default_lambda/unilasso_22datasets_100bootstrap_train50percent.csv")

# rename dataset names to match previous naming convention
boot_results$dataset <- recode(boot_results$dataset,
                            "airfoil" = "Airfoil",
                            "appliances_energy" = "Appliances energy",
                            "auto_mpg" = "Auto MPG",
                            "automobile" = "Automobile",
                            "beijing_pm2.5" = "Beijing PM2.5",
                            "bike_sharing" = "Bike sharing",
                            "concrete" = "Concrete",
                            "crime" = "Crime",
                            "crime_unnormalized" = "Crime unnormalized",
                            "daily_demand" = "Daily demand",
                            "facebook_metrics" = "Facebook metrics",
                            "forest_fires" = "Forest fires",
                            "infrared_thermo_temp" = "Infrared thermo temp",
                            "liver_disorders" = "Liver disorders",
                            "metro_traffic" = "Metro traffic",
                            "parkinsons" = "Parkinsons",
                            "power_consumption" = "Power consumption",
                            "power_plant" = "Power plant",
                            "real_estate" = "Real estate",
                            "servo" = "Servo",
                            "stock_portfolio" = "Stock portfolio",
                            "superconductivity" = "Superconductivity" )


# print the unique names in results_all_splits$dataset to verify
print(unique(boot_results$dataset))

# calculate the support size mean and sd for each dataset and method
library(dplyr)
summary_boot_MSE <- boot_results %>%
  group_by(dataset) %>%
  summarise(
    # MSE statistics
    unilasso_loo_true_mean_mse = mean(unilasso_loo_true_mse, na.rm = TRUE),
    unilasso_loo_true_sd_mse = sd(unilasso_loo_true_mse, na.rm = TRUE),
    unilasso_loo_false_mean_mse = mean(unilasso_loo_false_mse, na.rm = TRUE),
    unilasso_loo_false_sd_mse = sd(unilasso_loo_false_mse, na.rm = TRUE),
    polish_unilasso_mean_mse = mean(polish_unilasso_mse, na.rm = TRUE),
    polish_unilasso_sd_mse = sd(polish_unilasso_mse, na.rm = TRUE),
    lasso_cv_mean_mse = mean(lasso_cv_mse, na.rm = TRUE),
    lasso_cv_sd_mse = sd(lasso_cv_mse, na.rm = TRUE),
    unireg_mean_mse = mean(unireg_mse, na.rm = TRUE),
    unireg_sd_mse = sd(unireg_mse, na.rm = TRUE),
    least_squares_mean_mse = mean(least_squares_mse, na.rm = TRUE),
    least_squares_sd_mse = sd(least_squares_mse, na.rm = TRUE),
    .groups = 'drop' )

#drop unilasso_loo_false method from the summary_boot_MSE
summary_boot_MSE <- summary_boot_MSE %>%
  select(-c(unilasso_loo_false_mean_mse, unilasso_loo_false_sd_mse))

library(ggplot2)
library(tidyr)
library(dplyr)

# 1. MSE Plot with Error Bars
# Create a single pivot that handles both mean and SD columns together
plot_mse_data <- summary_boot_MSE %>%
  pivot_longer( 
    cols = c(unilasso_loo_true_mean_mse, 
             polish_unilasso_mean_mse, lasso_cv_mean_mse,
             unireg_mean_mse, least_squares_mean_mse,
             unilasso_loo_true_sd_mse, 
             polish_unilasso_sd_mse, lasso_cv_sd_mse,
             unireg_sd_mse, least_squares_sd_mse),
    names_to = c("method", "statistic"),
    values_to = "value",
    names_pattern = "(.*)_(mean_mse|sd_mse)"
  ) %>%
  # Pivot wider to get mean_mse and sd_mse as separate columns
  pivot_wider(
    names_from = statistic,
    values_from = value
  ) %>%
  # Keep mean_mse and sd_mse as numeric for plotting
  # Clean up method names
  mutate(method = recode(method,
                        "unilasso_loo_true" = "uniLasso",
                        "polish_unilasso" = "Polish",
                        "lasso_cv" = "Lasso",
                        "unireg" = "uniReg",
                        "least_squares" = "LS"))

# Build labels: 1 decimal; if >100 use scientific with 1 sig decimal; if <0.1 use 4 decimals
plot_mse_data2 <- plot_mse_data %>%
  mutate(
    mean_label = case_when(
      mean_mse < 0.1 ~ formatC(mean_mse, format = "e", digits = 2),
      mean_mse > 100 ~ formatC(mean_mse, format = "e", digits = 2),
      TRUE ~ sprintf("%.1f", mean_mse)
    ),
    sd_label = case_when(
      sd_mse < 0.1 ~ formatC(sd_mse, format = "e", digits = 2),
      sd_mse > 100 ~ formatC(sd_mse, format = "e", digits = 2),
      TRUE ~ sprintf("%.1f", sd_mse)
    ),
    label_text = paste0(mean_label, " ± ", sd_label)
  )


plot_mse_data2$method <- factor(plot_mse_data2$method, levels = c("LS", "Lasso", "uniReg", "uniLasso", "Polish"))


method_colors <- c(
  "uniLasso" = "#e75480",      # medium pink
  "Polish" = "#f7b6d2",        # light pink
  "uniReg" = "#c71585",        # dark pink/magenta
  "Lasso" = "#1f77b4",      # medium blue
  "LS" = "#aec7e8"           # light blue
)


p_mse_error <- ggplot(plot_mse_data2, aes(x = method, y = mean_mse, fill = method)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.8, alpha = 0.7) +  # wider bars
  geom_errorbar(aes(ymin = mean_mse - sd_mse, ymax = mean_mse + sd_mse),
                position = position_dodge(width = 0.6),
                width = 0.25, alpha = 0.8) +
  # Label means on top of bars, tilted 45 degrees
  geom_text(aes(label = label_text),
            position = position_dodge(width = 1),
            vjust = -2, size = 3.3, angle = 75, hjust = 0, family = "Times New Roman") +
  # Facet with per-facet axes
  ggh4x::facet_wrap2(
    ~ dataset,
    nrow = ceiling(length(unique(plot_mse_data$dataset))/5),
    ncol = 5,
    scales = "free_y",
    axes = "x"
  ) +
  labs(
    #title = "Mean MSE with Standard Deviation Bars (100 Bootstrap Results)",
    x = "Method",
    y = "Mean MSE",
    fill = "Method"
  ) +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 14, family = "Times New Roman", face="bold"),  # increase tick label font size
    axis.text.y = element_text(size = 16, family = "Times New Roman", face = "bold"),  # ADD THIS LINE
    axis.title.x = element_text(size = 18, family = "Times New Roman", face="bold"),  # x-axis title font size
    axis.title.y = element_text(size = 18, family = "Times New Roman", face="bold"),  # y-axis title font size
    legend.position = "bottom",
    legend.text = element_text(size = 18, family = "Times New Roman", face="bold"),
    legend.title = element_text(size = 18, family = "Times New Roman", face="bold"),
    strip.text = element_text(size = 18, family = "Times New Roman", face="bold")  # ADD THIS LINE - makes facet titles larger
  )+
  scale_y_continuous(expand = expansion(mult = c(0, 1.5)))

print(p_mse_error)
ggsave("/accounts/grad/aqwang/unilasso/figures_22data_default_lambda/mse_boot_22data.png", plot = p_mse_error, width = 16, height = 18, dpi = 300)


# make choose label_text plot_mse_data2 a wide format 
plot_mse_data_wide <- plot_mse_data2 %>%
  select(dataset, method, label_text) %>%
  pivot_wider(names_from = method, values_from = label_text)
print(plot_mse_data_wide)


summary_boot_support <- boot_results %>%
  group_by(dataset) %>%
  summarise(
    # Support size statistics
    unilasso_loo_true_mean_support = mean(unilasso_loo_true_support, na.rm = TRUE),
    unilasso_loo_true_sd_support = sd(unilasso_loo_true_support, na.rm = TRUE),
    polish_unilasso_mean_support = mean(polish_unilasso_support, na.rm = TRUE),
    polish_unilasso_sd_support = sd(polish_unilasso_support, na.rm = TRUE),
    lasso_cv_mean_support = mean(lasso_cv_support, na.rm = TRUE),
    lasso_cv_sd_support = sd(lasso_cv_support, na.rm = TRUE),
    unireg_mean_support = mean(unireg_support, na.rm = TRUE),
    unireg_sd_support = sd(unireg_support, na.rm = TRUE),
    least_squares_mean_support = mean(least_squares_support, na.rm = TRUE),
    least_squares_sd_support = sd(least_squares_support, na.rm = TRUE),
    .groups = 'drop'
  )

# support size plot with error bars
# Create a single pivot that handles both mean and SD columns together
plot_support_data <- summary_boot_support %>%
  pivot_longer( 
    cols = c(unilasso_loo_true_mean_support, 
             polish_unilasso_mean_support, lasso_cv_mean_support,
             unireg_mean_support, least_squares_mean_support,
             unilasso_loo_true_sd_support, 
             polish_unilasso_sd_support, lasso_cv_sd_support,
             unireg_sd_support, least_squares_sd_support),
    names_to = c("method", "statistic"),
    values_to = "value",
    names_pattern = "(.*)_(mean_support|sd_support)"
  ) %>%
  # Pivot wider to get mean_support and sd_support as separate columns
  pivot_wider(
    names_from = statistic,
    values_from = value
  ) %>%
  # Clean up method names
  mutate(method = recode(method,
                        "unilasso_loo_true" = "uniLasso",
                        "polish_unilasso" = "Polish",
                        "lasso_cv" = "Lasso",
                        "unireg" = "uniReg",
                        "least_squares" = "LS"
                        ))

# Build labels: 1 decimal for support (since it's typically whole numbers, use 1 decimal)
plot_support_data2 <- plot_support_data %>%
  mutate(
    mean_label = sprintf("%.1f", mean_support),
    sd_label = sprintf("%.1f", sd_support),
    label_text = paste0(mean_label, " ± ", sd_label)
  )

p_support_error <- ggplot(plot_support_data2, aes(x = method, y = mean_support, fill = method)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.8, alpha = 0.7) +  # wider bars
  geom_errorbar(aes(ymin = mean_support - sd_support, ymax = mean_support + sd_support),
                position = position_dodge(width = 0.6),
                width = 0.25, alpha = 0.8) +
  # Label means on top of bars, tilted 45 degrees
  geom_text(aes(label = label_text),
            position = position_dodge(width = 1), 
            vjust = -2, size = 3.3, angle = 75, hjust = 0, family = "Times New Roman") +
  # Facet with per-facet axes
  ggh4x::facet_wrap2(
    ~ dataset,
    nrow = ceiling(length(unique(plot_support_data$dataset))/5),
    ncol = 5,
    scales = "free_y",
    axes = "x"
  ) +
  labs(
    #title = "Mean Support Size with Standard Deviation Bars (100 Bootstrap Results)",
    x = "Method",
    y = "Mean Support Size",
    fill = "Method"
  ) +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 14, family = "Times New Roman", face="bold"),  # increase tick label font size
    axis.text.y = element_text(size = 16, family = "Times New Roman", face = "bold"),  # ADD THIS LINE
    axis.title.x = element_text(size = 18, family = "Times New Roman", face="bold"),  # x-axis title font size
    axis.title.y = element_text(size = 18, family = "Times New Roman", face="bold"),  # y-axis title font size
    legend.position = "bottom",
    legend.text = element_text(size = 18, family = "Times New Roman", face="bold"),
    legend.title = element_text(size = 18, family = "Times New Roman", face="bold"),
    strip.text = element_text(size = 18, family = "Times New Roman", face="bold")  # ADD THIS LINE - makes facet titles larger
  )+
  scale_y_continuous(expand = expansion(mult = c(0, 0.8)))
print(p_support_error)
ggsave("/accounts/grad/aqwang/unilasso/figures_22data_default_lambda/supp_boot_22data.png", plot = p_support_error, width = 16, height = 18, dpi = 300)



# Make a wide format table for support data
plot_support_data_wide <- plot_support_data2 %>%
  select(dataset, method, label_text) %>%
  pivot_wider(names_from = method, values_from = label_text)

print(plot_support_data_wide)



# for prediction interval, make a plot of average width of prediction interval for each dataset with standard error bar
pred_int <- read.csv("/accounts/grad/aqwang/unilasso/analysis/unilasso_22data_default_lambda/unilasso_22datasets_100bootstrap_pred_int.csv")

# print the unique names in results_all_splits$dataset to verify
print(unique(pred_int$dataset))

#rename dataset names to match previous naming convention
pred_int$dataset <- recode(pred_int$dataset,
                          "airfoil" = "Airfoil",
                            "appliances_energy" = "Appliances energy",
                            "auto_mpg" = "Auto MPG",
                            "automobile" = "Automobile",
                            "beijing_pm2.5" = "Beijing PM2.5",
                            "bike_sharing" = "Bike sharing",
                            "concrete" = "Concrete",
                            "crime" = "Crime",
                            "crime_unnormalized" = "Crime unnormalized",
                            "daily_demand" = "Daily demand",
                            "facebook_metrics" = "Facebook metrics",
                            "forest_fires" = "Forest fires",
                            "infrared_thermo_temp" = "Infrared thermo temp",
                            "liver_disorders" = "Liver disorders",
                            "metro_traffic" = "Metro traffic",
                            "parkinsons" = "Parkinsons",
                            "power_consumption" = "Power consumption",
                            "power_plant" = "Power plant",
                            "real_estate" = "Real estate",
                            "servo" = "Servo",
                            "stock_portfolio" = "Stock portfolio",
                            "superconductivity" = "Superconductivity")

# graph the mean width of prediction interval for all 4 methods for each dataset
library(ggplot2)
library(dplyr)

# mean and sd is already calculated in pred_int
# pred_int is a long format
pred_int <- pred_int %>%
  mutate(
    method = recode(method,
                    "lasso_cv" = "Lasso",
                    "uniLasso_loo_true" = "uniLasso",
                    "polish_uniLasso" = "Polish",
                    "unireg" = "uniReg",
                    "least_squares" = "LS")
  )

# DELETE unilasso_loo_false method from pred_int
pred_int <- pred_int %>%
  filter(method != "uniLasso_loo_false")

# Build labels: 1 decimal; if >100 use scientific with 1 sig decimal; if <0.1 use 4 decimals
pred_int2 <- pred_int %>%
  mutate(
    mean_label = case_when(
      avg_interval_width < 0.1 ~ formatC(avg_interval_width, format = "e",  digits = 2),
      avg_interval_width > 100 ~ formatC(avg_interval_width, format = "e", digits = 2),
      TRUE ~ sprintf("%.2f", avg_interval_width)
    ),
    sd_label = case_when(
      sd_interval_width < 0.1 ~ formatC(sd_interval_width, format = "e",  digits = 2),
      sd_interval_width > 100 ~ formatC(sd_interval_width, format = "e", digits = 2),
      TRUE ~ sprintf("%.2f",  sd_interval_width)
    ),
    label_text = paste0(mean_label, " ± ", sd_label)
  )
p_pred_int <- ggplot(pred_int2, aes(x = method, y = avg_interval_width, fill = method)) +
  geom_col(position = position_dodge(width = 0.9), width = 0.9, alpha = 0.7) +  # wider bars
  geom_errorbar(aes(ymin = avg_interval_width - sd_interval_width, ymax = avg_interval_width + sd_interval_width),
                position = position_dodge(width = 0.6),
                width = 0.25, alpha = 0.8) +
  # Label means on top of bars, tilted 45 degrees
  geom_text(aes(label = label_text),  
            position = position_dodge(width = 1),
            vjust = -2, size = 3.3, angle = 80, hjust = 0, family = "Times New Roman") +
  # Facet with per-facet axes
  ggh4x::facet_wrap2(
    ~ dataset,
    nrow = ceiling(length(unique(pred_int$dataset))/5),
    ncol = 5,
    scales = "free_y",
    axes = "x"
  ) +
  labs(
    #title = "Mean Width of Prediction Interval with Standard Deviation Bars (100 Bootstrap Results)",
    x = "Method", 
    y = "Mean Width of Prediction Interval",
    fill = "Method"
  ) +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 18, family = "Times New Roman", face = "bold"),
    axis.text.y = element_text(size = 16, family = "Times New Roman", face = "bold"),  # ADD THIS LINE
    axis.title = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.position = "bottom",
    legend.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.title = element_text(size = 20, family = "Times New  Roman", face = "bold"),
    strip.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    strip.placement = "outside"
  ) +
  scale_y_continuous(expand = expansion(mult = c(0, 1)))
print(p_pred_int) 
ggsave("/accounts/grad/aqwang/unilasso/figures_22data_default_lambda/appendix_22data_pred_int.png", 
       plot = p_pred_int, width = 16, height = 20, dpi = 300)

# make a wide format table for prediction interval data
pred_int_wide <- pred_int2 %>%
  select(dataset, method, label_text) %>%
  pivot_wider(names_from = method, values_from = label_text)
print(pred_int_wide)

library(dplyr)
library(tidyr)

pred_int_coverage <- pred_int %>% select(dataset, method, coverage) %>% pivot_wider(names_from = method, values_from = coverage) %>% select(dataset, LS, Lasso, uniReg, uniLasso, Polish) %>% mutate(across(-dataset, ~ round(., 3)))

# Calculate row averages (across methods for each dataset), rounded to 3 decimal places
pred_int_coverage$row_avg <- round(rowMeans(pred_int_coverage[, c("LS", "Lasso", "uniReg", "uniLasso", "Polish")], na.rm = TRUE), 3)

# Calculate column averages (across datasets for each method)
col_avgs <- colMeans(pred_int_coverage[, c("LS", "Lasso", "uniReg", "uniLasso", "Polish", "row_avg")], na.rm = TRUE)

# Optionally, print column averages
print(col_avgs)

# add col avg to the bottom of pred_int_coverage
pred_int_coverage <- rbind(pred_int_coverage, c("Column Average", round(col_avgs, 3)))

# save as csv
write.csv(pred_int_coverage, "/accounts/grad/aqwang/unilasso/figures_22data_default_lambda/pred_int_coverage_22datasets.csv", row.names = FALSE)

```
