
# Final version: combine stability with mse, support, sign_diff 9/15 Monday updates
```{r combine stability with mse, support, sign_diff}

### setup####

if (R.home() != "/scratch/users/aqwang/conda/envs/r_package/lib/R") {
  system("/scratch/users/aqwang/conda/envs/r_package/bin/Rscript -e 'rmarkdown::render(\"unilasso_12data_loop_graphs.Rmd\")'")
  quit("no")
}

# check the R environment is r_package
R.home()

# set working directory
setwd("/accounts/grad/aqwang/unilasso/analysis/unilasso_12data_default_lambda")

# load packages 
library(uniLasso) # for unilasso 
library(glmnet) # for cv lasso 
library(dplyr)
library(tidyr)

# Define all dataset names (remove "data_" prefix)
dataset_names <- c(
  "ca_housing", "computer",
  "debutanizer", "diamond", "elevator", "energy_efficiency",
  "insurance", "kin8nm", "miami_housing", "naval_propulsion",
 "protein_structure", "qsar")

 
# Number of random splits
N_SPLITS <- 100
####################################################



###################(1)load results for mse, support, sign_diff#################
# read csv file
results_all_splits <- read.csv("/accounts/grad/aqwang/unilasso/analysis/random_split_result/unilasso_12datasets_100splits_train50percentresults.csv")


# using results_all_splits data frame to graph boxplot of MSE on the left and boxplot of support on the right for each dataset 
library(ggplot2)
library(tidyr)
library(dplyr)

# Reshape data for plotting
plot_long <- results_all_splits %>%
  select(dataset, unilasso_loo_true_mse, polish_unilasso_mse, lasso_cv_mse, unireg_mse, least_squares_mse,
         unilasso_loo_true_support, polish_unilasso_support, lasso_cv_support,unireg_support, least_squares_support,
         unilasso_loo_true_sign_diff, polish_unilasso_sign_diff,lasso_cv_sign_diff,unireg_sign_diff, least_squares_sign_diff) %>%
  pivot_longer(
    cols = c(unilasso_loo_true_mse, polish_unilasso_mse, lasso_cv_mse, unireg_mse, least_squares_mse,
             unilasso_loo_true_support, polish_unilasso_support, lasso_cv_support, unireg_support, least_squares_support,
             unilasso_loo_true_sign_diff, polish_unilasso_sign_diff, lasso_cv_sign_diff, unireg_sign_diff, least_squares_sign_diff),
    names_to = c("method", ".value"),
    names_pattern = "(unilasso_loo_true|polish_unilasso|lasso_cv|unireg|least_squares)_(mse|support|sign_diff)"
  )

# Order datasets for consistent facetting
desired_order <- c(
  "ca_housing", "debutanizer", "insurance", "kin8nm", 
  "computer", "elevator", "energy_efficiency", "miami_housing", "naval_propulsion",
  "diamond", "protein_structure", "qsar"
)


plot_long$dataset <- factor(plot_long$dataset, levels = desired_order)

# rename unilasso_loo_true to unilasso
plot_long$method <- recode(plot_long$method, unilasso_loo_true = "uniLasso", polish_unilasso = "Polish", lasso_cv = "Lasso", unireg = "uniReg", least_squares = "LS")

# After creating plot_long and recoding the method names, add this line:
plot_long$method <- factor(plot_long$method, levels = c("LS", "Lasso", "uniReg", "uniLasso", "Polish"))

#rename all datasets to have first letter capitalized and underscores replaced with spaces
plot_long$dataset <- recode(plot_long$dataset,
                            "ca_housing" = "CA housing",
                            "debutanizer" = "Debutanizer",
                            "insurance" = "Insurance",
                            "kin8nm" = "Kin8nm",
                            "computer" = "Computer",
                            "elevator" = "Elevator",
                            "energy_efficiency" = "Energy efficiency",
                            "miami_housing" = "Miami housing",
                            "naval_propulsion" = "Naval propulsion",
                            "diamond" = "Diamond",
                            "protein_structure" = "Protein structure",
                            "qsar" = "QSAR"
)

# Create combined long data with metric type including sign_diff
plot_combined_long <- plot_long %>%
  pivot_longer(
    cols = c(mse, support, sign_diff),
    names_to = "metric",
    values_to = "value"
  ) %>%
  mutate(
    metric = recode(metric, 
                   "mse" = "MSE", 
                   "support" = "Support",
                   "sign_diff" = "Number of violations"),
    metric = factor(metric, levels = c("MSE", "Support", "Number of violations"))
  )


#########################################################


###################(2)calculate stability for all our 12 datasets. 9/19 Friday updates#################
library(dplyr)
library(utils)  # for combn function

# Function to calculate stability for a given method - returns all pairwise values
calculate_stability_full <- function(data, method_name) {
  # Filter data for the specific method
  method_data <- data %>% filter(method == method_name)
  
  # Extract coefficient columns (starting from column 4)
  coef_matrix <- as.matrix(method_data[, 4:ncol(method_data)])
  
  # Number of models for this method
  n_models <- nrow(coef_matrix)
  
  if (n_models < 2) {
    return(c())  # Return empty vector if not enough models
  }
  
  # Generate all pairs of models (100 choose 2)
  model_pairs <- combn(1:n_models, 2, simplify = FALSE)
  
  # Calculate stability for each pair
  stability_values <- sapply(model_pairs, function(pair) {
    model_i <- pair[1]
    model_j <- pair[2]
    
    # Find selected features (non-zero coefficients) for each model. returns the indices (column numbers) where the coefficients are nonzero.
    features_i <- which(coef_matrix[model_i, ] != 0)
    features_j <- which(coef_matrix[model_j, ] != 0)
    
    # Calculate Jaccard similarity: |intersection| / |union|
    common_features <- length(intersect(features_i, features_j))
    total_unique_features <- length(union(features_i, features_j))
    
    # Handle case where both models select no features
    if (total_unique_features == 0) {
      return(1)  # Perfect stability if both select nothing
    } else {
      return(common_features / total_unique_features)
    }
  })
  
  # Return the entire vector of stability values
  return(stability_values)
}

# Get all CSV files in the coef_csv directory
coef_csv_dir <- "/accounts/grad/aqwang/unilasso/analysis/coef_csv_12datasets_standardize_lasso"
csv_files <- list.files(coef_csv_dir, pattern = "coefficients_.*\\.csv$", full.names = TRUE)

# check dataset names from file names
dataset_names <- gsub("coefficients_(.+)\\.csv", "\\1", basename(csv_files))
print(dataset_names)  # Verify dataset names

# Initialize storage for all results
all_stability_results <- data.frame(
  dataset = character(),
  method = character(),
  mean_stability = numeric(),
  sd_stability = numeric(),
  min_stability = numeric(),
  max_stability = numeric(),
  n_pairs = integer(),
  stringsAsFactors = FALSE
)

# Initialize storage for detailed results (optional - if you want all pairwise values)
all_stability_detailed <- list()

# Loop through all datasets
for (i in seq_along(csv_files)) {
  dataset_name <- dataset_names[i]
  csv_file <- csv_files[i]
  
  cat("\n", strrep("=", 60), "\n")
  cat("Processing dataset:", dataset_name, "(", i, "/", length(csv_files), ")\n")
  cat(strrep("=", 60), "\n")
  
  # Read coefficient data
  tryCatch({
    coefficients_data <- read.csv(csv_file)
    # Remove rows with method=unilasso_loo_false
    coefficients_data <- coefficients_data[coefficients_data$method != "unilasso_loo_false", ]
    coefficients_data <- coefficients_data[coefficients_data$method != "uni_loo", ]
    
    # Get unique methods in this dataset
    unique_methods <- unique(coefficients_data$method)
    cat("Found methods:", paste(unique_methods, collapse = ", "), "\n")
    
    # Calculate stability for each method in this dataset
    dataset_stability_detailed <- list()
    
    for (method in unique_methods) {
      cat("  Processing method:", method, "...")
      
      # Calculate full stability vector for this method
      stability_vector <- calculate_stability_full(coefficients_data, method)
      
      if (length(stability_vector) > 0) {
        # Clean method name
        clean_method <- recode(method,
          "unilasso_loo_true" = "uniLasso",
          "polish_unilasso" = "Polish",
          "lasso_cv" = "Lasso",
          "unireg" = "uniReg", 
          "least_squares" = "LS"
        )
        
        # Calculate summary statistics
        summary_stats <- data.frame(
          dataset = dataset_name,
          method = clean_method,
          mean_stability = mean(stability_vector, na.rm = TRUE),
          sd_stability = sd(stability_vector, na.rm = TRUE),
          min_stability = min(stability_vector, na.rm = TRUE),
          max_stability = max(stability_vector, na.rm = TRUE),
          n_pairs = length(stability_vector),
          stringsAsFactors = FALSE
        )
        
        # Add to main results dataframe
        all_stability_results <- rbind(all_stability_results, summary_stats)
        
        # Store detailed results (optional)
        dataset_stability_detailed[[clean_method]] <- stability_vector
        
        cat(" Done (", length(stability_vector), " pairs)\n")
        
      } else {
        cat(" Skipped (insufficient data)\n")
      }
    }
    
    # Store detailed results for this dataset
    all_stability_detailed[[dataset_name]] <- dataset_stability_detailed
    
    # Print summary for this dataset
    dataset_results <- all_stability_results[all_stability_results$dataset == dataset_name, ]
    if (nrow(dataset_results) > 0) {
      cat("\nSummary for", dataset_name, ":\n")
      for (j in 1:nrow(dataset_results)) {
        row <- dataset_results[j, ]
        cat(sprintf("  %-10s: Mean = %.3f (SD = %.3f) Range = [%.3f, %.3f] [%d pairs]\n",
                    row$method, row$mean_stability, row$sd_stability,
                    row$min_stability, row$max_stability, row$n_pairs))
      }
    }
    
  }, error = function(e) {
    cat("ERROR processing", dataset_name, ":", e$message, "\n")
  })
}

# Final summary
cat("\n", strrep("=", 80), "\n")
cat("STABILITY ANALYSIS COMPLETE!\n")
cat("Total datasets processed:", length(unique(all_stability_results$dataset)), "\n")
cat("Total method-dataset combinations:", nrow(all_stability_results), "\n")
cat(strrep("=", 80), "\n")

# Display overall results
print(all_stability_results)

# Save results
write.csv(all_stability_results, "stability_results_12_data_summary.csv", row.names = FALSE)
save(all_stability_results, all_stability_detailed, file = "stability_results_12_datasets.RData")


################# prepare stability data #################
library(ggplot2)

# Build one long data.frame: dataset, method, stability
make_long <- function(all_stability_detailed) {
  do.call(rbind, lapply(names(all_stability_detailed), function(ds) {
    methods <- all_stability_detailed[[ds]]
    if (length(methods) == 0) return(NULL)
    do.call(rbind, lapply(names(methods), function(m) {
      v <- methods[[m]]
      v <- v[is.finite(v)]                 # drop NA/Inf if present
      if (length(v) == 0) return(NULL)
      data.frame(dataset = ds, method = m, stability = v, 
                 stringsAsFactors = FALSE)
    }))
  }))
}

plot_data <- make_long(all_stability_detailed)


# Order datasets for consistent facetting
desired_order <- c(
  "ca_housing", "debutanizer", "insurance", "kin8nm", 
  "computer", "elevator", "energy_efficiency", "miami_housing", "naval_propulsion",
  "diamond", "protein_structure", "qsar"
)


plot_data$dataset <- factor(plot_data$dataset, levels = desired_order)

#rename all datasets to have first letter capitalized and underscores replaced with spaces
plot_data$dataset <- recode(plot_data$dataset,
                            "ca_housing" = "CA housing",
                            "debutanizer" = "Debutanizer",
                            "insurance" = "Insurance",
                            "kin8nm" = "Kin8nm",
                            "computer" = "Computer",
                            "elevator" = "Elevator",
                            "energy_efficiency" = "Energy efficiency",
                            "miami_housing" = "Miami housing",
                            "naval_propulsion" = "Naval propulsion",
                            "diamond" = "Diamond",
                            "protein_structure" = "Protein structure",
                            "qsar" = "QSAR"
)

# Use similar colors for Polish, uniLasso, and uniReg
method_colors <- c(
  "uniLasso" = "#e75480",      # medium pink
  "Polish" = "#f7b6d2",        # light pink
  "uniReg" = "#c71585",        # dark pink/magenta
  "Lasso" = "#1f77b4",      # medium blue
  "LS" = "#aec7e8"           # light blue
)


########################(3) combine stability with mse, support, sign_diff########################
library(ggh4x)

stability_data_formatted <- plot_data %>%
  rename(value = stability) %>%
  mutate(metric = "Stability") %>%
  select(dataset, method, metric, value)


# Combine all four metrics into one dataset
plot_combined_long_with_stability <- bind_rows(
  plot_combined_long,  # This has MSE, Support, and Number of violations
  stability_data_formatted  # This adds Stability
) %>%
  mutate(
    metric = factor(metric, levels = c("MSE", "Support", "Number of violations", "Stability"))
  ) %>%
  mutate(
    method = factor(method, levels = c("LS", "Lasso", "uniReg", "uniLasso", "Polish"))
  )


# Choose first 6 datasets (now with stability included)
plot_combined_long1_with_stability <- plot_combined_long_with_stability %>%
  filter(dataset %in% c("CA housing", "Debutanizer", "Insurance", "Kin8nm", "Computer", "Elevator"))

# Choose last 6 datasets (now with stability included)
plot_combined_long2_with_stability <- plot_combined_long_with_stability %>%
  filter(dataset %in% c("Energy efficiency", "Miami housing", "Naval propulsion", "Diamond", "Protein structure", "QSAR"))

# Create the enhanced plot with 4 columns (MSE, Support, Number of violations, Stability)
p_combined_facet1_with_stability <- ggplot(plot_combined_long1_with_stability, aes(x = method, y = value, fill = method)) +
  geom_boxplot() +
  facet_grid2(
    dataset ~ metric,
    switch = "y",
    scales = "free_y",     # <-- make y free
    independent = "y"      # <-- now each dataset×metric panel gets its own y-scale
  ) +
  labs(x = "Method", y = NULL, fill = "Method") +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 18, family = "Times New Roman", face = "bold"),
    axis.text.y = element_text(size = 16, family = "Times New Roman", face = "bold"),  # ADD THIS LINE
    axis.title = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.position = "bottom",
    legend.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.title = element_text(size = 20, family = "Times New Roman", face = "bold"),
    strip.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    strip.placement = "outside",
    panel.spacing.y = unit(0.7, "cm")  # Increase vertical spacing between rows
  )

print(p_combined_facet1_with_stability)
# Save the enhanced plot
ggsave("/accounts/grad/aqwang/unilasso/figures/p_mse_supp_sign_stability_12data1.png", 
       plot = p_combined_facet1_with_stability, width = 20, height = 24, dpi = 300)



# Do the same for the second set of datasets
p_combined_facet2_with_stability <- ggplot(plot_combined_long2_with_stability, aes(x = method, y = value, fill = method)) +
  geom_boxplot() +
  facet_grid2(
    dataset ~ metric,
    switch = "y",
    scales = "free_y",     # <-- make y free
    independent = "y"      # <-- now each dataset×metric panel gets its own y-scale
  ) +
  labs(x = "Method", y = NULL, fill = "Method") +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 18, family = "Times New Roman", face = "bold"),
    axis.text.y = element_text(size = 16, family = "Times New Roman", face = "bold"),  # ADD THIS LINE
    axis.title = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.position = "bottom",
    legend.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.title = element_text(size = 20, family = "Times New Roman", face = "bold"),
    strip.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    strip.placement = "outside",
    panel.spacing.y = unit(0.7, "cm")  # Increase vertical spacing between rows
  )

print(p_combined_facet2_with_stability)

# Save the second enhanced plot
ggsave("/accounts/grad/aqwang/unilasso/figures/p_mse_supp_sign_stability_12data2.png", 
       plot = p_combined_facet2_with_stability, width = 20, height = 24, dpi = 300)

```












# Loop to run uniLasso analysis on all 17 datasets with 100 random splits
```{r setup}
if (R.home() != "/scratch/users/aqwang/conda/envs/r_package/lib/R") {
  system("/scratch/users/aqwang/conda/envs/r_package/bin/Rscript -e 'rmarkdown::render(\"unilasso_12data_loop_graphs.Rmd\")'")
  quit("no")
}

# check the R environment is r_package
R.home()

# set working directory
setwd("/accounts/grad/aqwang/unilasso/analysis")

# load packages 
library(uniLasso) # for unilasso 
library(glmnet) # for cv lasso 
library(dplyr)
library(tidyr)

# Define all dataset names (remove "data_" prefix)
dataset_names <- c(
  "ca_housing", "computer",
  "debutanizer", "diamond", "elevator", "energy_efficiency",
  "insurance", "kin8nm", "miami_housing", "naval_propulsion",
 "protein_structure", "qsar")

 
# Number of random splits
N_SPLITS <- 100

# Initialize results storage for all splits
results_all_splits <- data.frame(
  dataset = character(),
  split_id = integer(),
  unilasso_loo_true_mse = numeric(),
  unilasso_loo_true_support = numeric(),
  unilasso_loo_false_mse = numeric(),
  unilasso_loo_false_support = numeric(),
  polish_unilasso_mse = numeric(),
  polish_unilasso_support = numeric(),
  lasso_cv_mse = numeric(),
  lasso_cv_support = numeric(),
  stringsAsFactors = FALSE
)
```


# run below (see unilasso_12data_loop_basic) on stringsAsFactors
# Version 2: Running 100 random 80/20 splits for each dataset
```{r run_analysis_loop_100_splits}
# Loop through all datasets
for (i in seq_along(dataset_names)) {
  dataset_name <- dataset_names[i]
  
  # Visual separator for output 
  cat("\n", strrep("=", 80), "\n")
  cat("Processing dataset:", dataset_name, "(", i, "/", length(dataset_names), ")\n")
  cat("Running", N_SPLITS, "random train/test splits...\n")
  cat(strrep("=", 80), "\n")
  
  # Load data
  X_path <- paste0("/accounts/grad/aqwang/unilasso/datasets_17/", dataset_name, "/X.csv")
  y_path <- paste0("/accounts/grad/aqwang/unilasso/datasets_17/", dataset_name, "/y.csv")
  
  X <- read.csv(X_path)
  X <- as.matrix(X)
  y <- read.csv(y_path, header = FALSE)
  y <- as.numeric(unlist(y))
  
  cat("Data dimensions: X =", dim(X), ", y =", length(y), "\n")
  
  # Storage for this dataset's results across all splits
  dataset_split_results <- list()
  
  # Run N_SPLITS different train/test splits
  for (split_id in 1:N_SPLITS) {
    
    if (split_id %% 10 == 0) {
      cat("  Split", split_id, "/", N_SPLITS, "\n")
    }
    
    # Split data into training and test sets (different seed for each split)
    set.seed(split_id)  # Different seed for each split
    train_indices <- sample(seq_len(nrow(X)), size = floor(0.8 * nrow(X)))
    Xtr <- X[train_indices, ]
    ytr <- y[train_indices]
    Xte <- X[-train_indices, ]
    yte <- y[-train_indices]
    
    # Initialize results for this split
    split_results <- list()
    
    # ensuring the same CV folds for all methods within this split
    set.seed(42 + split_id)  # Consistent folds within split, but different across splits
    K <- 10
    n <- nrow(Xtr)
    foldid <- sample(rep(1:K, length.out = n))
    
    # 1. UniLasso with loo=TRUE
    tryCatch({
      unilasso_cv_loo_true <- cv.uniLasso(
        Xtr, ytr,
        family = "gaussian",
        loo = TRUE,
        lower.limits = 0,
        standardize = FALSE,
        foldid = foldid,
        nlambda = 100
      )
      
      yte_pred_CV <- predict(unilasso_cv_loo_true, newx = Xte, s = "lambda.min")
      split_results$unilasso_loo_true_mse <- mean((yte_pred_CV - yte)^2)
      split_results$unilasso_loo_true_support <- sum(coef(unilasso_cv_loo_true, s = "lambda.min")[-1] != 0)
      
    }, error = function(e) {
      split_results$unilasso_loo_true_mse <<- NA
      split_results$unilasso_loo_true_support <<- NA
    })
    
    # 2. UniLasso with loo=FALSE
    tryCatch({
      unilasso_cv_loo_false <- cv.uniLasso(
        Xtr, ytr,
        family = "gaussian",
        loo = FALSE,
        lower.limits = 0,
        standardize = FALSE,
        foldid = foldid,
        nlambda = 100
      )
      
      yte_pred_CV <- predict(unilasso_cv_loo_false, newx = Xte, s = "lambda.min")
      split_results$unilasso_loo_false_mse <- mean((yte_pred_CV - yte)^2)
      split_results$unilasso_loo_false_support <- sum(coef(unilasso_cv_loo_false, s = "lambda.min")[-1] != 0)
      
    }, error = function(e) {
      split_results$unilasso_loo_false_mse <<- NA
      split_results$unilasso_loo_false_support <<- NA
    })
    
    # 3. Polish UniLasso
    tryCatch({
      pol <- polish.uniLasso(Xtr, ytr,
                            family = "gaussian",
                            foldid = foldid,
                            nlambda = 100, 
                            standardize = FALSE,
                            intercept = TRUE,
                            loo = TRUE)
      
      yte_pred_pol <- predict(pol, newx = Xte, s = "lambda.min")
      split_results$polish_unilasso_mse <- mean((yte_pred_pol - yte)^2)
      split_results$polish_unilasso_support <- sum(coef(pol, s = "lambda.min")[-1] != 0)
      
    }, error = function(e) {
      split_results$polish_unilasso_mse <<- NA
      split_results$polish_unilasso_support <<- NA
    })
    
    # 4. Lasso with CV
    tryCatch({
      lasso_cv <- cv.glmnet(
        Xtr, ytr,
        family = "gaussian",
        alpha = 1,
        standardize = FALSE,
        foldid = foldid,
        nlambda = 100
      )
      
      yte_pred_CV <- predict(lasso_cv, newx = Xte, s = "lambda.min")
      split_results$lasso_cv_mse <- mean((yte_pred_CV - yte)^2)
      split_results$lasso_cv_support <- sum(coef(lasso_cv, s = "lambda.min")[-1] != 0)
      
    }, error = function(e) {
      split_results$lasso_cv_mse <<- NA
      split_results$lasso_cv_support <<- NA
    })
    
    # Add results to main results dataframe
    new_row <- data.frame(
      dataset = dataset_name,
      split_id = split_id,
      unilasso_loo_true_mse = split_results$unilasso_loo_true_mse,
      unilasso_loo_true_support = split_results$unilasso_loo_true_support,
      unilasso_loo_false_mse = split_results$unilasso_loo_false_mse,
      unilasso_loo_false_support = split_results$unilasso_loo_false_support,
      polish_unilasso_mse = split_results$polish_unilasso_mse,
      polish_unilasso_support = split_results$polish_unilasso_support,
      lasso_cv_mse = split_results$lasso_cv_mse,
      lasso_cv_support = split_results$lasso_cv_support,
      stringsAsFactors = FALSE
    )
    
    results_all_splits <- rbind(results_all_splits, new_row)
  }
  
  # Summary statistics for this dataset across all splits
  dataset_summary <- results_all_splits[results_all_splits$dataset == dataset_name, ]
  
  cat("\nSummary statistics for", dataset_name, "(", N_SPLITS, "splits):\n")
  cat("  UniLasso (LOO=T):     Mean MSE =", sprintf("%.6f", mean(dataset_summary$unilasso_loo_true_mse, na.rm = TRUE)), 
      " (SD =", sprintf("%.6f", sd(dataset_summary$unilasso_loo_true_mse, na.rm = TRUE)), ")\n")
  cat("                        Mean Support =", sprintf("%.2f", mean(dataset_summary$unilasso_loo_true_support, na.rm = TRUE)), 
      " (SD =", sprintf("%.2f", sd(dataset_summary$unilasso_loo_true_support, na.rm = TRUE)), ")\n")
  
  cat("  UniLasso (LOO=F):     Mean MSE =", sprintf("%.6f", mean(dataset_summary$unilasso_loo_false_mse, na.rm = TRUE)), 
      " (SD =", sprintf("%.6f", sd(dataset_summary$unilasso_loo_false_mse, na.rm = TRUE)), ")\n")
  cat("                        Mean Support =", sprintf("%.2f", mean(dataset_summary$unilasso_loo_false_support, na.rm = TRUE)), 
      " (SD =", sprintf("%.2f", sd(dataset_summary$unilasso_loo_false_support, na.rm = TRUE)), ")\n")
  
  cat("  Polish UniLasso:      Mean MSE =", sprintf("%.6f", mean(dataset_summary$polish_unilasso_mse, na.rm = TRUE)), 
      " (SD =", sprintf("%.6f", sd(dataset_summary$polish_unilasso_mse, na.rm = TRUE)), ")\n")
  cat("                        Mean Support =", sprintf("%.2f", mean(dataset_summary$polish_unilasso_support, na.rm = TRUE)), 
      " (SD =", sprintf("%.2f", sd(dataset_summary$polish_unilasso_support, na.rm = TRUE)), ")\n")
  
  cat("  Lasso CV:             Mean MSE =", sprintf("%.6f", mean(dataset_summary$lasso_cv_mse, na.rm = TRUE)), 
      " (SD =", sprintf("%.6f", sd(dataset_summary$lasso_cv_mse, na.rm = TRUE)), ")\n")
  cat("                        Mean Support =", sprintf("%.2f", mean(dataset_summary$lasso_cv_support, na.rm = TRUE)), 
      " (SD =", sprintf("%.2f", sd(dataset_summary$lasso_cv_support, na.rm = TRUE)), ")\n")
}

cat("\n", strrep("=", 80), "\n")
cat("ANALYSIS COMPLETE FOR ALL", length(dataset_names), "DATASETS!\n")
cat("Total number of experiments:", nrow(results_all_splits), "\n")
cat(strrep("=", 80), "\n")
```

```{r load results graph: comparing loo=TRUE vs loo=FALSE with train/test 80/20 split}
# read csv file
results_all_splits <- read.csv("unilasso_17datasets_100splits_train80percent.csv")
library(dplyr)

summary_by_dataset <- results_all_splits %>%
  group_by(dataset) %>%
  summarise(
    unilasso_loo_true_mean_mse = mean(unilasso_loo_true_mse, na.rm = TRUE),
    unilasso_loo_true_sd_mse   = sd(unilasso_loo_true_mse,   na.rm = TRUE),
    unilasso_loo_false_mean_mse = mean(unilasso_loo_false_mse, na.rm = TRUE),
    unilasso_loo_false_sd_mse   = sd(unilasso_loo_false_mse,   na.rm = TRUE),
    polish_unilasso_mean_mse = mean(polish_unilasso_mse, na.rm = TRUE),
    polish_unilasso_sd_mse   = sd(polish_unilasso_mse,   na.rm = TRUE),
    lasso_cv_mean_mse = mean(lasso_cv_mse, na.rm = TRUE),
    lasso_cv_sd_mse   = sd(lasso_cv_mse,   na.rm = TRUE),

    unilasso_loo_true_mean_support = mean(unilasso_loo_true_support, na.rm = TRUE),
    unilasso_loo_true_sd_support   = sd(unilasso_loo_true_support,   na.rm = TRUE),
    unilasso_loo_false_mean_support = mean(unilasso_loo_false_support, na.rm = TRUE),
    unilasso_loo_false_sd_support   = sd(unilasso_loo_false_support,   na.rm = TRUE),
    polish_unilasso_mean_support = mean(polish_unilasso_support, na.rm = TRUE),
    polish_unilasso_sd_support   = sd(polish_unilasso_support,   na.rm = TRUE),
    lasso_cv_mean_support = mean(lasso_cv_support, na.rm = TRUE),
    lasso_cv_sd_support   = sd(lasso_cv_support,   na.rm = TRUE),
    .groups = "drop"
  )

# using results_all_splits data frame to graph boxplot of MSE on the left and boxplot of support on the right for each dataset 
library(ggplot2)
library(tidyr)
library(dplyr)

# Reshape data for plotting
plot_long <- results_all_splits %>%
  select(dataset, unilasso_loo_true_mse, unilasso_loo_false_mse, lasso_cv_mse,
         unilasso_loo_true_support, unilasso_loo_false_support, lasso_cv_support) %>%
  pivot_longer(
    cols = c(unilasso_loo_true_mse, unilasso_loo_false_mse, lasso_cv_mse,
            unilasso_loo_true_support, unilasso_loo_false_support, lasso_cv_support),
    names_to = c("method", ".value"),
    names_pattern = "(unilasso_loo_true|unilasso_loo_false|lasso_cv)_(mse|support)"
  )

# Order datasets for consistent facetting
plot_long$dataset <- factor(plot_long$dataset, levels = sort(unique(plot_long$dataset)))

library(ggh4x)

# MSE boxplot: 5 per row, 4 rows (20 panels, but have 17 datasets)
p_mse <- ggplot(plot_long, aes(x = method, y = mse, fill = method)) +
  geom_boxplot() +
  ggh4x::facet_wrap2(~ dataset, nrow = 4, ncol = 5, scales = "free_y", axes = "x") +
  labs(
    title = "MSE Distribution by Method for Each Dataset Using 100 Random Train/Test (80/20) Splits",
    x = "Method",
    y = "MSE",
    fill = "Method"
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 12),  # increase tick label font size
    axis.title.x = element_text(size = 18),  # x-axis title font size
    axis.title.y = element_text(size = 18),  # y-axis title font size
    legend.position = "bottom",
    legend.text = element_text(size = 18),
    legend.title = element_text(size = 18)
  )

print(p_mse)

p_support <- ggplot(plot_long, aes(x = method, y = support, fill = method)) +
  geom_boxplot() +
  ggh4x::facet_wrap2(~ dataset, nrow = 4, ncol = 5, scales = "free_y", axes = "x") +
  labs(
    title = "Support Distribution by Method for Each Dataset Using 100 Random Train/Test (80/20) Splits",
    x = "Method",
    y = "Support",
    fill = "Method"
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 12),  # increase tick label font size
    axis.title.x = element_text(size = 18),
    axis.title.y = element_text(size = 18),
    legend.position = "bottom",
    legend.text = element_text(size = 18),
    legend.title = element_text(size = 18)
  )

print(p_support)

```

```{r load results: comparing unilasso and polish unilasso with loo=TRUE with 80/20 train/test splits}
# read csv file
results_all_splits <- read.csv("unilasso_17datasets_100splits_train80percent.csv")


# using results_all_splits data frame to graph boxplot of MSE on the left and boxplot of support on the right for each dataset 
library(ggplot2)
library(tidyr)
library(dplyr)

# Reshape data for plotting
plot_long <- results_all_splits %>%
  select(dataset, unilasso_loo_true_mse, polish_unilasso_mse, lasso_cv_mse,
         unilasso_loo_true_support, polish_unilasso_support, lasso_cv_support) %>%
  pivot_longer(
    cols = c(unilasso_loo_true_mse, polish_unilasso_mse, lasso_cv_mse,
             unilasso_loo_true_support, polish_unilasso_support, lasso_cv_support),
    names_to = c("method", ".value"),
    names_pattern = "(unilasso_loo_true|polish_unilasso|lasso_cv)_(mse|support)"
  )


# Order datasets for consistent facetting
plot_long$dataset <- factor(plot_long$dataset, levels = sort(unique(plot_long$dataset)))
# rename unilasso_loo_true to unilasso
plot_long$method <- recode(plot_long$method, unilasso_loo_true = "uniLasso", polish_unilasso = "uniLasso_polish", lasso_cv = "lasso_cv")

library(ggh4x)

# MSE boxplot: 5 per row, 4 rows (20 panels, but you have 17 datasets)
p_mse <- ggplot(plot_long, aes(x = method, y = mse, fill = method)) +
  geom_boxplot() +
  ggh4x::facet_wrap2(~ dataset, nrow = 4, ncol = 5, scales = "free_y", axes = "x") +
  labs(
    title = "MSE Distribution by Method for Each Dataset Using 100 Random Train/Test (80/20) Splits",
    x = "Method",
    y = "MSE",
    fill = "Method"
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 12),  # increase tick label font size
    axis.title.x = element_text(size = 18),  # x-axis title font size
    axis.title.y = element_text(size = 18),  # y-axis title font size
    legend.position = "bottom",
    legend.text = element_text(size = 18),
    legend.title = element_text(size = 18)
  )

print(p_mse)

p_support <- ggplot(plot_long, aes(x = method, y = support, fill = method)) +
  geom_boxplot() +
  ggh4x::facet_wrap2(~ dataset, nrow = 4, ncol = 5, scales = "free_y", axes = "x") +
  labs(
    title = "Support Distribution by Method for Each Dataset Using 100 Random Train/Test (80/20) Splits",
    x = "Method",
    y = "Support",
    fill = "Method"
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 12),  # increase tick label font size
    axis.title.x = element_text(size = 18),
    axis.title.y = element_text(size = 18),
    legend.position = "bottom",
    legend.text = element_text(size = 18),
    legend.title = element_text(size = 18)
  )

print(p_support)

```

# train/test split 2/3-1/3
```{r load results: comparing unilasso and polish unilasso with loo=TRUE with 2/3-1/3 train/test splits}
# read csv file
results_all_splits <- read.csv("unilasso_17datasets_100splits_train67percent_all_results_parallel.csv")


# using results_all_splits data frame to graph boxplot of MSE on the left and boxplot of support on the right for each dataset 
library(ggplot2)
library(tidyr)
library(dplyr)

# Reshape data for plotting
plot_long <- results_all_splits %>%
  select(dataset, unilasso_loo_true_mse, polish_unilasso_mse, lasso_cv_mse,
         unilasso_loo_true_support, polish_unilasso_support, lasso_cv_support) %>%
  pivot_longer(
    cols = c(unilasso_loo_true_mse, polish_unilasso_mse, lasso_cv_mse,
             unilasso_loo_true_support, polish_unilasso_support, lasso_cv_support),
    names_to = c("method", ".value"),
    names_pattern = "(unilasso_loo_true|polish_unilasso|lasso_cv)_(mse|support)"
  )

# Order datasets for consistent facetting
plot_long$dataset <- factor(plot_long$dataset, levels = sort(unique(plot_long$dataset)))
# rename unilasso_loo_true to unilasso
plot_long$method <- recode(plot_long$method, unilasso_loo_true = "uniLasso", polish_unilasso = "uniLasso_polish", lasso_cv = "lasso_cv")

library(ggh4x)

# MSE boxplot: 5 per row, 4 rows (20 panels, but you have 17 datasets)
p_mse <- ggplot(plot_long, aes(x = method, y = mse, fill = method)) +
  geom_boxplot() +
  ggh4x::facet_wrap2(~ dataset, nrow = 4, ncol = 5, scales = "free_y", axes = "x") +
  labs(
    title = "MSE Distribution by Method for Each Dataset Using 100 Random Train/Test (67/33) Splits",
    x = "Method",
    y = "MSE",
    fill = "Method"
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 12),  # increase tick label font size
    axis.title.x = element_text(size = 18),  # x-axis title font size
    axis.title.y = element_text(size = 18),  # y-axis title font size
    legend.position = "bottom",
    legend.text = element_text(size = 18),
    legend.title = element_text(size = 18)
  )

print(p_mse)

p_support <- ggplot(plot_long, aes(x = method, y = support, fill = method)) +
  geom_boxplot() +
  ggh4x::facet_wrap2(~ dataset, nrow = 4, ncol = 5, scales = "free_y", axes = "x") +
  labs(
    title = "Support Distribution by Method for Each Dataset Using 100 Random Train/Test (67/33) Splits",
    x = "Method",
    y = "Support",
    fill = "Method"
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 12),  # increase tick label font size
    axis.title.x = element_text(size = 18),
    axis.title.y = element_text(size = 18),
    legend.position = "bottom",
    legend.text = element_text(size = 18),
    legend.title = element_text(size = 18)
  )

print(p_support)

```



```{r load results graph: comparing loo=TRUE vs loo=FALSE with 2/3-1/3 train/test splits}
# read csv file
results_all_splits <- read.csv("unilasso_17datasets_100splits_train67percent_all_results_parallel.csv")
library(dplyr)

summary_by_dataset <- results_all_splits %>%
  group_by(dataset) %>%
  summarise(
    unilasso_loo_true_mean_mse = mean(unilasso_loo_true_mse, na.rm = TRUE),
    unilasso_loo_true_sd_mse   = sd(unilasso_loo_true_mse,   na.rm = TRUE),
    unilasso_loo_false_mean_mse = mean(unilasso_loo_false_mse, na.rm = TRUE),
    unilasso_loo_false_sd_mse   = sd(unilasso_loo_false_mse,   na.rm = TRUE),
    polish_unilasso_mean_mse = mean(polish_unilasso_mse, na.rm = TRUE),
    polish_unilasso_sd_mse   = sd(polish_unilasso_mse,   na.rm = TRUE),
    lasso_cv_mean_mse = mean(lasso_cv_mse, na.rm = TRUE),
    lasso_cv_sd_mse   = sd(lasso_cv_mse,   na.rm = TRUE),

    unilasso_loo_true_mean_support = mean(unilasso_loo_true_support, na.rm = TRUE),
    unilasso_loo_true_sd_support   = sd(unilasso_loo_true_support,   na.rm = TRUE),
    unilasso_loo_false_mean_support = mean(unilasso_loo_false_support, na.rm = TRUE),
    unilasso_loo_false_sd_support   = sd(unilasso_loo_false_support,   na.rm = TRUE),
    polish_unilasso_mean_support = mean(polish_unilasso_support, na.rm = TRUE),
    polish_unilasso_sd_support   = sd(polish_unilasso_support,   na.rm = TRUE),
    lasso_cv_mean_support = mean(lasso_cv_support, na.rm = TRUE),
    lasso_cv_sd_support   = sd(lasso_cv_support,   na.rm = TRUE),
    .groups = "drop"
  )

# using results_all_splits data frame to graph boxplot of MSE on the left and boxplot of support on the right for each dataset 
library(ggplot2)
library(tidyr)
library(dplyr)

# Reshape data for plotting
plot_long <- results_all_splits %>%
  select(dataset, unilasso_loo_true_mse, unilasso_loo_false_mse, lasso_cv_mse,
         unilasso_loo_true_support, unilasso_loo_false_support, lasso_cv_support) %>%
  pivot_longer(
    cols = c(unilasso_loo_true_mse, unilasso_loo_false_mse, lasso_cv_mse,
            unilasso_loo_true_support, unilasso_loo_false_support, lasso_cv_support),
    names_to = c("method", ".value"),
    names_pattern = "(unilasso_loo_true|unilasso_loo_false|lasso_cv)_(mse|support)"
  )

# Order datasets for consistent facetting
plot_long$dataset <- factor(plot_long$dataset, levels = sort(unique(plot_long$dataset)))

library(ggh4x)

# MSE boxplot: 5 per row, 4 rows (20 panels, but have 17 datasets)
p_mse <- ggplot(plot_long, aes(x = method, y = mse, fill = method)) +
  geom_boxplot() +
  ggh4x::facet_wrap2(~ dataset, nrow = 4, ncol = 5, scales = "free_y", axes = "x") +
  labs(
    title = "MSE Distribution by Method for Each Dataset Using 100 Random Train/Test (67/33) Splits",
    x = "Method",
    y = "MSE",
    fill = "Method"
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 12),  # increase tick label font size
    axis.title.x = element_text(size = 18),  # x-axis title font size
    axis.title.y = element_text(size = 18),  # y-axis title font size
    legend.position = "bottom",
    legend.text = element_text(size = 18),
    legend.title = element_text(size = 18)
  )

print(p_mse)

p_support <- ggplot(plot_long, aes(x = method, y = support, fill = method)) +
  geom_boxplot() +
  ggh4x::facet_wrap2(~ dataset, nrow = 4, ncol = 5, scales = "free_y", axes = "x") +
  labs(
    title = "Support Distribution by Method for Each Dataset Using 100 Random Train/Test (67/33) Splits",
    x = "Method",
    y = "Support",
    fill = "Method"
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 12),  # increase tick label font size
    axis.title.x = element_text(size = 18),
    axis.title.y = element_text(size = 18),
    legend.position = "bottom",
    legend.text = element_text(size = 18),
    legend.title = element_text(size = 18)
  )

print(p_support)

```

# 50-50 split results
```{r load results: comparing unilasso and polish unilasso with loo=TRUE with 50-50 train/test splits}
# read csv file
results_all_splits <- read.csv("unilasso_17datasets_100splits_train50percent_all_results_parallel.csv")


# using results_all_splits data frame to graph boxplot of MSE on the left and boxplot of support on the right for each dataset 
library(ggplot2)
library(tidyr)
library(dplyr)

# Reshape data for plotting
plot_long <- results_all_splits %>%
  select(dataset, unilasso_loo_true_mse, polish_unilasso_mse, lasso_cv_mse,
         unilasso_loo_true_support, polish_unilasso_support, lasso_cv_support) %>%
  pivot_longer(
    cols = c(unilasso_loo_true_mse, polish_unilasso_mse, lasso_cv_mse,
             unilasso_loo_true_support, polish_unilasso_support, lasso_cv_support),
    names_to = c("method", ".value"),
    names_pattern = "(unilasso_loo_true|polish_unilasso|lasso_cv)_(mse|support)"
  )

# Order datasets for consistent facetting
plot_long$dataset <- factor(plot_long$dataset, levels = sort(unique(plot_long$dataset)))
# rename unilasso_loo_true to unilasso
plot_long$method <- recode(plot_long$method, unilasso_loo_true = "uniLasso", polish_unilasso = "uniLasso_polish", lasso_cv = "lasso_cv")

library(ggh4x)

# MSE boxplot: 5 per row, 4 rows (20 panels, but you have 17 datasets)
p_mse <- ggplot(plot_long, aes(x = method, y = mse, fill = method)) +
  geom_boxplot() +
  ggh4x::facet_wrap2(~ dataset, nrow = 4, ncol = 5, scales = "free_y", axes = "x") +
  labs(
    title = "MSE Distribution by Method for Each Dataset Using 100 Random Train/Test (50/50) Splits",
    x = "Method",
    y = "MSE",
    fill = "Method"
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 12),  # increase tick label font size
    axis.title.x = element_text(size = 18),  # x-axis title font size
    axis.title.y = element_text(size = 18),  # y-axis title font size
    legend.position = "bottom",
    legend.text = element_text(size = 18),
    legend.title = element_text(size = 18)
  )

print(p_mse)

p_support <- ggplot(plot_long, aes(x = method, y = support, fill = method)) +
  geom_boxplot() +
  ggh4x::facet_wrap2(~ dataset, nrow = 4, ncol = 5, scales = "free_y", axes = "x") +
  labs(
    title = "Support Distribution by Method for Each Dataset Using 100 Random Train/Test (50/50) Splits",
    x = "Method",
    y = "Support",
    fill = "Method"
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 12),  # increase tick label font size
    axis.title.x = element_text(size = 18),
    axis.title.y = element_text(size = 18),
    legend.position = "bottom",
    legend.text = element_text(size = 18),
    legend.title = element_text(size = 18)
  )

print(p_support)



```

```{r load results graph: comparing loo=TRUE vs loo=FALSE with 50-50 train/test splits}
# read csv file
results_all_splits <- read.csv("unilasso_17datasets_100splits_train50percent_all_results_parallel.csv")
library(dplyr)

summary_by_dataset <- results_all_splits %>%
  group_by(dataset) %>%
  summarise(
    unilasso_loo_true_mean_mse = mean(unilasso_loo_true_mse, na.rm = TRUE),
    unilasso_loo_true_sd_mse   = sd(unilasso_loo_true_mse,   na.rm = TRUE),
    unilasso_loo_false_mean_mse = mean(unilasso_loo_false_mse, na.rm = TRUE),
    unilasso_loo_false_sd_mse   = sd(unilasso_loo_false_mse,   na.rm = TRUE),
    polish_unilasso_mean_mse = mean(polish_unilasso_mse, na.rm = TRUE),
    polish_unilasso_sd_mse   = sd(polish_unilasso_mse,   na.rm = TRUE),
    lasso_cv_mean_mse = mean(lasso_cv_mse, na.rm = TRUE),
    lasso_cv_sd_mse   = sd(lasso_cv_mse,   na.rm = TRUE),

    unilasso_loo_true_mean_support = mean(unilasso_loo_true_support, na.rm = TRUE),
    unilasso_loo_true_sd_support   = sd(unilasso_loo_true_support,   na.rm = TRUE),
    unilasso_loo_false_mean_support = mean(unilasso_loo_false_support, na.rm = TRUE),
    unilasso_loo_false_sd_support   = sd(unilasso_loo_false_support,   na.rm = TRUE),
    polish_unilasso_mean_support = mean(polish_unilasso_support, na.rm = TRUE),
    polish_unilasso_sd_support   = sd(polish_unilasso_support,   na.rm = TRUE),
    lasso_cv_mean_support = mean(lasso_cv_support, na.rm = TRUE),
    lasso_cv_sd_support   = sd(lasso_cv_support,   na.rm = TRUE),
    .groups = "drop"
  )

# using results_all_splits data frame to graph boxplot of MSE on the left and boxplot of support on the right for each dataset 
library(ggplot2)
library(tidyr)
library(dplyr)

# Reshape data for plotting
plot_long <- results_all_splits %>%
  select(dataset, unilasso_loo_true_mse, unilasso_loo_false_mse, lasso_cv_mse,
         unilasso_loo_true_support, unilasso_loo_false_support, lasso_cv_support) %>%
  pivot_longer(
    cols = c(unilasso_loo_true_mse, unilasso_loo_false_mse, lasso_cv_mse,
            unilasso_loo_true_support, unilasso_loo_false_support, lasso_cv_support),
    names_to = c("method", ".value"),
    names_pattern = "(unilasso_loo_true|unilasso_loo_false|lasso_cv)_(mse|support)"
  )

# Order datasets for consistent facetting
plot_long$dataset <- factor(plot_long$dataset, levels = sort(unique(plot_long$dataset)))

library(ggh4x)

# MSE boxplot: 5 per row, 4 rows (20 panels, but have 17 datasets)
p_mse <- ggplot(plot_long, aes(x = method, y = mse, fill = method)) +
  geom_boxplot() +
  ggh4x::facet_wrap2(~ dataset, nrow = 4, ncol = 5, scales = "free_y", axes = "x") +
  labs(
    title = "MSE Distribution by Method for Each Dataset Using 100 Random Train/Test (50/50) Splits",
    x = "Method",
    y = "MSE",
    fill = "Method"
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 12),  # increase tick label font size
    axis.title.x = element_text(size = 18),  # x-axis title font size
    axis.title.y = element_text(size = 18),  # y-axis title font size
    legend.position = "bottom",
    legend.text = element_text(size = 18),
    legend.title = element_text(size = 18)
  )

print(p_mse)

p_support <- ggplot(plot_long, aes(x = method, y = support, fill = method)) +
  geom_boxplot() +
  ggh4x::facet_wrap2(~ dataset, nrow = 4, ncol = 5, scales = "free_y", axes = "x") +
  labs(
    title = "Support Distribution by Method for Each Dataset Using 100 Random Train/Test (50/50) Splits",
    x = "Method",
    y = "Support",
    fill = "Method"
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 12),  # increase tick label font size
    axis.title.x = element_text(size = 18),
    axis.title.y = element_text(size = 18),
    legend.position = "bottom",
    legend.text = element_text(size = 18),
    legend.title = element_text(size = 18)
  )

print(p_support)

```


# updated 50-50 random split results with 100 different splits 9/15 Friday for 12 datasets
```{r load results}
# read csv file
results_all_splits <- read.csv("/accounts/grad/aqwang/unilasso/analysis/random_split_result/unilasso_12datasets_100splits_train50percentresults.csv")


# using results_all_splits data frame to graph boxplot of MSE on the left and boxplot of support on the right for each dataset 
library(ggplot2)
library(tidyr)
library(dplyr)

# Reshape data for plotting
plot_long <- results_all_splits %>%
  select(dataset, unilasso_loo_true_mse, polish_unilasso_mse, lasso_cv_mse, unireg_mse, least_squares_mse,
         unilasso_loo_true_support, polish_unilasso_support, lasso_cv_support,unireg_support, least_squares_support,
         unilasso_loo_true_sign_diff, polish_unilasso_sign_diff,lasso_cv_sign_diff,unireg_sign_diff, least_squares_sign_diff) %>%
  pivot_longer(
    cols = c(unilasso_loo_true_mse, polish_unilasso_mse, lasso_cv_mse, unireg_mse, least_squares_mse,
             unilasso_loo_true_support, polish_unilasso_support, lasso_cv_support, unireg_support, least_squares_support,
             unilasso_loo_true_sign_diff, polish_unilasso_sign_diff, lasso_cv_sign_diff, unireg_sign_diff, least_squares_sign_diff),
    names_to = c("method", ".value"),
    names_pattern = "(unilasso_loo_true|polish_unilasso|lasso_cv|unireg|least_squares)_(mse|support|sign_diff)"
  )

# Order datasets for consistent facetting
desired_order <- c(
  "ca_housing", "debutanizer", "insurance", "kin8nm", 
  "computer", "elevator", "energy_efficiency", "miami_housing", "naval_propulsion",
  "diamond", "protein_structure", "qsar"
)


plot_long$dataset <- factor(plot_long$dataset, levels = desired_order)

# rename unilasso_loo_true to unilasso
plot_long$method <- recode(plot_long$method, unilasso_loo_true = "uniLasso", polish_unilasso = "Polish", lasso_cv = "Lasso", unireg = "uniReg", least_squares = "LS")

# After creating plot_long and recoding the method names, add this line:
plot_long$method <- factor(plot_long$method, levels = c("LS", "Lasso", "uniReg", "uniLasso", "Polish"))

#rename all datasets to have first letter capitalized and underscores replaced with spaces
plot_long$dataset <- recode(plot_long$dataset,
                            "ca_housing" = "CA housing",
                            "debutanizer" = "Debutanizer",
                            "insurance" = "Insurance",
                            "kin8nm" = "Kin8nm",
                            "computer" = "Computer",
                            "elevator" = "Elevator",
                            "energy_efficiency" = "Energy efficiency",
                            "miami_housing" = "Miami housing",
                            "naval_propulsion" = "Naval propulsion",
                            "diamond" = "Diamond",
                            "protein_structure" = "Protein structure",
                            "qsar" = "QSAR"
)

library(ggh4x)

# MSE boxplot: 5 per row, 4 rows (20 panels, but you have 17 datasets)
# Use similar colors for Polish, uniLasso, and uniReg
method_colors <- c(
  "uniLasso" = "#e75480",      # medium pink
  "Polish" = "#f7b6d2",        # light pink
  "uniReg" = "#c71585",        # dark pink/magenta
  "Lasso" = "#1f77b4",      # medium blue
  "LS" = "#aec7e8"           # light blue
)

p_mse <- ggplot(plot_long, aes(x = method, y = mse, fill = method)) +
  geom_boxplot() +
  ggh4x::facet_wrap2(~ dataset, nrow = 3, ncol = 4, scales = "free_y", axes = "x") +
  labs(
    #title = "MSE Distribution by Method for Each Dataset Using 100 Random Train/Test (50/50) Splits",
    x = "Method",
    y = "MSE",
    fill = "Method"
  ) +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 14, family = "Times New Roman"),  # increase tick label font size
    axis.title.x = element_text(size = 18, family = "Times New Roman"),  # x-axis title font size
    axis.title.y = element_text(size = 18, family = "Times New Roman"),  # y-axis title font size
    legend.position = "bottom",
    legend.text = element_text(size = 18, family = "Times New Roman"),
    legend.title = element_text(size = 18, family = "Times New Roman"),
    strip.text = element_text(size = 18, family = "Times New Roman"),  # ADD THIS LINE - makes facet titles larger
    plot.title = element_text(size = 20, face = "bold", hjust = 0.5, family = "Times New Roman")  # ADD/MODIFY THIS LINE
  )

print(p_mse)
# save p-mse to /accounts/grad/aqwang/unilasso/figures as a png file
ggsave("/accounts/grad/aqwang/unilasso/figures/mse_dist_12data.png", plot = p_mse, width = 16, height = 17, dpi = 300)




p_support <- ggplot(plot_long, aes(x = method, y = support, fill = method)) +
  geom_boxplot() +
  ggh4x::facet_wrap2(~ dataset, nrow = 3, ncol = 4, scales = "free_y", axes = "x") +
  labs(
    #title = "Support Distribution by Method for Each Dataset Using 100 Random Train/Test (50/50) Splits",
    x = "Method",
    y = "Support",
    fill = "Method"
  ) +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 14, family = "Times New Roman"),  # increase tick label font size
    axis.title.x = element_text(size = 18, family = "Times New Roman"),  # x-axis title font size
    axis.title.y = element_text(size = 18, family = "Times New Roman"),  # y-axis title font size
    legend.position = "bottom",
    legend.text = element_text(size = 18, family = "Times New Roman"),
    legend.title = element_text(size = 18, family = "Times New Roman"),
    strip.text = element_text(size = 18, family = "Times New Roman"),  # ADD THIS LINE - makes facet titles larger
    plot.title = element_text(size = 20, face = "bold", hjust = 0.5, family = "Times New Roman")  # ADD/MODIFY THIS LINE
  )

print(p_support)
# save p-support to /accounts/grad/aqwang/unilasso/figures as a png file
ggsave("/accounts/grad/aqwang/unilasso/figures/supp_dist_12data.png", plot = p_support, width = 16, height = 17, dpi = 300)



# sign difference boxplot (# of violations)
p_sign_diff <- ggplot(plot_long, aes(x = method, y = sign_diff, fill = method)) +
  geom_boxplot() +
  ggh4x::facet_wrap2(~ dataset, nrow = 3, ncol = 4, scales = "free_y", axes = "x") +
  labs(
    #title = "Distribution of Number of Violations by Method for Each Dataset Using 100 Random Train/Test (50/50) Splits",
    x = "Method",
    y = "Number of Violations",
    fill = "Method"
  ) +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 14, family = "Times New Roman"),  # increase tick label font size
    axis.title.x = element_text(size = 18, family = "Times New Roman"),  # x-axis title font size
    axis.title.y = element_text(size = 18, family = "Times New Roman"),  # y-axis title font size
    legend.position = "bottom",
    legend.text = element_text(size = 18, family = "Times New Roman"),
    legend.title = element_text(size = 18, family = "Times New Roman"),
    strip.text = element_text(size = 18, family = "Times New Roman"),  # ADD THIS LINE - makes facet titles larger
    plot.title = element_text(size = 20, face = "bold", hjust = 0.5, family = "Times New Roman")  # ADD/MODIFY THIS LINE
  ) +
  scale_y_continuous(expand = expansion(mult = c(0.05, 0.05)))
print(p_sign_diff)

# save p-support to /accounts/grad/aqwang/unilasso/figures as a png file
ggsave("/accounts/grad/aqwang/unilasso/figures/sign_dist_12data.png", plot = p_sign_diff, width = 16, height = 17, dpi = 300)


```

# updated 50-50 random split results with 100 different splits 9/10 wednesday for 12 datasets by combining the graphs
```{R}
# Create combined long data with metric type including sign_diff
plot_combined_long <- plot_long %>%
  pivot_longer(
    cols = c(mse, support, sign_diff),
    names_to = "metric",
    values_to = "value"
  ) %>%
  mutate(
    metric = recode(metric, 
                   "mse" = "MSE", 
                   "support" = "Support",
                   "sign_diff" = "Number of violations"),
    metric = factor(metric, levels = c("MSE", "Support", "Number of violations"))
  )



library(ggh4x)

# choose first 6 datasets
plot_combined_long1 <- plot_combined_long %>%
  filter(dataset %in% c("CA housing", "Debutanizer", "Insurance", "Kin8nm", "Computer", "Elevator"))

# choose last 6 datasets
plot_combined_long2 <- plot_combined_long %>%
  filter(dataset %in% c("Energy efficiency", "Miami housing", "Naval propulsion", "Diamond", "Protein structure", "QSAR"))


p_combined_facet1 <- ggplot(plot_combined_long1, aes(x = method, y = value, fill = method)) +
  geom_boxplot() +
  facet_grid2(
    dataset ~ metric,
    switch = "y",
    scales = "free_y",     # <-- make y free
    independent = "y"      # <-- now each dataset×metric panel gets its own y-scale
  ) +
  labs(x = "Method", y = NULL, fill = "Method") +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 18, family = "Times New Roman"),
    axis.title = element_text(size = 20, family = "Times New Roman"),
    legend.position = "bottom",
    legend.text = element_text(size = 20, family = "Times New Roman"),
    legend.title = element_text(size = 20, family = "Times New Roman"),
    strip.text = element_text(size = 20, family = "Times New Roman"),
    strip.placement = "outside"
  )
print(p_combined_facet1)
# save p-support to /accounts/grad/aqwang/unilasso/figures as a png file
ggsave("/accounts/grad/aqwang/unilasso/figures/p_mse_supp_sign_12data1.png", plot = p_combined_facet1, width = 16, height = 22, dpi = 300)


p_combined_facet2 <- ggplot(plot_combined_long2, aes(x = method, y = value, fill = method)) +
  geom_boxplot() +
  facet_grid2(
    dataset ~ metric,
    switch = "y",
    scales = "free_y",     # <-- make y free
    independent = "y"      # <-- now each dataset×metric panel gets its own y-scale
  ) +
  labs(x = "Method", y = NULL, fill = "Method") +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 18, family = "Times New Roman"),
    axis.title = element_text(size = 20, family = "Times New Roman"),
    legend.position = "bottom",
    legend.text = element_text(size = 20, family = "Times New Roman"),
    legend.title = element_text(size = 20, family = "Times New Roman"),
    strip.text = element_text(size = 20, family = "Times New Roman"),
    strip.placement = "outside"
  )
print(p_combined_facet2)

# save p-support to /accounts/grad/aqwang/unilasso/figures as a png file
ggsave("/accounts/grad/aqwang/unilasso/figures/p_mse_supp_sign_12data2.png", plot = p_combined_facet2, width = 16, height = 22, dpi = 300)
```


# calculate stability for all our 12 datasets. 9/15 Monday updates
```{r load dataset names}
library(dplyr)
library(utils)  # for combn function

# Function to calculate stability for a given method - returns all pairwise values
calculate_stability_full <- function(data, method_name) {
  # Filter data for the specific method
  method_data <- data %>% filter(method == method_name)
  
  # Extract coefficient columns (starting from column 4)
  coef_matrix <- as.matrix(method_data[, 4:ncol(method_data)])
  
  # Number of models for this method
  n_models <- nrow(coef_matrix)
  
  if (n_models < 2) {
    return(c())  # Return empty vector if not enough models
  }
  
  # Generate all pairs of models (100 choose 2)
  model_pairs <- combn(1:n_models, 2, simplify = FALSE)
  
  # Calculate stability for each pair
  stability_values <- sapply(model_pairs, function(pair) {
    model_i <- pair[1]
    model_j <- pair[2]
    
    # Find selected features (non-zero coefficients) for each model. returns the indices (column numbers) where the coefficients are nonzero.
    features_i <- which(coef_matrix[model_i, ] != 0)
    features_j <- which(coef_matrix[model_j, ] != 0)
    
    # Calculate Jaccard similarity: |intersection| / |union|
    common_features <- length(intersect(features_i, features_j))
    total_unique_features <- length(union(features_i, features_j))
    
    # Handle case where both models select no features
    if (total_unique_features == 0) {
      return(1)  # Perfect stability if both select nothing
    } else {
      return(common_features / total_unique_features)
    }
  })
  
  # Return the entire vector of stability values
  return(stability_values)
}

# Get all CSV files in the coef_csv directory
coef_csv_dir <- "/accounts/grad/aqwang/unilasso/analysis/coef_csv_12datasets"
csv_files <- list.files(coef_csv_dir, pattern = "coefficients_.*\\.csv$", full.names = TRUE)

# check dataset names from file names
dataset_names <- gsub("coefficients_(.+)\\.csv", "\\1", basename(csv_files))
print(dataset_names)  # Verify dataset names

# Initialize storage for all results
all_stability_results <- data.frame(
  dataset = character(),
  method = character(),
  mean_stability = numeric(),
  sd_stability = numeric(),
  min_stability = numeric(),
  max_stability = numeric(),
  n_pairs = integer(),
  stringsAsFactors = FALSE
)

# Initialize storage for detailed results (optional - if you want all pairwise values)
all_stability_detailed <- list()

# Loop through all datasets
for (i in seq_along(csv_files)) {
  dataset_name <- dataset_names[i]
  csv_file <- csv_files[i]
  
  cat("\n", strrep("=", 60), "\n")
  cat("Processing dataset:", dataset_name, "(", i, "/", length(csv_files), ")\n")
  cat(strrep("=", 60), "\n")
  
  # Read coefficient data
  tryCatch({
    coefficients_data <- read.csv(csv_file)
    # Remove rows with method=unilasso_loo_false
    coefficients_data <- coefficients_data[coefficients_data$method != "unilasso_loo_false", ]
    coefficients_data <- coefficients_data[coefficients_data$method != "uni_loo", ]
    
    # Get unique methods in this dataset
    unique_methods <- unique(coefficients_data$method)
    cat("Found methods:", paste(unique_methods, collapse = ", "), "\n")
    
    # Calculate stability for each method in this dataset
    dataset_stability_detailed <- list()
    
    for (method in unique_methods) {
      cat("  Processing method:", method, "...")
      
      # Calculate full stability vector for this method
      stability_vector <- calculate_stability_full(coefficients_data, method)
      
      if (length(stability_vector) > 0) {
        # Clean method name
        clean_method <- recode(method,
          "unilasso_loo_true" = "uniLasso",
          "polish_unilasso" = "Polish",
          "lasso_cv" = "Lasso",
          "unireg" = "uniReg", 
          "least_squares" = "LS"
        )
        
        # Calculate summary statistics
        summary_stats <- data.frame(
          dataset = dataset_name,
          method = clean_method,
          mean_stability = mean(stability_vector, na.rm = TRUE),
          sd_stability = sd(stability_vector, na.rm = TRUE),
          min_stability = min(stability_vector, na.rm = TRUE),
          max_stability = max(stability_vector, na.rm = TRUE),
          n_pairs = length(stability_vector),
          stringsAsFactors = FALSE
        )
        
        # Add to main results dataframe
        all_stability_results <- rbind(all_stability_results, summary_stats)
        
        # Store detailed results (optional)
        dataset_stability_detailed[[clean_method]] <- stability_vector
        
        cat(" Done (", length(stability_vector), " pairs)\n")
        
      } else {
        cat(" Skipped (insufficient data)\n")
      }
    }
    
    # Store detailed results for this dataset
    all_stability_detailed[[dataset_name]] <- dataset_stability_detailed
    
    # Print summary for this dataset
    dataset_results <- all_stability_results[all_stability_results$dataset == dataset_name, ]
    if (nrow(dataset_results) > 0) {
      cat("\nSummary for", dataset_name, ":\n")
      for (j in 1:nrow(dataset_results)) {
        row <- dataset_results[j, ]
        cat(sprintf("  %-10s: Mean = %.3f (SD = %.3f) Range = [%.3f, %.3f] [%d pairs]\n",
                    row$method, row$mean_stability, row$sd_stability,
                    row$min_stability, row$max_stability, row$n_pairs))
      }
    }
    
  }, error = function(e) {
    cat("ERROR processing", dataset_name, ":", e$message, "\n")
  })
}

# Final summary
cat("\n", strrep("=", 80), "\n")
cat("STABILITY ANALYSIS COMPLETE!\n")
cat("Total datasets processed:", length(unique(all_stability_results$dataset)), "\n")
cat("Total method-dataset combinations:", nrow(all_stability_results), "\n")
cat(strrep("=", 80), "\n")

# Display overall results
print(all_stability_results)

# Save results
write.csv(all_stability_results, "stability_results_12_data_summary.csv", row.names = FALSE)
save(all_stability_results, all_stability_detailed, file = "stability_results_12_datasets.RData")




################# Graph stability boxplots #################
library(ggplot2)

# Build one long data.frame: dataset, method, stability
make_long <- function(all_stability_detailed) {
  do.call(rbind, lapply(names(all_stability_detailed), function(ds) {
    methods <- all_stability_detailed[[ds]]
    if (length(methods) == 0) return(NULL)
    do.call(rbind, lapply(names(methods), function(m) {
      v <- methods[[m]]
      v <- v[is.finite(v)]                 # drop NA/Inf if present
      if (length(v) == 0) return(NULL)
      data.frame(dataset = ds, method = m, stability = v, 
                 stringsAsFactors = FALSE)
    }))
  }))
}

plot_data <- make_long(all_stability_detailed)

# After creating plot_long and recoding the method names, add this line:
plot_data$method <- factor(plot_data$method, levels = c("LS", "Lasso", "uniReg", "uniLasso", "Polish"))

# Order datasets for consistent facetting
desired_order <- c(
  "ca_housing", "debutanizer", "insurance", "kin8nm", 
  "computer", "elevator", "energy_efficiency", "miami_housing", "naval_propulsion",
  "diamond", "protein_structure", "qsar"
)


plot_data$dataset <- factor(plot_data$dataset, levels = desired_order)

#rename all datasets to have first letter capitalized and underscores replaced with spaces
plot_data$dataset <- recode(plot_data$dataset,
                            "ca_housing" = "CA housing",
                            "debutanizer" = "Debutanizer",
                            "insurance" = "Insurance",
                            "kin8nm" = "Kin8nm",
                            "computer" = "Computer",
                            "elevator" = "Elevator",
                            "energy_efficiency" = "Energy efficiency",
                            "miami_housing" = "Miami housing",
                            "naval_propulsion" = "Naval propulsion",
                            "diamond" = "Diamond",
                            "protein_structure" = "Protein structure",
                            "qsar" = "QSAR"
)

# Order datasets for consistent facetting
plot_data$dataset <- factor(plot_data$dataset, levels = sort(unique(plot_data$dataset)))
# Use similar colors for Polish, uniLasso, and uniReg
method_colors <- c(
  "uniLasso" = "#e75480",      # medium pink
  "Polish" = "#f7b6d2",        # light pink
  "uniReg" = "#c71585",        # dark pink/magenta
  "Lasso" = "#1f77b4",      # medium blue
  "LS" = "#aec7e8"           # light blue
)


p_stability <- ggplot(plot_data, aes(x = method, y = stability, fill = method)) +
  geom_boxplot() +
  ggh4x::facet_wrap2(~ dataset, nrow = 3, ncol = 4, scales = "free_y", axes = "x") +
  labs(
    #title = "Stability Distribution by Method for Each Dataset Using 100 Random Train/Test (50/50) Splits",
    x = "Method",
    y = "Stability",
    fill = "Method"
  ) +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 14, family = "Times New Roman"),  # increase tick label font size
    axis.title.x = element_text(size = 18, family = "Times New Roman"),  # x-axis title font size
    axis.title.y = element_text(size = 18, family = "Times New Roman"),  # y-axis title font size
    legend.position = "bottom",
    legend.text = element_text(size = 18, family = "Times New Roman"),
    legend.title = element_text(size = 18, family = "Times New Roman"),
    strip.text = element_text(size = 18, family = "Times New Roman"),  # ADD THIS LINE - makes facet titles larger
    plot.title = element_text(size = 20, face = "bold", hjust = 0.5, family = "Times New Roman")  # ADD/MODIFY THIS LINE
  )

print(p_stability)

# save p-stability to /accounts/grad/aqwang/unilasso/figures as a png file
ggsave("/accounts/grad/aqwang/unilasso/figures/stability_dist_12data.png", plot = p_stability, width = 16, height = 17, dpi = 300)

```

# Final version: combine stability with mse, support, sign_diff 9/15 Monday updates
```{r combine stability with mse, support, sign_diff}

### setup####

if (R.home() != "/scratch/users/aqwang/conda/envs/r_package/lib/R") {
  system("/scratch/users/aqwang/conda/envs/r_package/bin/Rscript -e 'rmarkdown::render(\"unilasso_12data_loop_graphs.Rmd\")'")
  quit("no")
}

# check the R environment is r_package
R.home()

# set working directory
setwd("/accounts/grad/aqwang/unilasso/analysis")

# load packages 
library(uniLasso) # for unilasso 
library(glmnet) # for cv lasso 
library(dplyr)
library(tidyr)

# Define all dataset names (remove "data_" prefix)
dataset_names <- c(
  "ca_housing", "computer",
  "debutanizer", "diamond", "elevator", "energy_efficiency",
  "insurance", "kin8nm", "miami_housing", "naval_propulsion",
 "protein_structure", "qsar")

 
# Number of random splits
N_SPLITS <- 100
####################################################



###################(1)load results for mse, support, sign_diff#################
# read csv file
results_all_splits <- read.csv("/accounts/grad/aqwang/unilasso/analysis/random_split_result/unilasso_12datasets_100splits_train50percentresults.csv")


# using results_all_splits data frame to graph boxplot of MSE on the left and boxplot of support on the right for each dataset 
library(ggplot2)
library(tidyr)
library(dplyr)

# Reshape data for plotting
plot_long <- results_all_splits %>%
  select(dataset, unilasso_loo_true_mse, polish_unilasso_mse, lasso_cv_mse, unireg_mse, least_squares_mse,
         unilasso_loo_true_support, polish_unilasso_support, lasso_cv_support,unireg_support, least_squares_support,
         unilasso_loo_true_sign_diff, polish_unilasso_sign_diff,lasso_cv_sign_diff,unireg_sign_diff, least_squares_sign_diff) %>%
  pivot_longer(
    cols = c(unilasso_loo_true_mse, polish_unilasso_mse, lasso_cv_mse, unireg_mse, least_squares_mse,
             unilasso_loo_true_support, polish_unilasso_support, lasso_cv_support, unireg_support, least_squares_support,
             unilasso_loo_true_sign_diff, polish_unilasso_sign_diff, lasso_cv_sign_diff, unireg_sign_diff, least_squares_sign_diff),
    names_to = c("method", ".value"),
    names_pattern = "(unilasso_loo_true|polish_unilasso|lasso_cv|unireg|least_squares)_(mse|support|sign_diff)"
  )

# Order datasets for consistent facetting
desired_order <- c(
  "ca_housing", "debutanizer", "insurance", "kin8nm", 
  "computer", "elevator", "energy_efficiency", "miami_housing", "naval_propulsion",
  "diamond", "protein_structure", "qsar"
)


plot_long$dataset <- factor(plot_long$dataset, levels = desired_order)

# rename unilasso_loo_true to unilasso
plot_long$method <- recode(plot_long$method, unilasso_loo_true = "uniLasso", polish_unilasso = "Polish", lasso_cv = "Lasso", unireg = "uniReg", least_squares = "LS")

# After creating plot_long and recoding the method names, add this line:
plot_long$method <- factor(plot_long$method, levels = c("LS", "Lasso", "uniReg", "uniLasso", "Polish"))

#rename all datasets to have first letter capitalized and underscores replaced with spaces
plot_long$dataset <- recode(plot_long$dataset,
                            "ca_housing" = "CA housing",
                            "debutanizer" = "Debutanizer",
                            "insurance" = "Insurance",
                            "kin8nm" = "Kin8nm",
                            "computer" = "Computer",
                            "elevator" = "Elevator",
                            "energy_efficiency" = "Energy efficiency",
                            "miami_housing" = "Miami housing",
                            "naval_propulsion" = "Naval propulsion",
                            "diamond" = "Diamond",
                            "protein_structure" = "Protein structure",
                            "qsar" = "QSAR"
)

# Create combined long data with metric type including sign_diff
plot_combined_long <- plot_long %>%
  pivot_longer(
    cols = c(mse, support, sign_diff),
    names_to = "metric",
    values_to = "value"
  ) %>%
  mutate(
    metric = recode(metric, 
                   "mse" = "MSE", 
                   "support" = "Support",
                   "sign_diff" = "Number of violations"),
    metric = factor(metric, levels = c("MSE", "Support", "Number of violations"))
  )


#########################################################


###################(2)calculate stability for all our 12 datasets. 9/19 Friday updates#################
library(dplyr)
library(utils)  # for combn function

# Function to calculate stability for a given method - returns all pairwise values
calculate_stability_full <- function(data, method_name) {
  # Filter data for the specific method
  method_data <- data %>% filter(method == method_name)
  
  # Extract coefficient columns (starting from column 4)
  coef_matrix <- as.matrix(method_data[, 4:ncol(method_data)])
  
  # Number of models for this method
  n_models <- nrow(coef_matrix)
  
  if (n_models < 2) {
    return(c())  # Return empty vector if not enough models
  }
  
  # Generate all pairs of models (100 choose 2)
  model_pairs <- combn(1:n_models, 2, simplify = FALSE)
  
  # Calculate stability for each pair
  stability_values <- sapply(model_pairs, function(pair) {
    model_i <- pair[1]
    model_j <- pair[2]
    
    # Find selected features (non-zero coefficients) for each model. returns the indices (column numbers) where the coefficients are nonzero.
    features_i <- which(coef_matrix[model_i, ] != 0)
    features_j <- which(coef_matrix[model_j, ] != 0)
    
    # Calculate Jaccard similarity: |intersection| / |union|
    common_features <- length(intersect(features_i, features_j))
    total_unique_features <- length(union(features_i, features_j))
    
    # Handle case where both models select no features
    if (total_unique_features == 0) {
      return(1)  # Perfect stability if both select nothing
    } else {
      return(common_features / total_unique_features)
    }
  })
  
  # Return the entire vector of stability values
  return(stability_values)
}

# Get all CSV files in the coef_csv directory
coef_csv_dir <- "/accounts/grad/aqwang/unilasso/analysis/coef_csv_12datasets_standardize_lasso"
csv_files <- list.files(coef_csv_dir, pattern = "coefficients_.*\\.csv$", full.names = TRUE)

# check dataset names from file names
dataset_names <- gsub("coefficients_(.+)\\.csv", "\\1", basename(csv_files))
print(dataset_names)  # Verify dataset names

# Initialize storage for all results
all_stability_results <- data.frame(
  dataset = character(),
  method = character(),
  mean_stability = numeric(),
  sd_stability = numeric(),
  min_stability = numeric(),
  max_stability = numeric(),
  n_pairs = integer(),
  stringsAsFactors = FALSE
)

# Initialize storage for detailed results (optional - if you want all pairwise values)
all_stability_detailed <- list()

# Loop through all datasets
for (i in seq_along(csv_files)) {
  dataset_name <- dataset_names[i]
  csv_file <- csv_files[i]
  
  cat("\n", strrep("=", 60), "\n")
  cat("Processing dataset:", dataset_name, "(", i, "/", length(csv_files), ")\n")
  cat(strrep("=", 60), "\n")
  
  # Read coefficient data
  tryCatch({
    coefficients_data <- read.csv(csv_file)
    # Remove rows with method=unilasso_loo_false
    coefficients_data <- coefficients_data[coefficients_data$method != "unilasso_loo_false", ]
    coefficients_data <- coefficients_data[coefficients_data$method != "uni_loo", ]
    
    # Get unique methods in this dataset
    unique_methods <- unique(coefficients_data$method)
    cat("Found methods:", paste(unique_methods, collapse = ", "), "\n")
    
    # Calculate stability for each method in this dataset
    dataset_stability_detailed <- list()
    
    for (method in unique_methods) {
      cat("  Processing method:", method, "...")
      
      # Calculate full stability vector for this method
      stability_vector <- calculate_stability_full(coefficients_data, method)
      
      if (length(stability_vector) > 0) {
        # Clean method name
        clean_method <- recode(method,
          "unilasso_loo_true" = "uniLasso",
          "polish_unilasso" = "Polish",
          "lasso_cv" = "Lasso",
          "unireg" = "uniReg", 
          "least_squares" = "LS"
        )
        
        # Calculate summary statistics
        summary_stats <- data.frame(
          dataset = dataset_name,
          method = clean_method,
          mean_stability = mean(stability_vector, na.rm = TRUE),
          sd_stability = sd(stability_vector, na.rm = TRUE),
          min_stability = min(stability_vector, na.rm = TRUE),
          max_stability = max(stability_vector, na.rm = TRUE),
          n_pairs = length(stability_vector),
          stringsAsFactors = FALSE
        )
        
        # Add to main results dataframe
        all_stability_results <- rbind(all_stability_results, summary_stats)
        
        # Store detailed results (optional)
        dataset_stability_detailed[[clean_method]] <- stability_vector
        
        cat(" Done (", length(stability_vector), " pairs)\n")
        
      } else {
        cat(" Skipped (insufficient data)\n")
      }
    }
    
    # Store detailed results for this dataset
    all_stability_detailed[[dataset_name]] <- dataset_stability_detailed
    
    # Print summary for this dataset
    dataset_results <- all_stability_results[all_stability_results$dataset == dataset_name, ]
    if (nrow(dataset_results) > 0) {
      cat("\nSummary for", dataset_name, ":\n")
      for (j in 1:nrow(dataset_results)) {
        row <- dataset_results[j, ]
        cat(sprintf("  %-10s: Mean = %.3f (SD = %.3f) Range = [%.3f, %.3f] [%d pairs]\n",
                    row$method, row$mean_stability, row$sd_stability,
                    row$min_stability, row$max_stability, row$n_pairs))
      }
    }
    
  }, error = function(e) {
    cat("ERROR processing", dataset_name, ":", e$message, "\n")
  })
}

# Final summary
cat("\n", strrep("=", 80), "\n")
cat("STABILITY ANALYSIS COMPLETE!\n")
cat("Total datasets processed:", length(unique(all_stability_results$dataset)), "\n")
cat("Total method-dataset combinations:", nrow(all_stability_results), "\n")
cat(strrep("=", 80), "\n")

# Display overall results
print(all_stability_results)

# Save results
write.csv(all_stability_results, "stability_results_12_data_summary.csv", row.names = FALSE)
save(all_stability_results, all_stability_detailed, file = "stability_results_12_datasets.RData")


################# prepare stability data #################
library(ggplot2)

# Build one long data.frame: dataset, method, stability
make_long <- function(all_stability_detailed) {
  do.call(rbind, lapply(names(all_stability_detailed), function(ds) {
    methods <- all_stability_detailed[[ds]]
    if (length(methods) == 0) return(NULL)
    do.call(rbind, lapply(names(methods), function(m) {
      v <- methods[[m]]
      v <- v[is.finite(v)]                 # drop NA/Inf if present
      if (length(v) == 0) return(NULL)
      data.frame(dataset = ds, method = m, stability = v, 
                 stringsAsFactors = FALSE)
    }))
  }))
}

plot_data <- make_long(all_stability_detailed)


# Order datasets for consistent facetting
desired_order <- c(
  "ca_housing", "debutanizer", "insurance", "kin8nm", 
  "computer", "elevator", "energy_efficiency", "miami_housing", "naval_propulsion",
  "diamond", "protein_structure", "qsar"
)


plot_data$dataset <- factor(plot_data$dataset, levels = desired_order)

#rename all datasets to have first letter capitalized and underscores replaced with spaces
plot_data$dataset <- recode(plot_data$dataset,
                            "ca_housing" = "CA housing",
                            "debutanizer" = "Debutanizer",
                            "insurance" = "Insurance",
                            "kin8nm" = "Kin8nm",
                            "computer" = "Computer",
                            "elevator" = "Elevator",
                            "energy_efficiency" = "Energy efficiency",
                            "miami_housing" = "Miami housing",
                            "naval_propulsion" = "Naval propulsion",
                            "diamond" = "Diamond",
                            "protein_structure" = "Protein structure",
                            "qsar" = "QSAR"
)

# Use similar colors for Polish, uniLasso, and uniReg
method_colors <- c(
  "uniLasso" = "#e75480",      # medium pink
  "Polish" = "#f7b6d2",        # light pink
  "uniReg" = "#c71585",        # dark pink/magenta
  "Lasso" = "#1f77b4",      # medium blue
  "LS" = "#aec7e8"           # light blue
)


########################(3) combine stability with mse, support, sign_diff########################
library(ggh4x)

stability_data_formatted <- plot_data %>%
  rename(value = stability) %>%
  mutate(metric = "Stability") %>%
  select(dataset, method, metric, value)


# Combine all four metrics into one dataset
plot_combined_long_with_stability <- bind_rows(
  plot_combined_long,  # This has MSE, Support, and Number of violations
  stability_data_formatted  # This adds Stability
) %>%
  mutate(
    metric = factor(metric, levels = c("MSE", "Support", "Number of violations", "Stability"))
  ) %>%
  mutate(
    method = factor(method, levels = c("LS", "Lasso", "uniReg", "uniLasso", "Polish"))
  )


# Choose first 6 datasets (now with stability included)
plot_combined_long1_with_stability <- plot_combined_long_with_stability %>%
  filter(dataset %in% c("CA housing", "Debutanizer", "Insurance", "Kin8nm", "Computer", "Elevator"))

# Choose last 6 datasets (now with stability included)
plot_combined_long2_with_stability <- plot_combined_long_with_stability %>%
  filter(dataset %in% c("Energy efficiency", "Miami housing", "Naval propulsion", "Diamond", "Protein structure", "QSAR"))

# Create the enhanced plot with 4 columns (MSE, Support, Number of violations, Stability)
p_combined_facet1_with_stability <- ggplot(plot_combined_long1_with_stability, aes(x = method, y = value, fill = method)) +
  geom_boxplot() +
  facet_grid2(
    dataset ~ metric,
    switch = "y",
    scales = "free_y",     # <-- make y free
    independent = "y"      # <-- now each dataset×metric panel gets its own y-scale
  ) +
  labs(x = "Method", y = NULL, fill = "Method") +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 18, family = "Times New Roman", face = "bold"),
    axis.text.y = element_text(size = 16, family = "Times New Roman", face = "bold"),  # ADD THIS LINE
    axis.title = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.position = "bottom",
    legend.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.title = element_text(size = 20, family = "Times New Roman", face = "bold"),
    strip.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    strip.placement = "outside",
    panel.spacing.y = unit(0.7, "cm")  # Increase vertical spacing between rows
  )

print(p_combined_facet1_with_stability)
# Save the enhanced plot
ggsave("/accounts/grad/aqwang/unilasso/figures/p_mse_supp_sign_stability_12data1.png", 
       plot = p_combined_facet1_with_stability, width = 20, height = 24, dpi = 300)



# Do the same for the second set of datasets
p_combined_facet2_with_stability <- ggplot(plot_combined_long2_with_stability, aes(x = method, y = value, fill = method)) +
  geom_boxplot() +
  facet_grid2(
    dataset ~ metric,
    switch = "y",
    scales = "free_y",     # <-- make y free
    independent = "y"      # <-- now each dataset×metric panel gets its own y-scale
  ) +
  labs(x = "Method", y = NULL, fill = "Method") +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 18, family = "Times New Roman", face = "bold"),
    axis.text.y = element_text(size = 16, family = "Times New Roman", face = "bold"),  # ADD THIS LINE
    axis.title = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.position = "bottom",
    legend.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.title = element_text(size = 20, family = "Times New Roman", face = "bold"),
    strip.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    strip.placement = "outside",
    panel.spacing.y = unit(0.7, "cm")  # Increase vertical spacing between rows
  )

print(p_combined_facet2_with_stability)

# Save the second enhanced plot
ggsave("/accounts/grad/aqwang/unilasso/figures/p_mse_supp_sign_stability_12data2.png", 
       plot = p_combined_facet2_with_stability, width = 20, height = 24, dpi = 300)

```


# updated 50-50 random split results with 100 different splits 9/15 Monday for 22 datasets (choose one target for datasets with multiple targets )
```{r load results: comparing LS, uniReg, unilasso (loo=True) and polish unilasso with loo=TRUE with 50-50 train/test splits updated}
# read csv file
results_all_splits <- read.csv("/accounts/grad/aqwang/unilasso/analysis/random_split_result/unilasso_22datasets_100splits_train50percent_results.csv")

# print the unique names in results_all_splits$dataset to verify
print(unique(results_all_splits$dataset))


# using results_all_splits data frame to graph boxplot of MSE on the left and boxplot of support on the right for each dataset 
library(ggplot2)
library(tidyr)
library(dplyr)

# Reshape data for plotting
plot_long <- results_all_splits %>%
  select(dataset, unilasso_loo_true_mse, polish_unilasso_mse, lasso_cv_mse, unireg_mse, least_squares_mse,
         unilasso_loo_true_support, polish_unilasso_support, lasso_cv_support,unireg_support, least_squares_support,
         unilasso_loo_true_sign_diff, polish_unilasso_sign_diff,lasso_cv_sign_diff,unireg_sign_diff, least_squares_sign_diff) %>%
  pivot_longer(
    cols = c(unilasso_loo_true_mse, polish_unilasso_mse, lasso_cv_mse, unireg_mse, least_squares_mse,
             unilasso_loo_true_support, polish_unilasso_support, lasso_cv_support, unireg_support, least_squares_support,
             unilasso_loo_true_sign_diff, polish_unilasso_sign_diff, lasso_cv_sign_diff, unireg_sign_diff, least_squares_sign_diff),
    names_to = c("method", ".value"),
    names_pattern = "(unilasso_loo_true|polish_unilasso|lasso_cv|unireg|least_squares)_(mse|support|sign_diff)"
  )

# Order datasets for consistent facetting
plot_long$dataset <- factor(plot_long$dataset, levels = sort(unique(plot_long$dataset)))
# rename unilasso_loo_true to unilasso
plot_long$method <- recode(plot_long$method, unilasso_loo_true = "uniLasso", polish_unilasso = "Polish", lasso_cv = "Lasso", unireg = "uniReg", least_squares = "LS")
plot_long$method <- factor(plot_long$method, levels = c("LS", "Lasso", "uniReg", "uniLasso", "Polish"))
library(ggh4x)

# MSE boxplot: 5 per row, 4 rows (20 panels, but you have 17 datasets)
# Use similar colors for Polish, uniLasso, and uniReg
method_colors <- c(
  "uniLasso" = "#e75480",      # medium pink
  "Polish" = "#f7b6d2",        # light pink
  "uniReg" = "#c71585",        # dark pink/magenta
  "Lasso" = "#1f77b4",      # medium blue
  "LS" = "#aec7e8"           # light blue
)

p_mse <- ggplot(plot_long, aes(x = method, y = mse, fill = method)) +
  geom_boxplot() +
  ggh4x::facet_wrap2(~ dataset, nrow = 5, ncol = 5, scales = "free_y", axes = "x") +
  labs(
    #title = "MSE Distribution by Method for Each Dataset Using 100 Random Train/Test (50/50) Splits",
    x = "Method",
    y = "MSE",
    fill = "Method"
  ) +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1),  # increase tick label font size
    axis.title.x = element_text(size = 20),  # x-axis title font size
    axis.title.y = element_text(size = 20),  # y-axis title font size
    legend.position = "bottom",
    legend.text = element_text(size = 20),
    legend.title = element_text(size = 20),
    text=element_text(size=15)
  )
print(p_mse)


p_support <- ggplot(plot_long, aes(x = method, y = support, fill = method)) +
  geom_boxplot() +
  ggh4x::facet_wrap2(~ dataset, nrow = 4, ncol = 5, scales = "free_y", axes = "x") +
  labs(
    title = "Support Distribution by Method for Each Dataset Using 100 Random Train/Test (50/50) Splits",
    x = "Method",
    y = "Support",
    fill = "Method"
  ) +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 12),
    axis.title.x = element_text(size = 18),
    axis.title.y = element_text(size = 18),
    legend.position = "bottom",
    legend.text = element_text(size = 18),
    legend.title = element_text(size = 18),
    strip.text = element_text(size = 15)  # ADD THIS LINE
  )

print(p_support)


# sign difference boxplot (# of violations)
p_sign_diff <- ggplot(plot_long, aes(x = method, y = sign_diff, fill = method)) +
  geom_boxplot() +
  ggh4x::facet_wrap2(~ dataset, nrow = 4, ncol = 5, scales = "free_y", axes = "x") +
  labs(
    title = "Distribution of Number of Violations by Method for Each Dataset Using 100 Random Train/Test (50/50) Splits",
    x = "Method",
    y = "Number of Violations",
    fill = "Method"
  ) +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 12),
    axis.title.x = element_text(size = 18),
    axis.title.y = element_text(size = 18),
    legend.position = "bottom",
    legend.text = element_text(size = 18),
    legend.title = element_text(size = 18),
    strip.text = element_text(size = 15)  # ADD THIS LINE
  ) +
  scale_y_continuous(expand = expansion(mult = c(0.05, 0.05)))
print(p_sign_diff)

```


# Final version for 22 datasets 
```{r}
####################load results: comparing LS, uniReg, unilasso (loo=True) and polish unilasso with loo=TRUE with 50-50 train/test splits updated for 22 datasets (choose one target for datasets with multiple targets )####################
results_all_splits <- read.csv("/accounts/grad/aqwang/unilasso/analysis/random_split_result/unilasso_22datasets_100splits_train50percent_results.csv")

# print the unique names in results_all_splits$dataset to verify
print(unique(results_all_splits$dataset))


# using results_all_splits data frame to graph boxplot of MSE on the left and boxplot of support on the right for each dataset 
library(ggplot2)
library(tidyr)
library(dplyr)

# Reshape data for plotting
plot_long <- results_all_splits %>%
  select(dataset, unilasso_loo_true_mse, polish_unilasso_mse, lasso_cv_mse, unireg_mse, least_squares_mse,
         unilasso_loo_true_support, polish_unilasso_support, lasso_cv_support,unireg_support, least_squares_support,
         unilasso_loo_true_sign_diff, polish_unilasso_sign_diff,lasso_cv_sign_diff,unireg_sign_diff, least_squares_sign_diff) %>%
  pivot_longer(
    cols = c(unilasso_loo_true_mse, polish_unilasso_mse, lasso_cv_mse, unireg_mse, least_squares_mse,
             unilasso_loo_true_support, polish_unilasso_support, lasso_cv_support, unireg_support, least_squares_support,
             unilasso_loo_true_sign_diff, polish_unilasso_sign_diff, lasso_cv_sign_diff, unireg_sign_diff, least_squares_sign_diff),
    names_to = c("method", ".value"),
    names_pattern = "(unilasso_loo_true|polish_unilasso|lasso_cv|unireg|least_squares)_(mse|support|sign_diff)"
  )

# Order datasets for consistent facetting
plot_long$dataset <- factor(plot_long$dataset, levels = sort(unique(plot_long$dataset)))
# rename unilasso_loo_true to unilasso
plot_long$method <- recode(plot_long$method, unilasso_loo_true = "uniLasso", polish_unilasso = "Polish", lasso_cv = "Lasso", unireg = "uniReg", least_squares = "LS")
plot_long$method <- factor(plot_long$method, levels = c("LS", "Lasso", "uniReg", "uniLasso", "Polish"))


dataset_names <- c(
  "airfoil", "appliances_energy", "auto_mpg", "automobile", "beijing_pm2.5",
  "bike_sharing", "concrete", "crime", "crime_unnormalized", "daily_demand", "facebook_metrics", "forest_fires", "infrared_thermo_temp",
   "liver_disorders", "metro_traffic", "parkinsons", "power_consumption", "power_plant", "real_estate",
  "servo", "stock_portfolio", "superconductivity")

# rename all daasets to have first letter capitalized and underscores replaced with spaces
plot_long$dataset <- recode(plot_long$dataset,
                            "airfoil" = "Airfoil",
                            "appliances_energy" = "Appliances energy",
                            "auto_mpg" = "Auto MPG",
                            "automobile" = "Automobile",
                            "beijing_pm2.5" = "Beijing PM2.5",
                            "bike_sharing" = "Bike sharing",
                            "concrete" = "Concrete",
                            "crime" = "Crime",
                            "crime_unnormalized" = "Crime unnormalized",
                            "daily_demand" = "Daily demand",
                            "facebook_metrics" = "Facebook metrics",
                            "forest_fires" = "Forest fires",
                            "infrared_thermo_temp" = "Infrared thermo temp",
                            "liver_disorders" = "Liver disorders",
                            "metro_traffic" = "Metro traffic",
                            "parkinsons" = "Parkinsons",
                            "power_consumption" = "Power consumption",
                            "power_plant" = "Power plant",
                            "real_estate" = "Real estate",
                            "servo" = "Servo",
                            "stock_portfolio" = "Stock portfolio",
                            "superconductivity" = "Superconductivity"
)

plot_combined_long <- plot_long %>%
  pivot_longer(
    cols = c(mse, support, sign_diff),
    names_to = "metric",
    values_to = "value"
  ) %>%
  mutate(
    metric = recode(metric, 
                   "mse" = "MSE", 
                   "support" = "Support",
                   "sign_diff" = "Number of violations"),
    metric = factor(metric, levels = c("MSE", "Support", "Number of violations"))
  )

######################################2)calculate stabilty using all coeffcients 
library(dplyr)
library(utils)  # for combn function

# Function to calculate stability for a given method - returns all pairwise values
calculate_stability_full <- function(data, method_name) {
  # Filter data for the specific method
  method_data <- data %>% filter(method == method_name)
  
  # Extract coefficient columns (starting from column 4)
  coef_matrix <- as.matrix(method_data[, 4:ncol(method_data)])
  
  # Number of models for this method
  n_models <- nrow(coef_matrix)
  
  if (n_models < 2) {
    return(c())  # Return empty vector if not enough models
  }
  
  # Generate all pairs of models (100 choose 2)
  model_pairs <- combn(1:n_models, 2, simplify = FALSE)
  
  # Calculate stability for each pair
  stability_values <- sapply(model_pairs, function(pair) {
    model_i <- pair[1]
    model_j <- pair[2]
    
    # Find selected features (non-zero coefficients) for each model. returns the indices (column numbers) where the coefficients are nonzero.
    features_i <- which(coef_matrix[model_i, ] != 0)
    features_j <- which(coef_matrix[model_j, ] != 0)
    
    # Calculate Jaccard similarity: |intersection| / |union|
    common_features <- length(intersect(features_i, features_j))
    total_unique_features <- length(union(features_i, features_j))
    
    # Handle case where both models select no features
    if (total_unique_features == 0) {
      return(1)  # Perfect stability if both select nothing
    } else {
      return(common_features / total_unique_features)
    }
  })
  
  # Return the entire vector of stability values
  return(stability_values)
}

# Get all CSV files in the coef_csv directory
coef_csv_dir <- "/accounts/grad/aqwang/unilasso/analysis/coef_csv_22datasets"
csv_files <- list.files(coef_csv_dir, pattern = "coefficients_.*\\.csv$", full.names = TRUE)

# check dataset names from file names
dataset_names <- gsub("coefficients_(.+)\\.csv", "\\1", basename(csv_files))
print(dataset_names)  # Verify dataset names

# Initialize storage for all results
all_stability_results <- data.frame(
  dataset = character(),
  method = character(),
  mean_stability = numeric(),
  sd_stability = numeric(),
  min_stability = numeric(),
  max_stability = numeric(),
  n_pairs = integer(),
  stringsAsFactors = FALSE
)

# Initialize storage for detailed results (optional - if you want all pairwise values)
all_stability_detailed <- list()

# Loop through all datasets
for (i in seq_along(csv_files)) {
  dataset_name <- dataset_names[i]
  csv_file <- csv_files[i]
  
  cat("\n", strrep("=", 60), "\n")
  cat("Processing dataset:", dataset_name, "(", i, "/", length(csv_files), ")\n")
  cat(strrep("=", 60), "\n")
  
  # Read coefficient data
  tryCatch({
    coefficients_data <- read.csv(csv_file)
    # Remove rows with method=unilasso_loo_false
    coefficients_data <- coefficients_data[coefficients_data$method != "unilasso_loo_false", ]
    coefficients_data <- coefficients_data[coefficients_data$method != "uni_loo", ]
    
    # Get unique methods in this dataset
    unique_methods <- unique(coefficients_data$method)
    cat("Found methods:", paste(unique_methods, collapse = ", "), "\n")
    
    # Calculate stability for each method in this dataset
    dataset_stability_detailed <- list()
    
    for (method in unique_methods) {
      cat("  Processing method:", method, "...")
      
      # Calculate full stability vector for this method
      stability_vector <- calculate_stability_full(coefficients_data, method)
      
      if (length(stability_vector) > 0) {
        # Clean method name
        clean_method <- recode(method,
          "unilasso_loo_true" = "uniLasso",
          "polish_unilasso" = "Polish",
          "lasso_cv" = "Lasso",
          "unireg" = "uniReg", 
          "least_squares" = "LS"
        )
        
        # Calculate summary statistics
        summary_stats <- data.frame(
          dataset = dataset_name,
          method = clean_method,
          mean_stability = mean(stability_vector, na.rm = TRUE),
          sd_stability = sd(stability_vector, na.rm = TRUE),
          min_stability = min(stability_vector, na.rm = TRUE),
          max_stability = max(stability_vector, na.rm = TRUE),
          n_pairs = length(stability_vector),
          stringsAsFactors = FALSE
        )
        
        # Add to main results dataframe
        all_stability_results <- rbind(all_stability_results, summary_stats)
        
        # Store detailed results (optional)
        dataset_stability_detailed[[clean_method]] <- stability_vector
        
        cat(" Done (", length(stability_vector), " pairs)\n")
        
      } else {
        cat(" Skipped (insufficient data)\n")
      }
    }
    
    # Store detailed results for this dataset
    all_stability_detailed[[dataset_name]] <- dataset_stability_detailed
    
    # Print summary for this dataset
    dataset_results <- all_stability_results[all_stability_results$dataset == dataset_name, ]
    if (nrow(dataset_results) > 0) {
      cat("\nSummary for", dataset_name, ":\n")
      for (j in 1:nrow(dataset_results)) {
        row <- dataset_results[j, ]
        cat(sprintf("  %-10s: Mean = %.3f (SD = %.3f) Range = [%.3f, %.3f] [%d pairs]\n",
                    row$method, row$mean_stability, row$sd_stability,
                    row$min_stability, row$max_stability, row$n_pairs))
      }
    }
    
  }, error = function(e) {
    cat("ERROR processing", dataset_name, ":", e$message, "\n")
  })
}

# Final summary
cat("\n", strrep("=", 80), "\n")
cat("STABILITY ANALYSIS COMPLETE!\n")
cat("Total datasets processed:", length(unique(all_stability_results$dataset)), "\n")
cat("Total method-dataset combinations:", nrow(all_stability_results), "\n")
cat(strrep("=", 80), "\n")

# Display overall results
print(all_stability_results)

# Save results
write.csv(all_stability_results, "stability_results_22_data_summary.csv", row.names = FALSE)
save(all_stability_results, all_stability_detailed, file = "stability_results_22_datasets.RData")


################# prepare stability data #################
library(ggplot2)

# Build one long data.frame: dataset, method, stability
make_long <- function(all_stability_detailed) {
  do.call(rbind, lapply(names(all_stability_detailed), function(ds) {
    methods <- all_stability_detailed[[ds]]
    if (length(methods) == 0) return(NULL)
    do.call(rbind, lapply(names(methods), function(m) {
      v <- methods[[m]]
      v <- v[is.finite(v)]                 # drop NA/Inf if present
      if (length(v) == 0) return(NULL)
      data.frame(dataset = ds, method = m, stability = v, 
                 stringsAsFactors = FALSE)
    }))
  }))
}

plot_data <- make_long(all_stability_detailed)

plot_data$dataset <- factor(plot_data$dataset, levels = sort(unique(plot_data$dataset)))
#rename all datasets to have first letter capitalized and underscores replaced with spaces
plot_data$dataset <- recode(plot_data$dataset,
                            "airfoil" = "Airfoil",
                            "appliances_energy" = "Appliances energy",
                            "auto_mpg" = "Auto MPG",
                            "automobile" = "Automobile",
                            "beijing_pm2.5" = "Beijing PM2.5",
                            "bike_sharing" = "Bike sharing",
                            "concrete" = "Concrete",
                            "crime" = "Crime",
                            "crime_unnormalized" = "Crime unnormalized",
                            "daily_demand" = "Daily demand",
                            "facebook_metrics" = "Facebook metrics",
                            "forest_fires" = "Forest fires",
                            "infrared_thermo_temp" = "Infrared thermo temp",
                            "liver_disorders" = "Liver disorders",
                            "metro_traffic" = "Metro traffic",
                            "parkinsons" = "Parkinsons",
                            "power_consumption" = "Power consumption",
                            "power_plant" = "Power plant",
                            "real_estate" = "Real estate",
                            "servo" = "Servo",
                            "stock_portfolio" = "Stock portfolio",
                            "superconductivity" = "Superconductivity"
)

# Use similar colors for Polish, uniLasso, and uniReg
method_colors <- c(
  "uniLasso" = "#e75480",      # medium pink
  "Polish" = "#f7b6d2",        # light pink
  "uniReg" = "#c71585",        # dark pink/magenta
  "Lasso" = "#1f77b4",      # medium blue
  "LS" = "#aec7e8"           # light blue
)


########################(3) combine stability with mse, support, sign_diff########################
library(ggh4x)

stability_data_formatted <- plot_data %>%
  rename(value = stability) %>%
  mutate(metric = "Stability") %>%
  select(dataset, method, metric, value)

# Combine all four metrics into one dataset
plot_combined_long_with_stability <- bind_rows(
  plot_combined_long,  # This has MSE, Support, and Number of violations
  stability_data_formatted  # This adds Stability
) %>%
  mutate(
    metric = factor(metric, levels = c("MSE", "Support", "Number of violations", "Stability"))
  ) %>%
  mutate(
    method = factor(method, levels = c("LS", "Lasso", "uniReg", "uniLasso", "Polish"))
  ) 


# Choose first 8datasets (now with stability included)
plot_combined_long1_with_stability <- plot_combined_long_with_stability %>%
  filter(dataset %in% c("Airfoil", "Appliances energy", "Auto MPG", "Automobile", "Beijing PM2.5", "Bike sharing", "Concrete", "Crime"))
# Choose next 8 datasets (now with stability included)
plot_combined_long2_with_stability <- plot_combined_long_with_stability %>%
  filter(dataset %in% c("Crime unnormalized", "Daily demand", "Facebook metrics", "Forest fires", "Infrared thermo temp", "Liver disorders", "Metro traffic", "Parkinsons"))
# Choose last 6 datasets (now with stability included)
plot_combined_long3_with_stability <- plot_combined_long_with_stability %>%
  filter(dataset %in% c("Power consumption", "Power plant", "Real estate", "Servo", "Stock portfolio", "Superconductivity"))


# Create the enhanced plot with 4 columns (MSE, Support, Number of violations, Stability)
p_combined_facet1_with_stability <- ggplot(plot_combined_long1_with_stability, aes(x = method, y = value, fill = method)) +
  geom_boxplot() +
  facet_grid2(
    dataset ~ metric,
    switch = "y",
    scales = "free_y",     # <-- make y free
    independent = "y"      # <-- now each dataset×metric panel gets its own y-scale
  ) +
  labs(x = "Method", y = NULL, fill = "Method") +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 18, family = "Times New Roman", face = "bold"),
    axis.text.y = element_text(size = 16, family = "Times New Roman", face = "bold"),  # ADD THIS LINE
    axis.title = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.position = "bottom",
    legend.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.title = element_text(size = 20, family = "Times New  Roman", face = "bold"),
    strip.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    strip.placement = "outside",
    panel.spacing.y = unit(0.7, "cm")  # Increase vertical spacing between rows
  )
print(p_combined_facet1_with_stability)
# Save the enhanced plot
ggsave("/accounts/grad/aqwang/unilasso/figures/appendix_22data_4metrics1.png", 
       plot = p_combined_facet1_with_stability, width = 18, height = 26, dpi = 300)

# Do the same for the second set of datasets
p_combined_facet2_with_stability <- ggplot(plot_combined_long2_with_stability, aes(x = method, y = value, fill = method)) +
  geom_boxplot() +
  facet_grid2(
    dataset ~ metric,
    switch = "y",
    scales = "free_y",     # <-- make y free
    independent = "y"      # <-- now each dataset×metric panel gets its own y-scale
  ) +
  labs(x = "Method", y = NULL, fill = "Method") +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 18, family = "Times New Roman", face = "bold"),
    axis.text.y = element_text(size = 16, family = "Times New Roman", face = "bold"),  # ADD THIS LINE
    axis.title = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.position = "bottom",
    legend.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.title = element_text(size = 20, family = "Times New  Roman", face = "bold"),
    strip.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    strip.placement = "outside",
    panel.spacing.y = unit(0.7, "cm")  # Increase vertical spacing between rows
  )
print(p_combined_facet2_with_stability)
# Save the enhanced plot
ggsave("/accounts/grad/aqwang/unilasso/figures/appendix_22data_4metrics2.png", 
       plot = p_combined_facet2_with_stability, width = 18, height = 26, dpi = 300)

# Do the same for the third set of datasets
p_combined_facet3_with_stability <- ggplot(plot_combined_long3_with_stability, aes(x = method, y = value, fill = method)) +
  geom_boxplot() +
  facet_grid2(
    dataset ~ metric,
    switch = "y",
    scales = "free_y",     # <-- make y free
    independent = "y"      # <-- now each dataset×metric panel gets its own y-scale
  ) +
  labs(x = "Method", y = NULL, fill = "Method") +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 18, family = "Times New Roman", face = "bold"),
    axis.text.y = element_text(size = 16, family = "Times New Roman", face = "bold"),  # ADD THIS LINE
    axis.title = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.position = "bottom",
    legend.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.title = element_text(size = 20, family = "Times New  Roman", face = "bold"),
    strip.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    strip.placement = "outside",
    panel.spacing.y = unit(0.7, "cm")  # Increase vertical spacing between rows
  )
print(p_combined_facet3_with_stability)
# Save the enhanced plot
ggsave("/accounts/grad/aqwang/unilasso/figures/appendix_22data_4metrics3.png", 
       plot = p_combined_facet3_with_stability, width = 18, height = 20, dpi = 300)
```


# calculate stability
```{r calculate stability}
# read the coefficient csv file
coefficients_all_splits <- read.csv("/accounts/grad/aqwang/unilasso/analysis/coef_csv/coefficients_airfoil.csv")

# read the coefficient csv file
coefficients_all_splits <- read.csv("/accounts/grad/aqwang/unilasso/analysis/coef_csv/coefficients_airfoil.csv")

#remove rows with method=uni_loo
coefficients_all_splits <- coefficients_all_splits[coefficients_all_splits$method != "unilasso_loo_false", ]
coefficients_all_splits <- coefficients_all_splits[coefficients_all_splits$method != "uni_loo", ]

# Calculate stability for each method - return entire stability vector
library(dplyr)
library(utils)  # for combn function

# Function to calculate stability for a given method - returns all pairwise values
calculate_stability_full <- function(data, method_name) {
  # Filter data for the specific method
  method_data <- data %>% filter(method == method_name)
  
  # Extract coefficient columns (starting from column 4)
  coef_matrix <- as.matrix(method_data[, 4:ncol(method_data)])
  
  # Number of models for this method
  n_models <- nrow(coef_matrix)
  
  if (n_models < 2) {
    return(c())  # Return empty vector if not enough models
  }
  
  # Generate all pairs of models (100 choose 2)
  model_pairs <- combn(1:n_models, 2, simplify = FALSE)
  
  # Calculate stability for each pair
  stability_values <- sapply(model_pairs, function(pair) {
    model_i <- pair[1]
    model_j <- pair[2]
    
    # Find selected features (non-zero coefficients) for each model
    features_i <- which(coef_matrix[model_i, ] != 0)
    features_j <- which(coef_matrix[model_j, ] != 0)
    
    # Calculate Jaccard similarity: |intersection| / |union|
    common_features <- length(intersect(features_i, features_j))
    total_unique_features <- length(union(features_i, features_j))
    
    # Handle case where both models select no features
    if (total_unique_features == 0) {
      return(1)  # Perfect stability if both select nothing
    } else {
      return(common_features / total_unique_features)
    }
  })
  
  # Return the entire vector of stability values
  return(stability_values)
}

# Get unique methods in the dataset
unique_methods <- unique(coefficients_all_splits$method)

# Calculate stability for each method - store full vectors
stability_results_full <- list()

for (method in unique_methods) {
  stability_vector <- calculate_stability_full(coefficients_all_splits, method)
  
  # Clean method name
  clean_method <- recode(method,
    "unilasso_loo_true" = "uniLasso",
    "polish_unilasso" = "Polish",  
    "lasso_cv" = "Lasso",
    "unireg" = "uniReg",
    "least_squares" = "LS"
  )
  
  stability_results_full[[clean_method]] <- stability_vector
}

# Display summary statistics
cat("Stability Results for Airfoil Dataset:\n")
cat("=====================================\n")
for (method in names(stability_results_full)) {
  values <- stability_results_full[[method]]
  if (length(values) > 0) {
    cat(sprintf("%-10s: Mean = %.3f (SD = %.3f) [%d pairs]\n", 
                method,
                mean(values, na.rm = TRUE),
                sd(values, na.rm = TRUE),
                length(values)))
    cat(sprintf("           Range: [%.3f, %.3f]\n", 
                min(values, na.rm = TRUE), 
                max(values, na.rm = TRUE)))
  } else {
    cat(sprintf("%-10s: No data available\n", method))
  }
  cat("\n")
}
```



# calculate stability for all 22 datasets from paper (13 datasets left when excluding datasets with multiple targets and datasets that overlap with 17 datasets)
```{r load dataset names}
library(dplyr)
library(utils)  # for combn function

# Function to calculate stability for a given method - returns all pairwise values
calculate_stability_full <- function(data, method_name) {
  # Filter data for the specific method
  method_data <- data %>% filter(method == method_name)
  
  # Extract coefficient columns (starting from column 4)
  coef_matrix <- as.matrix(method_data[, 4:ncol(method_data)])
  
  # Number of models for this method
  n_models <- nrow(coef_matrix)
  
  if (n_models < 2) {
    return(c())  # Return empty vector if not enough models
  }
  
  # Generate all pairs of models (100 choose 2)
  model_pairs <- combn(1:n_models, 2, simplify = FALSE)
  
  # Calculate stability for each pair
  stability_values <- sapply(model_pairs, function(pair) {
    model_i <- pair[1]
    model_j <- pair[2]
    
    # Find selected features (non-zero coefficients) for each model
    features_i <- which(coef_matrix[model_i, ] != 0)
    features_j <- which(coef_matrix[model_j, ] != 0)
    
    # Calculate Jaccard similarity: |intersection| / |union|
    common_features <- length(intersect(features_i, features_j))
    total_unique_features <- length(union(features_i, features_j))
    
    # Handle case where both models select no features
    if (total_unique_features == 0) {
      return(1)  # Perfect stability if both select nothing
    } else {
      return(common_features / total_unique_features)
    }
  })
  
  # Return the entire vector of stability values
  return(stability_values)
}

# Get all CSV files in the coef_csv directory
coef_csv_dir <- "/accounts/grad/aqwang/unilasso/analysis/coef_csv_22datasets"
csv_files <- list.files(coef_csv_dir, pattern = "coefficients_.*\\.csv$", full.names = TRUE)

# Extract dataset names from file names
dataset_names <- gsub("coefficients_(.+)\\.csv", "\\1", basename(csv_files))

cat("Found", length(csv_files), "coefficient files:\n")
for (i in seq_along(dataset_names)) {
  cat("  ", i, ":", dataset_names[i], "\n")
}

# Initialize storage for all results
all_stability_results <- data.frame(
  dataset = character(),
  method = character(),
  mean_stability = numeric(),
  sd_stability = numeric(),
  min_stability = numeric(),
  max_stability = numeric(),
  n_pairs = integer(),
  stringsAsFactors = FALSE
)

# Initialize storage for detailed results (optional - if you want all pairwise values)
all_stability_detailed <- list()

# Loop through all datasets
for (i in seq_along(csv_files)) {
  dataset_name <- dataset_names[i]
  csv_file <- csv_files[i]
  
  cat("\n", strrep("=", 60), "\n")
  cat("Processing dataset:", dataset_name, "(", i, "/", length(csv_files), ")\n")
  cat(strrep("=", 60), "\n")
  
  # Read coefficient data
  tryCatch({
    coefficients_data <- read.csv(csv_file)
    # Remove rows with method=unilasso_loo_false
    coefficients_data <- coefficients_data[coefficients_data$method != "unilasso_loo_false", ]
    coefficients_data <- coefficients_data[coefficients_data$method != "uni_loo", ]
    
    # Get unique methods in this dataset
    unique_methods <- unique(coefficients_data$method)
    cat("Found methods:", paste(unique_methods, collapse = ", "), "\n")
    
    # Calculate stability for each method in this dataset
    dataset_stability_detailed <- list()
    
    for (method in unique_methods) {
      cat("  Processing method:", method, "...")
      
      # Calculate full stability vector for this method
      stability_vector <- calculate_stability_full(coefficients_data, method)
      
      if (length(stability_vector) > 0) {
        # Clean method name
        clean_method <- recode(method,
          "unilasso_loo_true" = "uniLasso",
          "polish_unilasso" = "Polish",
          "lasso_cv" = "Lasso",
          "unireg" = "uniReg", 
          "least_squares" = "LS"
        )
        
        # Calculate summary statistics
        summary_stats <- data.frame(
          dataset = dataset_name,
          method = clean_method,
          mean_stability = mean(stability_vector, na.rm = TRUE),
          sd_stability = sd(stability_vector, na.rm = TRUE),
          min_stability = min(stability_vector, na.rm = TRUE),
          max_stability = max(stability_vector, na.rm = TRUE),
          n_pairs = length(stability_vector),
          stringsAsFactors = FALSE
        )
        
        # Add to main results dataframe
        all_stability_results <- rbind(all_stability_results, summary_stats)
        
        # Store detailed results (optional)
        dataset_stability_detailed[[clean_method]] <- stability_vector
        
        cat(" Done (", length(stability_vector), " pairs)\n")
        
      } else {
        cat(" Skipped (insufficient data)\n")
      }
    }
    
    # Store detailed results for this dataset
    all_stability_detailed[[dataset_name]] <- dataset_stability_detailed
    
    # Print summary for this dataset
    dataset_results <- all_stability_results[all_stability_results$dataset == dataset_name, ]
    if (nrow(dataset_results) > 0) {
      cat("\nSummary for", dataset_name, ":\n")
      for (j in 1:nrow(dataset_results)) {
        row <- dataset_results[j, ]
        cat(sprintf("  %-10s: Mean = %.3f (SD = %.3f) Range = [%.3f, %.3f] [%d pairs]\n",
                    row$method, row$mean_stability, row$sd_stability,
                    row$min_stability, row$max_stability, row$n_pairs))
      }
    }
    
  }, error = function(e) {
    cat("ERROR processing", dataset_name, ":", e$message, "\n")
  })
}

# Final summary
cat("\n", strrep("=", 80), "\n")
cat("STABILITY ANALYSIS COMPLETE!\n")
cat("Total datasets processed:", length(unique(all_stability_results$dataset)), "\n")
cat("Total method-dataset combinations:", nrow(all_stability_results), "\n")
cat(strrep("=", 80), "\n")

# Display overall results
print(all_stability_results)

# Save results
write.csv(all_stability_results, "stability_results_all_datasets.csv", row.names = FALSE)
save(all_stability_results, all_stability_detailed, file = "stability_results_all_datasets.RData")

cat("\nResults saved to:\n")
cat("  - stability_results_all_datasets.csv (summary)\n")
cat("  - stability_results_all_datasets.RData (detailed)\n")


library(ggplot2)

# Build one long data.frame: dataset, method, stability
make_long <- function(all_stability_detailed) {
  do.call(rbind, lapply(names(all_stability_detailed), function(ds) {
    methods <- all_stability_detailed[[ds]]
    if (length(methods) == 0) return(NULL)
    do.call(rbind, lapply(names(methods), function(m) {
      v <- methods[[m]]
      v <- v[is.finite(v)]                 # drop NA/Inf if present
      if (length(v) == 0) return(NULL)
      data.frame(dataset = ds, method = m, stability = v, 
                 stringsAsFactors = FALSE)
    }))
  }))
}

plot_data <- make_long(all_stability_detailed)
if (is.null(plot_data) || nrow(plot_data) == 0L) stop("No stability data to plot.")


#recode method names
plot_data$method <- recode(plot_data$method,
  "unilasso_loo_true" = "uniLasso",
  "polish_unilasso" = "Polish",
  "lasso_cv" = "Lasso",
  "unireg" = "uniReg",
  "least_squares" = "LS"
)
# Order datasets for consistent facetting
plot_data$dataset <- factor(plot_data$dataset, levels = sort(unique(plot_data$dataset)))
# Use similar colors for Polish, uniLasso, and uniReg
method_colors <- c(
  "uniLasso"="blue",      # strong red
  "Polish" = "#fb6a4a",        # medium red/orange
  "uniReg" = "#fcbba1",        # light red/pink   
  "Lasso" = "#1f78b4",         # dark blue
  "LS" = "#a6cee3"             # light blue
)
p_stability <- ggplot(plot_data, aes(x = method, y = stability, fill = method)) +
  geom_boxplot() +
  ggh4x::facet_wrap2(~ dataset, nrow = 4, ncol = 5, scales = "free_y", axes = "x") +
  labs(
    title = "Stability Distribution by Method for Each Dataset Using 100 Random Train/Test (50/50) Splits",
    x = "Method",
    y = "Stability",
    fill = "Method"
  ) +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 12),  # increase tick label font size
    axis.title.x = element_text(size = 18),  # x-axis title font size
    axis.title.y = element_text(size = 18),  # y-axis title font size
    legend.position = "bottom",
    legend.text = element_text(size = 18),
    legend.title = element_text(size = 18)
  )
  print(p_stability)

```

# other analysis 
```{R}
# make a loop to find the observations and features for each dataset and summarize in a table
dataset_info <- data.frame(
  dataset = character(),
  n_obs = integer(),
  n_features = integer(),
  stringsAsFactors = FALSE
) 
for (dataset_name in dataset_names) {
  X_path <- paste0("/accounts/grad/aqwang/unilasso/datasets_12/", dataset_name, "/X.csv")
  y_path <- paste0("/accounts/grad/aqwang/unilasso/datasets_12/", dataset_name, "/y.csv")
  
  X <- read.csv(X_path)
  y <- read.csv(y_path, header = FALSE)
  
  n_obs <- nrow(X)
  n_features <- ncol(X)
  ratio <- n_features / n_obs
  
  dataset_info <- rbind(dataset_info, data.frame(
    dataset = dataset_name,
    n_obs = n_obs,
    n_features = n_features,
    p_n_ratio = ratio,
    stringsAsFactors = FALSE
  ))
}
print(dataset_info)


dataset_name2 <- c(
  "appliances_energy_prediction", "auto_mpg", "automobile", "beijing_pm2.5",
  "bike_sharing",  "communities_and_crime", "communities_and_crime_unnormalized", "daily_demand_forecasting_orders", "facebook_metrics", "forest_fires",
  "infrared_thermography_temperature",  "liver_disorders", "metro_interstate_traffic_volume",  "power_consumption_of_tetouan_city", "real_estate_valuation",
  "servo", "stock_portfolio_performance"
)

dataset_info <- data.frame(
  dataset = character(),
  n_obs = integer(),
  n_features = integer(),
  stringsAsFactors = FALSE
) 
for (dataset_name in dataset_name2) {
  X_path <- paste0("/accounts/grad/aqwang/unilasso/datasets_22/", dataset_name, "/X.csv")
  y_path <- paste0("/accounts/grad/aqwang/unilasso/datasets_22/", dataset_name, "/y.csv")
  
  X <- read.csv(X_path)
  y <- read.csv(y_path, header = FALSE)
  
  n_obs <- nrow(X)
  n_features <- ncol(X)
  ratio <- n_features / n_obs
  
  dataset_info <- rbind(dataset_info, data.frame(
    dataset = dataset_name,
    n_obs = n_obs,
    n_features = n_features,
    p_n_ratio = ratio,
    stringsAsFactors = FALSE
  ))
}
print(dataset_info)
```



```{r closer_look at diamnond,powerplant,superconductor, qsar}
# read the csv file of diamond, powerplant, and supercondactor dataset
diamond_features <- read.csv("/accounts/grad/aqwang/unilasso/datasets_17/data_diamond/X.csv")
powerplant_features <- read.csv("/accounts/grad/aqwang/unilasso/datasets_17/data_powerplant/X.csv")
superconductor_features <- read.csv("/accounts/grad/aqwang/unilasso/datasets_17/data_superconductor/X.csv")
qsar_features <- read.csv("/accounts/grad/aqwang/unilasso/datasets_17/data_qsar/X.csv")

# check if the features are highly correlated in all three datasets
cor_diamond <- cor(diamond_features)
cor_powerplant <- cor(powerplant_features)
cor_superconductor <- cor(superconductor_features)
cor_qsar <- cor(qsar_features)

# make a heatmap to visualize the correlation matrix
library(ggplot2)
library(reshape2)

# Example: diamond dataset
# Diamond dataset correlation heatmap
cor_diamond <- cor(diamond_features, use = "pairwise.complete.obs")
melted_cor_diamond <- melt(cor_diamond)

ggplot(melted_cor_diamond, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white",
                       midpoint = 0, limit = c(-1,1), space = "Lab",
                       name="Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1,
                                   size = 10, hjust = 1)) +
  coord_fixed() +
  labs(title = "Feature Correlation Heatmap for Diamond Dataset",
       x = "Features", y = "Features")

# calculate how many pairs of features in powerplant features that have correlation greater than 0.9 and list the pairs
high_cor_pairs <- sum(abs(cor_diamond[upper.tri(cor_diamond)]) > 0.7)
high_cor_pairs
# Only the upper triangle (excluding diagonal) for highly correlated pairs
high_cor_indices <- which(abs(cor_diamond) > 0.9 & abs(cor_diamond) < 1 & upper.tri(cor_diamond), arr.ind = TRUE)
high_cor_features_names <- data.frame(
  Feature1 = colnames(diamond_features)[high_cor_indices[,1]],
  Feature2 = colnames(diamond_features)[high_cor_indices[,2]],
  Correlation = cor_diamond[high_cor_indices]
)
print(high_cor_features_names)



# Powerplant dataset correlation heatmap
cor_powerplant <- cor(powerplant_features, use = "pairwise.complete.obs")
melted_cor_powerplant <- melt(cor_powerplant)

ggplot(melted_cor_powerplant, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white",
                       midpoint = 0, limit = c(-1,1), space = "Lab",
                       name="Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1,
                                   size = 10, hjust = 1)) +
  coord_fixed() +
  labs(title = "Feature Correlation Heatmap for Powerplant Dataset",
       x = "Features", y = "Features")

# calculate how many pairs of features in powerplant features that have correlation greater than 0.9 and list the pairs
high_cor_pairs <- sum(abs(cor_powerplant[upper.tri(cor_powerplant)]) > 0.7)
high_cor_pairs
# Only the upper triangle (excluding diagonal) for highly correlated pairs
high_cor_indices <- which(abs(cor_powerplant) > 0.7 & abs(cor_powerplant) < 1 & upper.tri(cor_powerplant), arr.ind = TRUE)
high_cor_features_names <- data.frame(
  Feature1 = colnames(powerplant_features)[high_cor_indices[,1]],
  Feature2 = colnames(powerplant_features)[high_cor_indices[,2]],
  Correlation = cor_powerplant[high_cor_indices]
)
print(high_cor_features_names)

# Superconductor dataset correlation heatmap
cor_superconductor <- cor(superconductor_features, use = "pairwise.complete.obs")
melted_cor_superconductor <- melt(cor_superconductor)

ggplot(melted_cor_superconductor, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white",
                       midpoint = 0, limit = c(-1,1), space = "Lab",
                       name="Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1,
                                   size = 10, hjust = 1)) +
  coord_fixed() +
  labs(title = "Feature Correlation Heatmap for Superconductor Dataset",
       x = "Features", y = "Features")

# calculate how many pairs of features in superconductor features that have correlation greater than 0.9 and list the pairs
high_cor_pairs <- sum(abs(cor_superconductor[upper.tri(cor_superconductor)]) > 0.9)
high_cor_pairs
# Only the upper triangle (excluding diagonal) for highly correlated pairs
high_cor_indices <- which(abs(cor_superconductor) > 0.9 & abs(cor_superconductor) < 1 & upper.tri(cor_superconductor), arr.ind = TRUE)
high_cor_features_names <- data.frame(
  Feature1 = colnames(superconductor_features)[high_cor_indices[,1]],
  Feature2 = colnames(superconductor_features)[high_cor_indices[,2]],
  Correlation = cor_superconductor[high_cor_indices]
)
print(high_cor_features_names)

# QSAR dataset correlation heatmap
# select the first 50 features for better visualization
qsar_features2 <- qsar_features2[, 151:200]
cor_qsar <- cor(qsar_features2, use = "pairwise.complete.obs")
melted_cor_qsar <- melt(cor_qsar)
ggplot(melted_cor_qsar, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white",
                       midpoint = 0, limit = c(-1,1), space = "Lab",
                       name="Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1,
                                   size = 10, hjust = 1)) +
  coord_fixed() +
  labs(title = "Feature Correlation Heatmap for QSAR Dataset",
       x = "Features", y = "Features")

# calculate how many pairs of features in qsar features that have correlation greater than 0.9 and list the pairs
cor_qsar2 <- cor(qsar_features, use = "pairwise.complete.obs")
high_cor_pairs <- sum(abs(cor_qsar2[upper.tri(cor_qsar2)]) > 0.9)
high_cor_pairs
# Only the upper triangle (excluding diagonal) for highly correlated pairs
high_cor_indices <- which(abs(cor_qsar2) > 0.9 & abs(cor_qsar2) < 1 & upper.tri(cor_qsar2), arr.ind = TRUE)
high_cor_features_names <- data.frame(
  Feature1 = colnames(qsar_features)[high_cor_indices[,1]],
  Feature2 = colnames(qsar_features)[high_cor_indices[,2]],
  Correlation = cor_qsar2[high_cor_indices]
)
print(high_cor_features_names)
````


# load bootstrap results and make some plots
```{r load bootstrap results and make some plots}
pred_int <- read.csv("/accounts/grad/aqwang/unilasso/analysis/unilasso_17datasets_100bootstrap_prediction_intervals.csv")
boot_results <- read.csv("/accounts/grad/aqwang/unilasso/analysis/unilasso_17datasets_100bootstrap_train67percent_all_results_parallel.csv")

# calculate the support size mean and sd for each dataset and method
library(dplyr)
summary_boot_MSE <- boot_results %>%
  group_by(dataset) %>%
  summarise(
    # MSE statistics
    unilasso_loo_true_mean_mse = mean(unilasso_loo_true_mse, na.rm = TRUE),
    unilasso_loo_true_sd_mse = sd(unilasso_loo_true_mse, na.rm = TRUE),
    unilasso_loo_false_mean_mse = mean(unilasso_loo_false_mse, na.rm = TRUE),
    unilasso_loo_false_sd_mse = sd(unilasso_loo_false_mse, na.rm = TRUE),
    polish_unilasso_mean_mse = mean(polish_unilasso_mse, na.rm = TRUE),
    polish_unilasso_sd_mse = sd(polish_unilasso_mse, na.rm = TRUE),
    lasso_cv_mean_mse = mean(lasso_cv_mse, na.rm = TRUE),
    lasso_cv_sd_mse = sd(lasso_cv_mse, na.rm = TRUE),
    .groups = 'drop' )


library(ggplot2)
library(tidyr)
library(dplyr)

# 1. MSE Plot with Error Bars
# Create a single pivot that handles both mean and SD columns together
plot_mse_data <- summary_boot_MSE %>%
  pivot_longer(
    cols = c(unilasso_loo_true_mean_mse, unilasso_loo_false_mean_mse, 
             polish_unilasso_mean_mse, lasso_cv_mean_mse,
             unilasso_loo_true_sd_mse, unilasso_loo_false_sd_mse, 
             polish_unilasso_sd_mse, lasso_cv_sd_mse),
    names_to = c("method", "statistic"),
    values_to = "value",
    names_pattern = "(.*)_(mean_mse|sd_mse)"
  ) %>%
  # Pivot wider to get mean_mse and sd_mse as separate columns
  pivot_wider(
    names_from = statistic,
    values_from = value
  ) %>%
  # Keep mean_mse and sd_mse as numeric for plotting
  # Clean up method names
  mutate(method = recode(method,
                        "unilasso_loo_true" = "uniLasso (LOO=T)",
                        "unilasso_loo_false" = "uniLasso (LOO=F)",
                        "polish_unilasso" = "uniLasso polish",
                        "lasso_cv" = "Lasso CV"))

# Build labels: 1 decimal; if >100 use scientific with 1 sig decimal; if <0.1 use 4 decimals
plot_mse_data2 <- plot_mse_data %>%
  mutate(
    mean_label = case_when(
      mean_mse < 0.1 ~ formatC(mean_mse, format = "e", digits = 1),
      mean_mse > 100 ~ formatC(mean_mse, format = "e", digits = 1),
      TRUE ~ sprintf("%.1f", mean_mse)
    ),
    sd_label = case_when(
      sd_mse < 0.1 ~ formatC(mean_mse, format = "e", digits = 1),
      sd_mse > 100 ~ formatC(sd_mse, format = "e", digits = 1),
      TRUE ~ sprintf("%.1f", sd_mse)
    ),
    label_text = paste0(mean_label, " ± ", sd_label)
  )

p_mse_error <- ggplot(plot_mse_data2, aes(x = method, y = mean_mse, fill = method)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.8, alpha = 0.7) +  # wider bars
  geom_errorbar(aes(ymin = mean_mse - sd_mse, ymax = mean_mse + sd_mse),
                position = position_dodge(width = 0.6),
                width = 0.25, alpha = 0.8) +
  # Label means on top of bars, tilted 45 degrees
  geom_text(aes(label = label_text),
            position = position_dodge(width = 0.6),
            vjust = -0.5, size = 3.3, angle = 75, hjust = 0) +
  # Facet with per-facet axes
  ggh4x::facet_wrap2(
    ~ dataset,
    nrow = ceiling(length(unique(plot_mse_data$dataset))/5),
    ncol = 5,
    scales = "free_y",
    axes = "x"
  ) +
  labs(
    title = "Mean MSE with Standard Deviation Bars (100 Bootstrap Results)",
    x = "Method",
    y = "Mean MSE",
    fill = "Method"
  ) +
  theme_bw() +
  theme(
    plot.title = element_text(size = 18, face = "bold"),  # increase title size
    axis.text.x  = element_text(angle = 30, hjust = 1, size = 13),
    axis.title   = element_text(size = 15),
    legend.position = "bottom",
    strip.text   = element_text(size = 13)
  ) +
  scale_y_continuous(expand = expansion(mult = c(0, 1.5)))

print(p_mse_error)

# make choose label_text plot_mse_data2 a wide format 
plot_mse_data_wide <- plot_mse_data2 %>%
  select(dataset, method, label_text) %>%
  pivot_wider(names_from = method, values_from = label_text)
print(plot_mse_data_wide)




summary_boot_support <- boot_results %>%
  group_by(dataset) %>%
  summarise(
    # Support size statistics
    unilasso_loo_true_mean_support = mean(unilasso_loo_true_support, na.rm = TRUE),
    unilasso_loo_true_sd_support = sd(unilasso_loo_true_support, na.rm = TRUE),
    unilasso_loo_false_mean_support = mean(unilasso_loo_false_support, na.rm = TRUE),
    unilasso_loo_false_sd_support = sd(unilasso_loo_false_support, na.rm = TRUE),
    polish_unilasso_mean_support = mean(polish_unilasso_support, na.rm = TRUE),
    polish_unilasso_sd_support = sd(polish_unilasso_support, na.rm = TRUE),
    lasso_cv_mean_support = mean(lasso_cv_support, na.rm = TRUE),
    lasso_cv_sd_support = sd(lasso_cv_support, na.rm = TRUE),
    .groups = 'drop'
  )



# 2. Support Size Plot with Error Bars
# Create a single pivot that handles both mean and SD columns together
plot_support_data <- summary_boot_support %>%
  pivot_longer(
    cols = c(unilasso_loo_true_mean_support, unilasso_loo_false_mean_support, 
             polish_unilasso_mean_support, lasso_cv_mean_support,
             unilasso_loo_true_sd_support, unilasso_loo_false_sd_support, 
             polish_unilasso_sd_support, lasso_cv_sd_support),
    names_to = c("method", "statistic"),
    values_to = "value",
    names_pattern = "(.*)_(mean_support|sd_support)"
  ) %>%
  # Pivot wider to get mean_support and sd_support as separate columns
  pivot_wider(
    names_from = statistic,
    values_from = value
  ) %>%
  # Clean up method names
  mutate(method = recode(method,
                        "unilasso_loo_true" = "uniLasso (LOO=T)",
                        "unilasso_loo_false" = "uniLasso (LOO=F)",
                        "polish_unilasso" = "uniLasso polish",
                        "lasso_cv" = "Lasso CV"))

# Build labels: 1 decimal for support (since it's typically whole numbers, use 1 decimal)
plot_support_data2 <- plot_support_data %>%
  mutate(
    mean_label = sprintf("%.1f", mean_support),
    sd_label = sprintf("%.1f", sd_support),
    label_text = paste0(mean_label, " ± ", sd_label)
  )

p_support_error <- ggplot(plot_support_data2, aes(x = method, y = mean_support, fill = method)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.8, alpha = 0.7) +  # wider bars
  geom_errorbar(aes(ymin = mean_support - sd_support, ymax = mean_support + sd_support),
                position = position_dodge(width = 0.6),
                width = 0.25, alpha = 0.8) +
  # Label means on top of bars, tilted 45 degrees
  geom_text(aes(label = label_text),
            position = position_dodge(width = 0.6),
            vjust = -0.5, size = 3.3, angle = 75, hjust = 0) +
  # Facet with per-facet axes
  ggh4x::facet_wrap2(
    ~ dataset,
    nrow = ceiling(length(unique(plot_support_data$dataset))/5),
    ncol = 5,
    scales = "free_y",
    axes = "x"
  ) +
  labs(
    title = "Mean Support Size with Standard Deviation Bars (100 Bootstrap Results)",
    x = "Method",
    y = "Mean Support Size",
    fill = "Method"
  ) +
  theme_bw() +
  theme(
    plot.title = element_text(size = 18, face = "bold"),  # increase title size
    axis.text.x  = element_text(angle = 30, hjust = 1, size = 12),
    axis.title   = element_text(size = 15),
    legend.position = "bottom",
    strip.text   = element_text(size = 12)
  ) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.8)))

print(p_support_error)

# Make a wide format table for support data
plot_support_data_wide <- plot_support_data2 %>%
  select(dataset, method, label_text) %>%
  pivot_wider(names_from = method, values_from = label_text)
print(plot_support_data_wide)

# scatter plot of support size for each dataset colored by method (use facet_wrap2 to make 5 columns and 4 rows)
library(ggplot2)
library(dplyr)
library(tidyr)
library(ggh4x)
library(patchwork)

# Prepare long data
support_long <- results_all_bootstrap %>%
  select(dataset, bootstrap_id,
         lasso_cv_support,
         unilasso_loo_false_support,
         unilasso_loo_true_support,
         polish_unilasso_support) %>%
  pivot_longer(
    cols = -c(dataset, bootstrap_id),
    names_to = "method_raw",
    values_to = "support"
  ) %>%
  mutate(
    method = recode(method_raw,
      lasso_cv_support           = "Lasso CV",
      unilasso_loo_false_support = "uniLasso (LOO=F)",
      unilasso_loo_true_support  = "uniLasso (LOO=T)",
      polish_unilasso_support    = "uniLasso polish"
    ),
    method = factor(method, levels = c("Lasso CV", "uniLasso (LOO=F)",
                                       "uniLasso (LOO=T)", "uniLasso polish"))
  )

# a function to draw one dataset's scatter with its own axes & title
plot_one_ds <- function(ds) {
  ggplot(filter(support_long, dataset == ds),
         aes(x = bootstrap_id, y = support, color = method)) +
    geom_point(alpha = 0.5, size = 1,   # lower alpha for more transparency
               position = position_jitter(width = 0.3, height = 0)) +
    labs(title = ds,
       x = "Bootstrap sample",          # <-- appears under THIS panel
       y = "Support size",
       color = "Method") +
    scale_color_manual(
      values = c(
      "Lasso CV" = "#39f617",
      "uniLasso (LOO=F)" = "#f2a114",
      "uniLasso (LOO=T)" = "#020c0f",
      "uniLasso polish" = "#ec0faa"
      )
    )+
    theme(
      plot.title = element_text(size = 12, hjust = 0.5),
      axis.text.x = element_text(size = 7),
      axis.text.y = element_text(size = 8),
      legend.position = "none"            # legend will be collected later
    )
}

plots <- lapply(unique(support_long$dataset), plot_one_ds)

# arrange in a grid (5 per row) and collect one common legend
# add plot.margin to each plot to increase space between rows
plots_spaced <- lapply(plots, function(p) p + theme(plot.margin = margin(t = 10, b = 30)))
p_support <- wrap_plots(plots_spaced, ncol = 5, guides = "collect") &
  theme(
    legend.position = "bottom",
    legend.title = element_text(size = 20)
  )

p_support


# for prediction interval, make a plot of average width of prediction interval for each dataset with standard error bar
pred_int <- read.csv("/accounts/grad/aqwang/unilasso/analysis/unilasso_17datasets_100bootstrap_prediction_intervals.csv")

# graph the mean width of prediction interval for all 4 methods for each dataset
library(ggplot2)
library(dplyr)

# mean and sd is already calculated in pred_int

# pred_int is a long format
pred_int <- pred_int %>%
  mutate(
    method = recode(method,
                    "lasso_cv" = "Lasso CV",
                    "uniLasso_loo_false" = "uniLasso (LOO=F)",
                    "uniLasso_loo_true" = "uniLasso (LOO=T)",
                    "polish_uniLasso" = "uniLasso polish")
  )
# Build labels: 1 decimal; if >100 use scientific with 1 sig decimal; if <0.1 use 4 decimals
pred_int2 <- pred_int %>%
  mutate(
    mean_label = case_when(
      avg_interval_width < 0.1 ~ formatC(avg_interval_width, format = "e",  digits = 2),
      avg_interval_width > 100 ~ formatC(avg_interval_width, format = "e", digits = 2),
      TRUE ~ sprintf("%.2f", avg_interval_width)
    ),
    sd_label = case_when(
      sd_interval_width < 0.1 ~ formatC(sd_interval_width, format = "e",  digits = 2),
      sd_interval_width > 100 ~ formatC(sd_interval_width, format = "e", digits = 2),
      TRUE ~ sprintf("%.2f", sd_interval_width)
    ),
    label_text = paste0(mean_label, " ± ", sd_label)
  )

p_pred_int <- ggplot(pred_int2, aes(x = method, y = avg_interval_width, fill = method)) +
  geom_col(position = position_dodge(width = 0.9), width = 0.9, alpha = 0.7) +  # wider bars
  geom_errorbar(aes(ymin = avg_interval_width - sd_interval_width, ymax = avg_interval_width + sd_interval_width),
                position = position_dodge(width = 0.6),
                width = 0.25, alpha = 0.8) +
  # Label means on top of bars, tilted 45 degrees
  geom_text(aes(label = label_text),  
            position = position_dodge(width = 0.6),
            vjust = -0.5, size = 3.3, angle = 75, hjust = -0.2) +
  # Facet with per-facet axes
  ggh4x::facet_wrap2(
    ~ dataset,
    nrow = ceiling(length(unique(pred_int$dataset))/5),
    ncol = 5,
    scales = "free_y",
    axes = "x"
  ) +
  labs(
    title = "Mean Width of Prediction Interval with Standard Deviation Bars (100 Bootstrap Results)",
    x = "Method", 
    y = "Mean Width of Prediction Interval",
    fill = "Method"
  ) + 
  theme_bw() +
  theme(
    plot.title = element_text(size = 18, face = "bold"),  # increase title size
    axis.text.x  = element_text(angle = 30, hjust = 1, size = 13),
    axis.title   = element_text(size = 15),
    legend.position = "bottom",
    strip.text   = element_text(size = 13)
  ) +
  scale_y_continuous(expand = expansion(mult = c(0, 1.8)))
print(p_pred_int)

# make a wide format table for prediction interval data
pred_int_wide <- pred_int2 %>%
  select(dataset, method, label_text) %>%
  pivot_wider(names_from = method, values_from = label_text)
print(pred_int_wide)


```

# Final version: updated bootstrap results with uniReg for 12 datasets 9/12 Friday
```{r load updated bootstrap results and make some plots}
boot_results <- read.csv("/accounts/grad/aqwang/unilasso/analysis/bootstrap_result/unilasso_12datasets_100bootstrap_train50percent.csv")

# calculate the support size mean and sd for each dataset and method
library(dplyr)
summary_boot_MSE <- boot_results %>%
  group_by(dataset) %>%
  summarise(
    # MSE statistics
    unilasso_loo_true_mean_mse = mean(unilasso_loo_true_mse, na.rm = TRUE),
    unilasso_loo_true_sd_mse = sd(unilasso_loo_true_mse, na.rm = TRUE),
    unilasso_loo_false_mean_mse = mean(unilasso_loo_false_mse, na.rm = TRUE),
    unilasso_loo_false_sd_mse = sd(unilasso_loo_false_mse, na.rm = TRUE),
    polish_unilasso_mean_mse = mean(polish_unilasso_mse, na.rm = TRUE),
    polish_unilasso_sd_mse = sd(polish_unilasso_mse, na.rm = TRUE),
    lasso_cv_mean_mse = mean(lasso_cv_mse, na.rm = TRUE),
    lasso_cv_sd_mse = sd(lasso_cv_mse, na.rm = TRUE),
    unireg_mean_mse = mean(unireg_mse, na.rm = TRUE),
    unireg_sd_mse = sd(unireg_mse, na.rm = TRUE),
    least_squares_mean_mse = mean(least_squares_mse, na.rm = TRUE),
    least_squares_sd_mse = sd(least_squares_mse, na.rm = TRUE),
    .groups = 'drop' )

#drop unilasso_loo_false method from the summary_boot_MSE
summary_boot_MSE <- summary_boot_MSE %>%
  select(-c(unilasso_loo_false_mean_mse, unilasso_loo_false_sd_mse))

library(ggplot2)
library(tidyr)
library(dplyr)

# 1. MSE Plot with Error Bars
# Create a single pivot that handles both mean and SD columns together
plot_mse_data <- summary_boot_MSE %>%
  pivot_longer( 
    cols = c(unilasso_loo_true_mean_mse, 
             polish_unilasso_mean_mse, lasso_cv_mean_mse,
             unireg_mean_mse, least_squares_mean_mse,
             unilasso_loo_true_sd_mse, 
             polish_unilasso_sd_mse, lasso_cv_sd_mse,
             unireg_sd_mse, least_squares_sd_mse),
    names_to = c("method", "statistic"),
    values_to = "value",
    names_pattern = "(.*)_(mean_mse|sd_mse)"
  ) %>%
  # Pivot wider to get mean_mse and sd_mse as separate columns
  pivot_wider(
    names_from = statistic,
    values_from = value
  ) %>%
  # Keep mean_mse and sd_mse as numeric for plotting
  # Clean up method names
  mutate(method = recode(method,
                        "unilasso_loo_true" = "uniLasso",
                        "polish_unilasso" = "Polish",
                        "lasso_cv" = "Lasso",
                        "unireg" = "uniReg",
                        "least_squares" = "LS"))

# Build labels: 1 decimal; if >100 use scientific with 1 sig decimal; if <0.1 use 4 decimals
plot_mse_data2 <- plot_mse_data %>%
  mutate(
    mean_label = case_when(
      mean_mse < 0.1 ~ formatC(mean_mse, format = "e", digits = 2),
      mean_mse > 1000 ~ formatC(mean_mse, format = "e", digits = 2),
      TRUE ~ sprintf("%.1f", mean_mse)
    ),
    sd_label = case_when(
      sd_mse < 0.08 ~ formatC(sd_mse, format = "e", digits = 2),
      sd_mse > 1000 ~ formatC(sd_mse, format = "e", digits = 2),
      TRUE ~ sprintf("%.1f", sd_mse)
    ),
    label_text = paste0(mean_label, " ± ", sd_label)
  )



method_colors <- c(
  "uniLasso" = "#e75480",      # medium pink
  "Polish" = "#f7b6d2",        # light pink
  "uniReg" = "#c71585",        # dark pink/magenta
  "Lasso" = "#1f77b4",      # medium blue
  "LS" = "#aec7e8"           # light blue
)

  # Order datasets for consistent facetting
desired_order <- c(
  "ca_housing", "debutanizer", "insurance", "kin8nm", 
  "computer", "elevator", "energy_efficiency", "miami_housing", "naval_propulsion",
  "diamond", "protein_structure", "qsar"
)


plot_mse_data2$dataset <- factor(plot_mse_data2$dataset, levels = desired_order)

plot_mse_data2$method <- factor(plot_mse_data2$method, levels = c("LS", "Lasso", "uniReg", "uniLasso", "Polish"))

plot_mse_data2$dataset <- recode(plot_mse_data2$dataset,
                            "ca_housing" = "CA housing",
                            "debutanizer" = "Debutanizer",
                            "insurance" = "Insurance",
                            "kin8nm" = "Kin8nm",
                            "computer" = "Computer",
                            "elevator" = "Elevator",
                            "energy_efficiency" = "Energy efficiency",
                            "miami_housing" = "Miami housing",
                            "naval_propulsion" = "Naval propulsion",
                            "diamond" = "Diamond",
                            "protein_structure" = "Protein structure",
                            "qsar" = "QSAR"
)


p_mse_error <- ggplot(plot_mse_data2, aes(x = method, y = mean_mse, fill = method)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.8, alpha = 0.7) +  # wider bars
  geom_errorbar(aes(ymin = mean_mse - sd_mse, ymax = mean_mse + sd_mse),
                position = position_dodge(width = 0.6),
                width = 0.25, alpha = 0.8) +
  # Label means on top of bars, tilted 45 degrees
  geom_text(aes(label = label_text),
            position = position_dodge(width = 0.6),
            vjust = -1.2, size = 4, angle = 75, hjust = -0.1,
            family = "Times New Roman") +
  # Facet with per-facet axes
  ggh4x::facet_wrap2(
    ~ dataset,
    nrow = ceiling(length(unique(plot_mse_data$dataset))/4),
    ncol = 4,
    scales = "free_y",
    axes = "x"
  ) +
  labs(
    #title = "Mean MSE with Standard Deviation Bars (100 Bootstrap Results)",
    x = "Method",
    y = "Mean MSE",
    fill = "Method"
  ) +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 14, family = "Times New Roman", face="bold"),  # increase tick label font size
    axis.text.y = element_text(size = 16, family = "Times New Roman", face = "bold"),  # ADD THIS LINE
    axis.title.x = element_text(size = 18, family = "Times New Roman", face="bold"),  # x-axis title font size
    axis.title.y = element_text(size = 18, family = "Times New Roman", face="bold"),  # y-axis title font size
    legend.position = "bottom",
    legend.text = element_text(size = 18, family = "Times New Roman", face="bold"),
    legend.title = element_text(size = 18, family = "Times New Roman", face="bold"),
    strip.text = element_text(size = 18, family = "Times New Roman", face="bold")  # ADD THIS LINE - makes facet titles larger
  )+
  scale_y_continuous(expand = expansion(mult = c(0, 0.7)))

print(p_mse_error)

ggsave("/accounts/grad/aqwang/unilasso/figures/mse_boot_12data.png", plot = p_mse_error, width = 16, height = 16, dpi = 300)



# make choose label_text plot_mse_data2 a wide format 
plot_mse_data_wide <- plot_mse_data2 %>%
  select(dataset, method, label_text) %>%
  pivot_wider(names_from = method, values_from = label_text)
print(plot_mse_data_wide)


summary_boot_support <- boot_results %>%
  group_by(dataset) %>%
  summarise(
    # Support size statistics
    unilasso_loo_true_mean_support = mean(unilasso_loo_true_support, na.rm = TRUE),
    unilasso_loo_true_sd_support = sd(unilasso_loo_true_support, na.rm = TRUE),
    polish_unilasso_mean_support = mean(polish_unilasso_support, na.rm = TRUE),
    polish_unilasso_sd_support = sd(polish_unilasso_support, na.rm = TRUE),
    lasso_cv_mean_support = mean(lasso_cv_support, na.rm = TRUE),
    lasso_cv_sd_support = sd(lasso_cv_support, na.rm = TRUE),
    unireg_mean_support = mean(unireg_support, na.rm = TRUE),
    unireg_sd_support = sd(unireg_support, na.rm = TRUE),
    least_squares_mean_support = mean(least_squares_support, na.rm = TRUE),
    least_squares_sd_support = sd(least_squares_support, na.rm = TRUE),
    .groups = 'drop'
  )

# support size plot with error bars
# Create a single pivot that handles both mean and SD columns together
plot_support_data <- summary_boot_support %>%
  pivot_longer( 
    cols = c(unilasso_loo_true_mean_support, 
             polish_unilasso_mean_support, lasso_cv_mean_support,
             unireg_mean_support, least_squares_mean_support,
             unilasso_loo_true_sd_support, 
             polish_unilasso_sd_support, lasso_cv_sd_support,
             unireg_sd_support, least_squares_sd_support),
    names_to = c("method", "statistic"),
    values_to = "value",
    names_pattern = "(.*)_(mean_support|sd_support)"
  ) %>%
  # Pivot wider to get mean_support and sd_support as separate columns
  pivot_wider(
    names_from = statistic,
    values_from = value
  ) %>%
  # Clean up method names
  mutate(method = recode(method,
                        "unilasso_loo_true" = "uniLasso",
                        "polish_unilasso" = "Polish",
                        "lasso_cv" = "Lasso",
                        "unireg" = "uniReg",
                        "least_squares" = "LS"
                        ))

# Build labels: 1 decimal for support (since it's typically whole numbers, use 1 decimal)
plot_support_data2 <- plot_support_data %>%
  mutate(
    mean_label = sprintf("%.1f", mean_support),
    sd_label = sprintf("%.1f", sd_support),
    label_text = paste0(mean_label, " ± ", sd_label)
  )

  # Order datasets for consistent facetting
desired_order <- c(
  "ca_housing", "debutanizer", "insurance", "kin8nm", 
  "computer", "elevator", "energy_efficiency", "miami_housing", "naval_propulsion",
  "diamond", "protein_structure", "qsar"
)
plot_support_data2$dataset <- factor(plot_support_data2$dataset, levels = desired_order)


 plot_support_data2$dataset <- recode(plot_support_data2$dataset,
                            "ca_housing" = "CA housing",
                            "debutanizer" = "Debutanizer",
                            "insurance" = "Insurance",
                            "kin8nm" = "Kin8nm",
                            "computer" = "Computer",
                            "elevator" = "Elevator",
                            "energy_efficiency" = "Energy efficiency",
                            "miami_housing" = "Miami housing",
                            "naval_propulsion" = "Naval propulsion",
                            "diamond" = "Diamond",
                            "protein_structure" = "Protein structure",
                            "qsar" = "QSAR"
)



plot_support_data2$method <- factor(plot_support_data2$method, levels = c("LS", "Lasso", "uniReg", "uniLasso", "Polish"))

p_support_error <- ggplot(plot_support_data2, aes(x = method, y = mean_support, fill = method)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.8, alpha = 0.7) +  # wider bars
  geom_errorbar(aes(ymin = mean_support - sd_support, ymax = mean_support + sd_support),
                position = position_dodge(width = 0.6),
                width = 0.25, alpha = 0.8) +
  # Label means on top of bars, tilted 45 degrees
  geom_text(aes(label = label_text),
            position = position_dodge(width = 0.6), 
            vjust = -1.2, size = 4, angle = 75, hjust = -0.1, family="Times New Roman") +
  # Facet with per-facet axes
  ggh4x::facet_wrap2(
    ~ dataset,
    nrow = ceiling(length(unique(plot_support_data$dataset))/4),
    ncol = 4,
    scales = "free_y",
    axes = "x"
  ) +
  labs(
    #title = "Mean Support Size with Standard Deviation Bars (100 Bootstrap Results)",
    x = "Method",
    y = "Mean support ize",
    fill = "Method"
  ) +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 14, family = "Times New Roman", face = "bold"),  # increase tick label font size
    axis.text.y = element_text(size = 16, family = "Times New Roman", face = "bold"),  # ADD THIS LINE
    axis.title.x = element_text(size = 18, family = "Times New Roman", face = "bold"),  # x-axis title font size
    axis.title.y = element_text(size = 18, family = "Times New Roman", face = "bold"),  # y-axis title font size
    legend.position = "bottom",
    legend.text = element_text(size = 18, family = "Times New Roman", face = "bold"),
    legend.title = element_text(size = 18, family = "Times New Roman", face = "bold"),
    strip.text = element_text(size = 18, family = "Times New Roman", face = "bold")  # facet titles larger and bold
  )+
  scale_y_continuous(expand = expansion(mult = c(0, 0.6)))
print(p_support_error)
ggsave("/accounts/grad/aqwang/unilasso/figures/size_boot_12data.png", plot = p_support_error, width = 16, height = 16, dpi = 300)





# Make a wide format table for support data
plot_support_data_wide <- plot_support_data2 %>%
  select(dataset, method, label_text) %>%
  pivot_wider(names_from = method, values_from = label_text)
print(plot_support_data_wide)

# scatter plot of support size for each dataset colored by method (use facet_wrap2 to make 5 columns and 4 rows)
library(ggplot2)
library(dplyr)
library(tidyr)
library(ggh4x)
library(patchwork)

# Prepare long data
support_long <- boot_results %>%
  select(dataset, bootstrap_id,
         lasso_cv_support,
         unilasso_loo_true_support,
         polish_unilasso_support, 
          unireg_support,
          least_squares_support) %>%
  pivot_longer(
    cols = -c(dataset, bootstrap_id),
    names_to = "method_raw",
    values_to = "support"
  ) %>%
  mutate(
    method = recode(method_raw,
      lasso_cv_support           = "Lasso",
      unilasso_loo_true_support  = "uniLasso",
      polish_unilasso_support    = "Polish",
      unireg_support             = "uniReg",
      least_squares_support      = "LS"
    ),
    method = factor(method, levels = c("Lasso", "uniLasso",
                                       "Polish", "uniReg", "LS"))
  )

# a function to draw one dataset's scatter with its own axes & title
plot_one_ds <- function(ds) {
  ggplot(filter(support_long, dataset == ds),
         aes(x = bootstrap_id, y = support, color = method)) +
    geom_point(alpha = 0.5, size = 1,   # lower alpha for more transparency
               position = position_jitter(width = 0.3, height = 0)) +
    labs(title = ds,
       x = "Bootstrap sample",          # <-- appears under THIS panel
       y = "Support size",
       color = "Method") +
    scale_color_manual(
      values = c(
      "Lasso" = "orange",
      "LS" = "pink",
      "uniReg" = "blue",
      "uniLasso" = "black",
      "Polish" = "purple"
      )+
    theme(
      plot.title = element_text(size = 12, hjust = 0.5),
      axis.text.x = element_text(size = 7),
      axis.text.y = element_text(size = 8),
      legend.position = "none"            # legend will be collected later
    )
}

plots <- lapply(unique(support_long$dataset), plot_one_ds)

# arrange in a grid (5 per row) and collect one common legend
# add plot.margin to each plot to increase space between rows
plots_spaced <- lapply(plots, function(p) p + theme(plot.margin = margin(t = 10, b = 30)))
p_support <- wrap_plots(plots_spaced, ncol = 5, guides = "collect") &
  theme(
    legend.position = "bottom",
    legend.title = element_text(size = 20)
  )
p_support


# for prediction interval, make a plot of average width of prediction interval for each dataset with standard error bar
pred_int <- read.csv("/accounts/grad/aqwang/unilasso/analysis/bootstrap_result/unilasso_12datasets_100bootstrap_prediction_intervals.csv")

# graph the mean width of prediction interval for all 4 methods for each dataset
library(ggplot2)
library(dplyr)

# mean and sd is already calculated in pred_int
# pred_int is a long format
pred_int <- pred_int %>%
  mutate(
    method = recode(method,
                    "lasso_cv" = "Lasso",
                    "uniLasso_loo_true" = "uniLasso",
                    "polish_uniLasso" = "Polish",
                    "unireg" = "uniReg",
                    "least_squares" = "LS")
  )

# DELETE unilasso_loo_false method from pred_int
pred_int <- pred_int %>%
  filter(method != "uniLasso_loo_false")

# Build labels: 1 decimal; if >100 use scientific with 1 sig decimal; if <0.1 use 4 decimals
pred_int2 <- pred_int %>%
  mutate(
    mean_label = case_when(
      avg_interval_width < 0.1 ~ formatC(avg_interval_width, format = "e",  digits = 2),
      avg_interval_width > 100 ~ formatC(avg_interval_width, format = "e", digits = 2),
      TRUE ~ sprintf("%.2f", avg_interval_width)
    ),
    sd_label = case_when(
      sd_interval_width < 0.1 ~ formatC(sd_interval_width, format = "e",  digits = 2),
      sd_interval_width > 100 ~ formatC(sd_interval_width, format = "e", digits = 2),
      TRUE ~ sprintf("%.2f",  sd_interval_width)
    ),
    label_text = paste0(mean_label, " ± ", sd_label)
  )


method_colors <- c(
  "uniLasso" = "#e75480",      # medium pink
  "Polish" = "#f7b6d2",        # light pink
  "uniReg" = "#c71585",        # dark pink/magenta
  "Lasso" = "#1f77b4",      # medium blue
  "LS" = "#aec7e8"           # light blue
)

  # Order datasets for consistent facetting
desired_order <- c(
  "ca_housing", "debutanizer", "insurance", "kin8nm", 
  "computer", "elevator", "energy_efficiency", "miami_housing", "naval_propulsion",
  "diamond", "protein_structure", "qsar"
)


pred_int2$dataset <- factor(pred_int2$dataset, levels = desired_order)
pred_int2$method <- factor(pred_int2$method, levels = c("LS", "Lasso", "uniReg", "uniLasso", "Polish"))
pred_int2$dataset <- recode(pred_int2$dataset,
                            "ca_housing" = "CA housing",
                            "debutanizer" = "Debutanizer",
                            "insurance" = "Insurance",
                            "kin8nm" = "Kin8nm",
                            "computer" = "Computer",
                            "elevator" = "Elevator",
                            "energy_efficiency" = "Energy efficiency",
                            "miami_housing" = "Miami housing",
                            "naval_propulsion" = "Naval propulsion",
                            "diamond" = "Diamond",
                            "protein_structure" = "Protein structure",
                            "qsar" = "QSAR"
)


p_pred_int <- ggplot(pred_int2, aes(x = method, y = avg_interval_width, fill = method)) +
  geom_col(position = position_dodge(width = 0.9), width = 0.9, alpha = 0.7) +  # wider bars
  geom_errorbar(aes(ymin = avg_interval_width - sd_interval_width, ymax = avg_interval_width + sd_interval_width),
                position = position_dodge(width = 0.6),
                width = 0.25, alpha = 0.8) +
  # Label means on top of bars, tilted 45 degrees
  geom_text(aes(label = label_text),  
            position = position_dodge(width = 0.6),
            vjust = -1.7, size = 3.8, angle = 80, hjust = -0.3, family = "Times New Roman") +
  # Facet with per-facet axes
  ggh4x::facet_wrap2(
    ~ dataset,
    nrow = ceiling(length(unique(pred_int$dataset))/4),
    ncol = 4,
    scales = "free_y",
    axes = "x"
  ) +
  labs(
    # title = "Mean Width of Prediction Interval with Standard Deviation Bars (100 Bootstrap Results)",
    x = "Method", 
    y = "Mean width of prediction interval",
    fill = "Method"
  ) +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 14, family = "Times New Roman", face = "bold"),  # increase tick label font size
    axis.text.y = element_text(size = 16, family = "Times New Roman", face = "bold"),  # ADD THIS LINE
    axis.title.x = element_text(size = 18, family = "Times New Roman", face = "bold"),  # x-axis title font size
    axis.title.y = element_text(size = 18, family = "Times New Roman", face = "bold"),  # y-axis title font size
    legend.position = "bottom",
    legend.text = element_text(size = 18, family = "Times New Roman", face = "bold"),
    legend.title = element_text(size = 18, family = "Times New Roman", face = "bold"),
    strip.text = element_text(size = 18, family = "Times New Roman", face = "bold")  # facet titles larger and bold
  )+
  scale_y_continuous(expand = expansion(mult = c(0, 0.7)))
print(p_pred_int) 
ggsave("/accounts/grad/aqwang/unilasso/figures/pred_int_12data.png", plot = p_pred_int, width = 16, height = 17, dpi = 300)



# make a wide format table for prediction interval data
pred_int_wide <- pred_int2 %>%
  select(dataset, method, label_text) %>%
  pivot_wider(names_from = method, values_from = label_text)
print(pred_int_wide)

library(dplyr)
library(tidyr)


pred_int_coverage <- pred_int %>%
  select(dataset, method, coverage) %>%
  pivot_wider(names_from = method, values_from = coverage) %>%
  select(dataset, LS, Lasso, uniReg, uniLasso, Polish) %>%
  mutate(across(-dataset, ~ round(., 3)))

# Calculate row averages (across methods for each dataset), rounded to 3 decimal places
pred_int_coverage$row_avg <- round(rowMeans(pred_int_coverage[, c("LS", "Lasso", "uniReg", "uniLasso", "Polish")], na.rm = TRUE), 3)

# Calculate column averages (across datasets for each method)
col_avgs <- colMeans(pred_int_coverage[, c("LS", "Lasso", "uniReg", "uniLasso", "Polish", "row_avg")], na.rm = TRUE)

# Optionally, print column averages
print(col_avgs)

# add col avg to the bottom of pred_int_coverage
pred_int_coverage <- rbind(pred_int_coverage, c("Column Average", round(col_avgs, 3)))

# save as csv
write.csv(pred_int_coverage, "/accounts/grad/aqwang/unilasso/figures/pred_int_coverage_12datasets.csv", row.names = FALSE)



```

# final version: updated bootstrap results with uniReg for 22 datasets 9/16 Tuesday
```{r load updated bootstrap results and make some plots}
boot_results <- read.csv("/accounts/grad/aqwang/unilasso/analysis/random_split_result/unilasso_22datasets_100splits_train50percent_results.csv")

# rename dataset names to match previous naming convention
boot_results$dataset <- recode(boot_results$dataset,
                            "airfoil" = "Airfoil",
                            "appliances_energy" = "Appliances energy",
                            "auto_mpg" = "Auto MPG",
                            "automobile" = "Automobile",
                            "beijing_pm2.5" = "Beijing PM2.5",
                            "bike_sharing" = "Bike sharing",
                            "concrete" = "Concrete",
                            "crime" = "Crime",
                            "crime_unnormalized" = "Crime unnormalized",
                            "daily_demand" = "Daily demand",
                            "facebook_metrics" = "Facebook metrics",
                            "forest_fires" = "Forest fires",
                            "infrared_thermo_temp" = "Infrared thermo temp",
                            "liver_disorders" = "Liver disorders",
                            "metro_traffic" = "Metro traffic",
                            "parkinsons" = "Parkinsons",
                            "power_consumption" = "Power consumption",
                            "power_plant" = "Power plant",
                            "real_estate" = "Real estate",
                            "servo" = "Servo",
                            "stock_portfolio" = "Stock portfolio",
                            "superconductivity" = "Superconductivity" )


# print the unique names in results_all_splits$dataset to verify
print(unique(boot_results$dataset))

# calculate the support size mean and sd for each dataset and method
library(dplyr)
summary_boot_MSE <- boot_results %>%
  group_by(dataset) %>%
  summarise(
    # MSE statistics
    unilasso_loo_true_mean_mse = mean(unilasso_loo_true_mse, na.rm = TRUE),
    unilasso_loo_true_sd_mse = sd(unilasso_loo_true_mse, na.rm = TRUE),
    unilasso_loo_false_mean_mse = mean(unilasso_loo_false_mse, na.rm = TRUE),
    unilasso_loo_false_sd_mse = sd(unilasso_loo_false_mse, na.rm = TRUE),
    polish_unilasso_mean_mse = mean(polish_unilasso_mse, na.rm = TRUE),
    polish_unilasso_sd_mse = sd(polish_unilasso_mse, na.rm = TRUE),
    lasso_cv_mean_mse = mean(lasso_cv_mse, na.rm = TRUE),
    lasso_cv_sd_mse = sd(lasso_cv_mse, na.rm = TRUE),
    unireg_mean_mse = mean(unireg_mse, na.rm = TRUE),
    unireg_sd_mse = sd(unireg_mse, na.rm = TRUE),
    least_squares_mean_mse = mean(least_squares_mse, na.rm = TRUE),
    least_squares_sd_mse = sd(least_squares_mse, na.rm = TRUE),
    .groups = 'drop' )

#drop unilasso_loo_false method from the summary_boot_MSE
summary_boot_MSE <- summary_boot_MSE %>%
  select(-c(unilasso_loo_false_mean_mse, unilasso_loo_false_sd_mse))

library(ggplot2)
library(tidyr)
library(dplyr)

# 1. MSE Plot with Error Bars
# Create a single pivot that handles both mean and SD columns together
plot_mse_data <- summary_boot_MSE %>%
  pivot_longer( 
    cols = c(unilasso_loo_true_mean_mse, 
             polish_unilasso_mean_mse, lasso_cv_mean_mse,
             unireg_mean_mse, least_squares_mean_mse,
             unilasso_loo_true_sd_mse, 
             polish_unilasso_sd_mse, lasso_cv_sd_mse,
             unireg_sd_mse, least_squares_sd_mse),
    names_to = c("method", "statistic"),
    values_to = "value",
    names_pattern = "(.*)_(mean_mse|sd_mse)"
  ) %>%
  # Pivot wider to get mean_mse and sd_mse as separate columns
  pivot_wider(
    names_from = statistic,
    values_from = value
  ) %>%
  # Keep mean_mse and sd_mse as numeric for plotting
  # Clean up method names
  mutate(method = recode(method,
                        "unilasso_loo_true" = "uniLasso",
                        "polish_unilasso" = "Polish",
                        "lasso_cv" = "Lasso",
                        "unireg" = "uniReg",
                        "least_squares" = "LS"))

# Build labels: 1 decimal; if >100 use scientific with 1 sig decimal; if <0.1 use 4 decimals
plot_mse_data2 <- plot_mse_data %>%
  mutate(
    mean_label = case_when(
      mean_mse < 0.1 ~ formatC(mean_mse, format = "e", digits = 2),
      mean_mse > 100 ~ formatC(mean_mse, format = "e", digits = 2),
      TRUE ~ sprintf("%.1f", mean_mse)
    ),
    sd_label = case_when(
      sd_mse < 0.1 ~ formatC(sd_mse, format = "e", digits = 2),
      sd_mse > 100 ~ formatC(sd_mse, format = "e", digits = 2),
      TRUE ~ sprintf("%.1f", sd_mse)
    ),
    label_text = paste0(mean_label, " ± ", sd_label)
  )


plot_mse_data2$method <- factor(plot_mse_data2$method, levels = c("LS", "Lasso", "uniReg", "uniLasso", "Polish"))


method_colors <- c(
  "uniLasso" = "#e75480",      # medium pink
  "Polish" = "#f7b6d2",        # light pink
  "uniReg" = "#c71585",        # dark pink/magenta
  "Lasso" = "#1f77b4",      # medium blue
  "LS" = "#aec7e8"           # light blue
)


p_mse_error <- ggplot(plot_mse_data2, aes(x = method, y = mean_mse, fill = method)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.8, alpha = 0.7) +  # wider bars
  geom_errorbar(aes(ymin = mean_mse - sd_mse, ymax = mean_mse + sd_mse),
                position = position_dodge(width = 0.6),
                width = 0.25, alpha = 0.8) +
  # Label means on top of bars, tilted 45 degrees
  geom_text(aes(label = label_text),
            position = position_dodge(width = 1),
            vjust = -2, size = 3.3, angle = 75, hjust = 0, family = "Times New Roman") +
  # Facet with per-facet axes
  ggh4x::facet_wrap2(
    ~ dataset,
    nrow = ceiling(length(unique(plot_mse_data$dataset))/5),
    ncol = 5,
    scales = "free_y",
    axes = "x"
  ) +
  labs(
    #title = "Mean MSE with Standard Deviation Bars (100 Bootstrap Results)",
    x = "Method",
    y = "Mean MSE",
    fill = "Method"
  ) +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 14, family = "Times New Roman", face="bold"),  # increase tick label font size
    axis.text.y = element_text(size = 16, family = "Times New Roman", face = "bold"),  # ADD THIS LINE
    axis.title.x = element_text(size = 18, family = "Times New Roman", face="bold"),  # x-axis title font size
    axis.title.y = element_text(size = 18, family = "Times New Roman", face="bold"),  # y-axis title font size
    legend.position = "bottom",
    legend.text = element_text(size = 18, family = "Times New Roman", face="bold"),
    legend.title = element_text(size = 18, family = "Times New Roman", face="bold"),
    strip.text = element_text(size = 18, family = "Times New Roman", face="bold")  # ADD THIS LINE - makes facet titles larger
  )+
  scale_y_continuous(expand = expansion(mult = c(0, 1.5)))

print(p_mse_error)
ggsave("/accounts/grad/aqwang/unilasso/figures/mse_boot_22data.png", plot = p_mse_error, width = 16, height = 18, dpi = 300)


# make choose label_text plot_mse_data2 a wide format 
plot_mse_data_wide <- plot_mse_data2 %>%
  select(dataset, method, label_text) %>%
  pivot_wider(names_from = method, values_from = label_text)
print(plot_mse_data_wide)


summary_boot_support <- boot_results %>%
  group_by(dataset) %>%
  summarise(
    # Support size statistics
    unilasso_loo_true_mean_support = mean(unilasso_loo_true_support, na.rm = TRUE),
    unilasso_loo_true_sd_support = sd(unilasso_loo_true_support, na.rm = TRUE),
    polish_unilasso_mean_support = mean(polish_unilasso_support, na.rm = TRUE),
    polish_unilasso_sd_support = sd(polish_unilasso_support, na.rm = TRUE),
    lasso_cv_mean_support = mean(lasso_cv_support, na.rm = TRUE),
    lasso_cv_sd_support = sd(lasso_cv_support, na.rm = TRUE),
    unireg_mean_support = mean(unireg_support, na.rm = TRUE),
    unireg_sd_support = sd(unireg_support, na.rm = TRUE),
    least_squares_mean_support = mean(least_squares_support, na.rm = TRUE),
    least_squares_sd_support = sd(least_squares_support, na.rm = TRUE),
    .groups = 'drop'
  )

# support size plot with error bars
# Create a single pivot that handles both mean and SD columns together
plot_support_data <- summary_boot_support %>%
  pivot_longer( 
    cols = c(unilasso_loo_true_mean_support, 
             polish_unilasso_mean_support, lasso_cv_mean_support,
             unireg_mean_support, least_squares_mean_support,
             unilasso_loo_true_sd_support, 
             polish_unilasso_sd_support, lasso_cv_sd_support,
             unireg_sd_support, least_squares_sd_support),
    names_to = c("method", "statistic"),
    values_to = "value",
    names_pattern = "(.*)_(mean_support|sd_support)"
  ) %>%
  # Pivot wider to get mean_support and sd_support as separate columns
  pivot_wider(
    names_from = statistic,
    values_from = value
  ) %>%
  # Clean up method names
  mutate(method = recode(method,
                        "unilasso_loo_true" = "uniLasso",
                        "polish_unilasso" = "Polish",
                        "lasso_cv" = "Lasso",
                        "unireg" = "uniReg",
                        "least_squares" = "LS"
                        ))

# Build labels: 1 decimal for support (since it's typically whole numbers, use 1 decimal)
plot_support_data2 <- plot_support_data %>%
  mutate(
    mean_label = sprintf("%.1f", mean_support),
    sd_label = sprintf("%.1f", sd_support),
    label_text = paste0(mean_label, " ± ", sd_label)
  )

p_support_error <- ggplot(plot_support_data2, aes(x = method, y = mean_support, fill = method)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.8, alpha = 0.7) +  # wider bars
  geom_errorbar(aes(ymin = mean_support - sd_support, ymax = mean_support + sd_support),
                position = position_dodge(width = 0.6),
                width = 0.25, alpha = 0.8) +
  # Label means on top of bars, tilted 45 degrees
  geom_text(aes(label = label_text),
            position = position_dodge(width = 1), 
            vjust = -2, size = 3.3, angle = 75, hjust = 0, family = "Times New Roman") +
  # Facet with per-facet axes
  ggh4x::facet_wrap2(
    ~ dataset,
    nrow = ceiling(length(unique(plot_support_data$dataset))/5),
    ncol = 5,
    scales = "free_y",
    axes = "x"
  ) +
  labs(
    #title = "Mean Support Size with Standard Deviation Bars (100 Bootstrap Results)",
    x = "Method",
    y = "Mean Support Size",
    fill = "Method"
  ) +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 14, family = "Times New Roman", face="bold"),  # increase tick label font size
    axis.text.y = element_text(size = 16, family = "Times New Roman", face = "bold"),  # ADD THIS LINE
    axis.title.x = element_text(size = 18, family = "Times New Roman", face="bold"),  # x-axis title font size
    axis.title.y = element_text(size = 18, family = "Times New Roman", face="bold"),  # y-axis title font size
    legend.position = "bottom",
    legend.text = element_text(size = 18, family = "Times New Roman", face="bold"),
    legend.title = element_text(size = 18, family = "Times New Roman", face="bold"),
    strip.text = element_text(size = 18, family = "Times New Roman", face="bold")  # ADD THIS LINE - makes facet titles larger
  )+
  scale_y_continuous(expand = expansion(mult = c(0, 0.8)))
print(p_support_error)
ggsave("/accounts/grad/aqwang/unilasso/figures/supp_boot_22data.png", plot = p_support_error, width = 16, height = 18, dpi = 300)



# Make a wide format table for support data
plot_support_data_wide <- plot_support_data2 %>%
  select(dataset, method, label_text) %>%
  pivot_wider(names_from = method, values_from = label_text)
print(plot_support_data_wide)

# scatter plot of support size for each dataset colored by method (use facet_wrap2 to make 5 columns and 4 rows)
library(ggplot2)
library(dplyr)
library(tidyr)
library(ggh4x)
library(patchwork)

# Prepare long data
support_long <- boot_results %>%
  select(dataset, bootstrap_id,
         lasso_cv_support,
         unilasso_loo_true_support,
         polish_unilasso_support, 
          unireg_support,
          least_squares_support) %>%
  pivot_longer(
    cols = -c(dataset, bootstrap_id),
    names_to = "method_raw",
    values_to = "support"
  ) %>%
  mutate(
    method = recode(method_raw,
      lasso_cv_support           = "Lasso",
      unilasso_loo_true_support  = "uniLasso",
      polish_unilasso_support    = "Polish",
      unireg_support             = "uniReg",
      least_squares_support      = "LS"
    ),
    method = factor(method, levels = c("Lasso", "uniLasso",
                                       "Polish", "uniReg", "LS"))
  )

# a function to draw one dataset's scatter with its own axes & title
plot_one_ds <- function(ds) {
  ggplot(filter(support_long, dataset == ds),
         aes(x = bootstrap_id, y = support, color = method)) +
    geom_point(alpha = 0.5, size = 1,   # lower alpha for more transparency
               position = position_jitter(width = 0.3, height = 0)) +
    labs(title = ds,
       x = "Bootstrap sample",          # <-- appears under THIS panel
       y = "Support size",
       color = "Method") +
    scale_color_manual(
      values = c(
      "Lasso" = "orange",
      "LS" = "pink",
      "uniReg" = "blue",
      "uniLasso" = "black",
      "Polish" = "purple"
      ))+
    theme(
      plot.title = element_text(size = 12, hjust = 0.5),
      axis.text.x = element_text(size = 7),
      axis.text.y = element_text(size = 8),
      legend.position = "none"            # legend will be collected later
    )
}

plots <- lapply(unique(support_long$dataset), plot_one_ds)

# arrange in a grid (5 per row) and collect one common legend
# add plot.margin to each plot to increase space between rows
plots_spaced <- lapply(plots, function(p) p + theme(plot.margin = margin(t = 10, b = 30)))
p_support <- wrap_plots(plots_spaced, ncol = 5, guides = "collect") &
  theme(
    legend.position = "bottom",
    legend.title = element_text(size = 20)
  )
p_support


# for prediction interval, make a plot of average width of prediction interval for each dataset with standard error bar
pred_int <- read.csv("/accounts/grad/aqwang/unilasso/analysis/bootstrap_result/unilasso_22datasets_100bootstrap_prediction_intervals.csv")

# print the unique names in results_all_splits$dataset to verify
print(unique(pred_int$dataset))

#rename dataset names to match previous naming convention
pred_int$dataset <- recode(pred_int$dataset,
                          "airfoil" = "Airfoil",
                            "appliances_energy" = "Appliances energy",
                            "auto_mpg" = "Auto MPG",
                            "automobile" = "Automobile",
                            "beijing_pm2.5" = "Beijing PM2.5",
                            "bike_sharing" = "Bike sharing",
                            "concrete" = "Concrete",
                            "crime" = "Crime",
                            "crime_unnormalized" = "Crime unnormalized",
                            "daily_demand" = "Daily demand",
                            "facebook_metrics" = "Facebook metrics",
                            "forest_fires" = "Forest fires",
                            "infrared_thermo_temp" = "Infrared thermo temp",
                            "liver_disorders" = "Liver disorders",
                            "metro_traffic" = "Metro traffic",
                            "parkinsons" = "Parkinsons",
                            "power_consumption" = "Power consumption",
                            "power_plant" = "Power plant",
                            "real_estate" = "Real estate",
                            "servo" = "Servo",
                            "stock_portfolio" = "Stock portfolio",
                            "superconductivity" = "Superconductivity")

# graph the mean width of prediction interval for all 4 methods for each dataset
library(ggplot2)
library(dplyr)

# mean and sd is already calculated in pred_int
# pred_int is a long format
pred_int <- pred_int %>%
  mutate(
    method = recode(method,
                    "lasso_cv" = "Lasso",
                    "uniLasso_loo_true" = "uniLasso",
                    "polish_uniLasso" = "Polish",
                    "unireg" = "uniReg",
                    "least_squares" = "LS")
  )

# DELETE unilasso_loo_false method from pred_int
pred_int <- pred_int %>%
  filter(method != "uniLasso_loo_false")

# Build labels: 1 decimal; if >100 use scientific with 1 sig decimal; if <0.1 use 4 decimals
pred_int2 <- pred_int %>%
  mutate(
    mean_label = case_when(
      avg_interval_width < 0.1 ~ formatC(avg_interval_width, format = "e",  digits = 2),
      avg_interval_width > 100 ~ formatC(avg_interval_width, format = "e", digits = 2),
      TRUE ~ sprintf("%.2f", avg_interval_width)
    ),
    sd_label = case_when(
      sd_interval_width < 0.1 ~ formatC(sd_interval_width, format = "e",  digits = 2),
      sd_interval_width > 100 ~ formatC(sd_interval_width, format = "e", digits = 2),
      TRUE ~ sprintf("%.2f",  sd_interval_width)
    ),
    label_text = paste0(mean_label, " ± ", sd_label)
  )
p_pred_int <- ggplot(pred_int2, aes(x = method, y = avg_interval_width, fill = method)) +
  geom_col(position = position_dodge(width = 0.9), width = 0.9, alpha = 0.7) +  # wider bars
  geom_errorbar(aes(ymin = avg_interval_width - sd_interval_width, ymax = avg_interval_width + sd_interval_width),
                position = position_dodge(width = 0.6),
                width = 0.25, alpha = 0.8) +
  # Label means on top of bars, tilted 45 degrees
  geom_text(aes(label = label_text),  
            position = position_dodge(width = 1),
            vjust = -2, size = 3.3, angle = 80, hjust = 0, family = "Times New Roman") +
  # Facet with per-facet axes
  ggh4x::facet_wrap2(
    ~ dataset,
    nrow = ceiling(length(unique(pred_int$dataset))/5),
    ncol = 5,
    scales = "free_y",
    axes = "x"
  ) +
  labs(
    #title = "Mean Width of Prediction Interval with Standard Deviation Bars (100 Bootstrap Results)",
    x = "Method", 
    y = "Mean Width of Prediction Interval",
    fill = "Method"
  ) +
  scale_fill_manual(values = method_colors) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, size = 18, family = "Times New Roman", face = "bold"),
    axis.text.y = element_text(size = 16, family = "Times New Roman", face = "bold"),  # ADD THIS LINE
    axis.title = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.position = "bottom",
    legend.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    legend.title = element_text(size = 20, family = "Times New  Roman", face = "bold"),
    strip.text = element_text(size = 20, family = "Times New Roman", face = "bold"),
    strip.placement = "outside"
  ) +
  scale_y_continuous(expand = expansion(mult = c(0, 1)))
print(p_pred_int) 
ggsave("/accounts/grad/aqwang/unilasso/figures/appendix_22data_pred_int.png", 
       plot = p_pred_int, width = 16, height = 20, dpi = 300)

# make a wide format table for prediction interval data
pred_int_wide <- pred_int2 %>%
  select(dataset, method, label_text) %>%
  pivot_wider(names_from = method, values_from = label_text)
print(pred_int_wide)

library(dplyr)
library(tidyr)

pred_int_coverage <- pred_int %>% select(dataset, method, coverage) %>% pivot_wider(names_from = method, values_from = coverage) %>% select(dataset, LS, Lasso, uniReg, uniLasso, Polish) %>% mutate(across(-dataset, ~ round(., 3)))

# Calculate row averages (across methods for each dataset), rounded to 3 decimal places
pred_int_coverage$row_avg <- round(rowMeans(pred_int_coverage[, c("LS", "Lasso", "uniReg", "uniLasso", "Polish")], na.rm = TRUE), 3)

# Calculate column averages (across datasets for each method)
col_avgs <- colMeans(pred_int_coverage[, c("LS", "Lasso", "uniReg", "uniLasso", "Polish", "row_avg")], na.rm = TRUE)

# Optionally, print column averages
print(col_avgs)

# add col avg to the bottom of pred_int_coverage
pred_int_coverage <- rbind(pred_int_coverage, c("Column Average", round(col_avgs, 3)))

# save as csv
write.csv(pred_int_coverage, "/accounts/grad/aqwang/unilasso/figures/pred_int_coverage_22datasets.csv", row.names = FALSE)





```



# coverage 
```{r coverage of prediction interval}
library(dplyr)
library(tidyr)
pred_int <- read.csv("/accounts/grad/aqwang/unilasso/analysis/unilasso_17datasets_100bootstrap_prediction_intervals.csv")

pred_int_coverage <- pred_int %>% select(dataset, method, coverage) %>% pivot_wider(names_from = method, values_from = coverage)

```


# counter example 
```{r}
# take n=100, p=20, x1~N(0,1) X2=x1+N(0,1), beta=(1,-0.5,0,...,0), and error SD=0.5. similuate the data. remaining 18 features are also standard normal.
set.seed(123)
n <- 100
p <- 20
X <- matrix(rnorm(n * p), nrow = n, ncol = p)
X[, 2] <- X[, 1] + rnorm(n)  # make X2 correlated with X1
beta <- c(1, -0.5, rep(0, p - 2))
y <- X %*% beta + rnorm(n, sd = 0.5)
X <- as.data.frame(X)
colnames(X) <- paste0("X", 1:p)
y <- as.vector(y)

# check the correaltion of x2 and x1
cor(X$X1, X$X2)

# create train/test split with 67% training
set.seed(123)
train_indices <- sample(1:n, size = round(0.67 * n), replace = FALSE)
Xtr <- X[train_indices, ]
ytr <- y[train_indices]
Xte <- X[-train_indices, ]
yte <- y[-train_indices]

set.seed(123)  # Consistent folds within split, but different across splits
K <- 10
n <- nrow(Xtr)
foldid <- sample(rep(1:K, length.out = n))

# fit lasso with cv to find lambda
library(glmnet)
set.seed(123)
lasso_cv <- cv.glmnet(as.matrix(Xtr), ytr, alpha = 1, foldid = foldid)
# support size and MSE
lasso_support <- sum(coef(lasso_cv, s = "lambda.min") != 0) - 1  # minus 1 to exclude intercept
lasso_pred <- predict(lasso_cv, newx = as.matrix(Xte), s = "lambda.min")
lasso_mse <- mean((yte - lasso_pred)^2)
lasso_support
lasso_mse


# fit unilasso with loo=TRUE
library(uniLasso)
unilasso_cv <- cv.uniLasso(
        Xtr, ytr,
        family = "gaussian",
        loo = TRUE,
        lower.limits = 0,
        standardize = FALSE,
        foldid = foldid,
        nlambda = 100
      )
      
yte_pred_CV <- predict(unilasso_cv, newx = as.matrix(Xte), s = "lambda.min")
# support size and MSE
unilasso_support <-  sum(coef(unilasso_cv, s = "lambda.min")[-1] != 0)
unilasso_mse <- mean((yte - yte_pred_CV)^2)
unilasso_support
unilasso_mse

```


# Final version: counter example diagnosis
```{r}
library(ppcor)  # for partial correlations

diagnose_counterexample_ols <- function(X, y, cor_cut = 0.6) {
  X <- as.matrix(X); y <- as.numeric(y)

  ## 1) Univariate signs (OLS, one variable at a time)
  s_uni <- apply(X, 2, function(x) {
    b <- coef(lm(y ~ x))[[2]]
    sign(b)
  })

  ## 2) Multivariate signs (OLS on all variables)
  # Use lm(y ~ ., data = as.data.frame(X)) for multivariate OLS
  ols <- lm(y ~ ., data = as.data.frame(X))
  beta <- coef(ols)[-1]  # drop intercept
  aliased <- is.na(beta) # NA => not estimable (rank deficiency)
  if (any(aliased)) {
    message("OLS is rank-deficient for these columns: ",
            paste(names(beta)[aliased], collapse = ", "))
    beta[aliased] <- 0   # treat as not selected
  }
  s_multi <- sign(beta); names(s_multi) <- names(beta)

  ## 3) Violations: univariate vs multivariate sign mismatch on selected vars
  viol <- names(which(s_multi != 0 & s_uni[names(s_multi)] != s_multi))

  ## 4) Look for highly correlated correlated, opposite-sign partners (counter-example pattern)
  R <- cor(X)
  pairs <- list()  
  for (j in viol) {
    opp <- names(which(s_multi * s_multi[j] < 0))   # opposite multivariate sign
    if (length(opp)) {
      cand <- opp[R[j, opp, drop = FALSE] > cor_cut & !is.na(R[j, opp, drop = FALSE])]
      if (length(cand)) {
        k <- cand[which.max(R[j, cand])]

        # Format rho with 6 decimal places if not exactly 1
        rho_value <- R[j, k]
        rho_formatted <- sprintf("%.6f", rho_value)
        
        pairs[[j]] <- list(
          partner       = k,
          rho           = rho_formatted,
          sign_uni_j    = s_uni[j],
          sign_multi_j  = s_multi[j],
          sign_multi_k  = s_multi[k]
        )
      }
    }
  }

  list(
    violations = viol,
    evidence   = pairs,
    s_uni      = s_uni,
    s_multi    = s_multi,
    aliased    = names(which(aliased))
  )
}
######################################
# diamond dataset
X <- read.csv("/accounts/grad/aqwang/unilasso/datasets_12/diamond/X.csv", header = TRUE)
y<-read.csv("/accounts/grad/aqwang/unilasso/datasets_12/diamond/y.csv", header = FALSE)

# elevator dataset
X <- read.csv("/accounts/grad/aqwang/unilasso/datasets_12/elevator/X.csv", header = TRUE)
y<-read.csv("/accounts/grad/aqwang/unilasso/datasets_12/elevator/y.csv", header = FALSE)

# naval propulsion dataset
X <- read.csv("/accounts/grad/aqwang/unilasso/datasets_12/naval_propulsion/X.csv", header = TRUE)
y<-read.csv("/accounts/grad/aqwang/unilasso/datasets_12/naval_propulsion/y.csv", header = FALSE)

# split into training and test set
set.seed(123)
n <- nrow(X)
train_indices <- sample(1:n, size = round(0.5 * n), replace = FALSE)
Xtr <- X[train_indices, ]
ytr <- y[train_indices, ]
Xte <- X[-train_indices, ]
yte <- y[-train_indices, ]

# fit an OLS
ols <- lm(ytr ~ ., data = as.data.frame(Xtr))
summary(ols)
# check all coefficients
coef(ols)
# check the MSE
yte_pred_ols <- predict(ols, newdata = as.data.frame(Xte))
ols_mse <- mean((yte - yte_pred_ols)^2)
ols_mse
# count the number of nonzero coefficients
ols_support <- sum(coef(ols)[-1] != 0, na.rm=TRUE)  # minus 1 to exclude intercept
ols_support

# correlation matrix
cor_matrix <- cor(Xtr)
print(cor_matrix)


# check if diffSaTime2 duplicates another column
cor(Xtr$diffSaTime2, Xtr$diffSaTime1)
cor(Xtr$diffSaTime2, Xtr$diffSaTime3)
cor(Xtr$diffSaTime2, Xtr$diffSaTime4)

# number of columns in Xtr
ncol(Xtr)
qr(Xtr)$rank
# diffSaTime2 gets dropped in OLS bc is identical to (or a linear combination of) other columns:

# fit unilasso with loo=TRUE
library(uniLasso)
set.seed(123)  # Consistent folds within split, but different across splits
K <- 10
n <- nrow(Xtr)
foldid <- sample(rep(1:K, length.out = n))  
unilasso_cv <- cv.uniLasso(
        Xtr, ytr,
        family = "gaussian",
        loo = TRUE,
        lower.limits = 0,
        standardize = FALSE,
        foldid = foldid,
        nlambda = 100
      )

# the names of the features that has coefficient nonzero
unilasso_selected <- colnames(Xtr)[which(coef(unilasso_cv, s = "lambda.min")[-1] != 0)]
print(unilasso_selected)
# find the MSE
yte_pred_CV <- predict(unilasso_cv, newx = as.matrix(Xte), s = "lambda.min")
unilasso_mse <- mean((yte - yte_pred_CV)^2)
unilasso_mse

# fit unilasso with loo=TRUE using customized lambda grid
library(uniLasso)
set.seed(123)  # Consistent folds within split, but different across splits
K <- 10
n <- nrow(Xtr)
foldid <- sample(rep(1:K, length.out = n))  

# Get univariate info once (and re-use it so you don't recompute LOO every time)
info <- uniInfo(Xtr, ytr, family = "gaussian", loo = TRUE, nit = 2, eps = 0.0001)

# Build the stage-2 design 'xp' the same way cv.uniLasso does
xp <- info$F  # predictions from LOO univariate fits

# Find lambda_max on xp (first lambda from a short glmnet fit is fine)
lam_max <- glmnet::glmnet(xp, ytr, family = "gaussian", standardize = FALSE, lower.limits = 0)$lambda[1]

# Make your custom geometric path relative to lam_max
lambda_seq <- exp(seq(log(lam_max), log(lam_max * 1e-8), length.out = 300))

# Now run cv.uniLasso, passing the precomputed info and your lambda grid
unilasso_cv <- cv.uniLasso(
  Xtr, ytr,
  family = "gaussian",
  loo = TRUE,
  lower.limits = 0,
  standardize = FALSE,
  foldid = foldid,
  lambda = lambda_seq,
  info = info  # Pass the precomputed info to avoid recomputation
)

# the names of the features that has coefficient nonzero
unilasso_selected <- colnames(Xtr)[which(coef(unilasso_cv, s = "lambda.min")[-1] != 0)]
print(unilasso_selected)
# find the MSE
yte_pred_CV <- predict(unilasso_cv, newx = as.matrix(Xte), s = "lambda.min")
unilasso_mse <- mean((yte - yte_pred_CV)^2)
unilasso_mse






###unilasso-nosign
unilasso_nosign <- cv.uniLasso(
        Xtr, ytr,
        family = "gaussian",
        loo = TRUE,
        lower.limits = -Inf,
        standardize = FALSE,
        foldid = foldid,
        nlambda = 100
      )

# the names of the features that has coefficient nonzero
unilasso_selected_nosign <- colnames(Xtr)[which(coef(unilasso_nosign, s = "lambda.min")[-1] != 0)]
print(unilasso_selected_nosign)


# also fit a lasso model for comparison
library(glmnet)
set.seed(123)
lasso_cv <- cv.glmnet(as.matrix(Xtr), ytr, alpha = 1, foldid = foldid, standardize = TRUE)
lasso_selected <- colnames(Xtr)[which(coef(lasso_cv, s = "lambda.min")[-1] != 0)]
print(lasso_selected)
# find the MSE
lasso_pred <- predict(lasso_cv, newx = as.matrix(Xte), s = "lambda.min")
lasso_mse <- mean((yte - lasso_pred)^2)
lasso_mse
# support size and MSE
lasso_support <- sum(coef(lasso_cv, s = "lambda.min") != 0) - 1  # minus 1 to exclude intercept
#name of features that has coefficient nonzero
rownames(coef(lasso_cv, s = "lambda.min"))[which(coef(lasso_cv, s = "lambda.min")[-1] != 0)]
plot(lasso_cv$glmnet.fit, xvar = "lambda", label = TRUE, par(cex = 0.7))

#lasso_support
#lasso_mse

#############customized lambda grid for lasso ################ ######
# also fit a lasso model for comparison
library(glmnet)
set.seed(123)

## 0) (Recommended) standardize inside glmnet
std <- TRUE

## 1) Find glmnet's default lambda_max for your data
fit0 <- glmnet(as.matrix(Xtr), ytr, alpha = 1, standardize = std)
lambda_max <- fit0$lambda[1]        # starting (largest) λ on the default path

## 2) Decide how far toward OLS you want to go
##    e.g., 1e-8 of lambda_max (much smaller than the default 1e-4)
lambda_min <- lambda_max * 1e-8

## 3) Create a dense log-spaced grid from lambda_max down to lambda_min
nlam <- 300
lam_grid <- exp(seq(log(lambda_max), log(lambda_min), length.out = nlam))

## 4) Run CV on **your** grid (note: nlambda & lambda.min.ratio are ignored now)
p <- ncol(Xtr)  # avoid early truncation of the path
lasso_cv <- cv.glmnet(
  as.matrix(Xtr), ytr,
  family = "gaussian",
  alpha = 1,
  standardize = std,
  foldid = foldid,
  lambda = lam_grid,
  dfmax = p, pmax = p
)

lasso_selected <- colnames(Xtr)[which(coef(lasso_cv, s = "lambda.min")[-1] != 0)]
print(lasso_selected)
# find the MSE
lasso_pred <- predict(lasso_cv, newx = as.matrix(Xte), s = "lambda.min")
lasso_mse <- mean((yte - lasso_pred)^2)
lasso_mse
####################################


#find the correlation of feature z and variable y 
cor(Xtr$z, ytr)
#find correlation between univariate prediction of z and y
cor(lm(ytr ~ Xtr$z)$fitted.values, ytr)
cor(Xtr$x, ytr)

# find univariate coefficient for x and z 
coef(lm(ytr ~ Xtr$x)) #3108
coef(lm(ytr ~ Xtr$z)) # 4976
cor(Xtr$x, Xtr$z) 
######################################

#correlation matrix for X
correlation <- print(cor(X))


# check for counter example pattern in training set
res <- diagnose_counterexample_ols(Xtr, ytr, cor_cut = 0.6)
print(res)
# build a table for the correlatios among variables in Xtr
cor_matrix <- round(cor(Xtr), 2)
print(cor_matrix)


# repeat this process for all datasets in datasets_12 folder
# datasets names
dataset_names <- c(
  "ca_housing", "computer",
  "debutanizer", "diamond", "elevator", "energy_efficiency",
  "insurance", "kin8nm", "miami_housing", "naval_propulsion",
 "protein_structure", "qsar")

for (ds in dataset_names) {
  cat("\nDataset:", ds, "\n")
  X <- read.csv(paste0("/accounts/grad/aqwang/unilasso/datasets_12/", ds, "/X.csv"))
  y <- read.csv(paste0("/accounts/grad/aqwang/unilasso/datasets_12/", ds, "/y.csv"))

  
  # split into training and test set
  set.seed(123)
  n <- nrow(X)
  train_indices <- sample(1:n, size = round(0.5 * n), replace = FALSE)
  Xtr <- X[train_indices, ]
  ytr <- y[train_indices, ]
  Xte <- X[-train_indices, ]
  yte <- y[-train_indices, ]
  
  # check for counter example pattern in training set
  res <- diagnose_counterexample_ols(Xtr, ytr, cor_cut = 0.8)
  # store results in a named list for later inspection
  if (!exists("counterexample_results")) counterexample_results <- list()
  counterexample_results[[ds]] <- res
  print(res)
}

```

```{R}
# for all datasets in dataset_12 folder, plot the histogram of correlation distribution 
dataset_names <- c(
  "ca_housing", "computer",
  "debutanizer", "diamond", "elevator", "energy_efficiency",
  "insurance", "kin8nm", "miami_housing", "naval_propulsion",
 "protein_structure", "qsar")

 # Set up the plotting grid
par(mfrow = c(3, 4), mar = c(4, 4, 3, 1))
for (ds in dataset_names) {
  cat("\nDataset:", ds, "\n")
  X <- read.csv(paste0("/accounts/grad/aqwang/unilasso/datasets_12/", ds, "/X.csv"))
  
  # Compute correlation matrix
  cor_matrix <- cor(X)
  # Extract upper triangle without diagonal
  cor_values <- cor_matrix[upper.tri(cor_matrix)]
  
  # Create histogram and capture the histogram object
  h <- hist(cor_values, 
            main = paste("Correlation Distribution -", ds),
            xlab = "Correlation", 
            ylab = "Frequency", 
            breaks = 30,
            cex.main = 0.9,    # Smaller title font
            cex.lab = 0.8,     # Smaller axis labels
            cex.axis = 0.7)    # Smaller axis text
  
  # Get min and max values
  min_cor <- min(cor_values, na.rm = TRUE)
  max_cor <- max(cor_values, na.rm = TRUE)
  
  # Create custom axis labels that include min and max
  axis_breaks <- pretty(cor_values, n = 5)
  axis_breaks <- unique(c(min_cor, axis_breaks, max_cor))
  axis_breaks <- sort(axis_breaks)
  
  # Add custom x-axis with min and max labeled
  axis(1, at = axis_breaks, 
       labels = round(axis_breaks, 3), 
       cex.axis = 0.7)
  
  # Add frequency labels on top of each bar
  text(h$mids, h$counts, labels = h$counts, adj = c(0.5, -0.1), cex = 0.6)
}


```



# look at diamond datasets withou one hot encoding:
```{R}
# treat the first column as index column and remove it
diamonds_ordinal <- read.csv("/accounts/grad/aqwang/unilasso/datasets_12/diamonds_ordinal.csv")
diamonds_ordinal <- diamonds_ordinal[ , -1]
# check the distinct values in clarity
sapply(diamonds_ordinal, function(x) length(unique(x)))
# check the max price of diamonds
max(diamonds_ordinal$price)
# convert cut, color, clarity to ordinal variables
diamonds_ordinal$cut <- as.numeric(factor(diamonds_ordinal$cut,
                                        levels = c("Fair", "Good", "Very Good", "Premium", "Ideal"),
                                        ordered = TRUE))
diamonds_ordinal$color <- as.numeric(factor(diamonds_ordinal$color,
                                          levels = c("J", "I", "H", "G", "F", "E", "D"),
                                          ordered = TRUE))
diamonds_ordinal$clarity <- as.numeric(factor(diamonds_ordinal$clarity,
                                            levels = c("I1", "SI2", "SI1", "VS2", "VS1", "VVS2", "VVS1", "IF"),
                                            ordered = TRUE))
X <- diamonds_ordinal[, -which(names(diamonds_ordinal) == "price")]
y <- diamonds_ordinal[,price]

# split into training and test set
set.seed(123)
n <- nrow(X)
train_indices <- sample(1:n, size = round(0.5 * n), replace = FALSE)
Xtr <- X[train_indices, ]
ytr <- y[train_indices]
Xte <- X[-train_indices, ]
yte <- y[-train_indices]

# fit unilasso with loo=TRUE
library(uniLasso)
set.seed(123)  # Consistent folds within split, but different across splits
K <- 10
n <- nrow(Xtr)
foldid <- sample(rep(1:K, length.out = n))  
unilasso_cv <- cv.uniLasso(
        Xtr, ytr,
        family = "gaussian",
        loo = TRUE,
        lower.limits = 0,
        standardize = FALSE,
        foldid = foldid,
        nlambda = 100
      )

# the names of the features that has coefficient nonzero
unilasso_selected <- colnames(Xtr)[which(coef(unilasso_cv, s = "lambda.min")[-1] != 0)]
print(unilasso_selected)
# find the MSE
yte_pred_CV <- predict(unilasso_cv, newx = as.matrix(Xte), s = "lambda.min")
unilasso_mse <- mean((yte - yte_pred_CV)^2)
unilasso_mse

###unilasso-nosign
unilasso_nosign <- cv.uniLasso(
        Xtr, ytr,
        family = "gaussian",
        loo = TRUE,
        lower.limits = -Inf,
        standardize = FALSE,
        foldid = foldid,
        nlambda = 100
      )

# the names of the features that has coefficient nonzero
unilasso_selected_nosign <- colnames(Xtr)[which(coef(unilasso_nosign, s = "lambda.min")[-1] != 0)]
# print the coefficients
print(unilasso_selected_nosign)


# also fit a lasso model for comparison
library(glmnet)
set.seed(123)
lasso_cv <- cv.glmnet(as.matrix(Xtr), ytr, alpha = 1, foldid = foldid, standardize = TRUE)
lasso_selected <- colnames(Xtr)[which(coef(lasso_cv, s = "lambda.min")[-1] != 0)]
print(lasso_selected)
# find the MSE
lasso_pred <- predict(lasso_cv, newx = as.matrix(Xte), s = "lambda.min")
lasso_mse <- mean((yte - lasso_pred)^2)
lasso_mse
# support size and MSE
lasso_support <- sum(coef(lasso_cv, s = "lambda.min") != 0) - 1  # minus 1 to exclude intercept
#name of features that has coefficient nonzero
rownames(coef(lasso_cv, s = "lambda.min"))[which(coef(lasso_cv, s = "lambda.min")[-1] != 0)]



```
# when violations are features that selected by uniLasso
```{R}
diagnose_counterexample_ols <- function(X, y, cor_cut = 0.6) {
  X <- as.matrix(X); y <- as.numeric(y)

  ## 1) Univariate signs (OLS, one variable at a time)
  s_uni <- apply(X, 2, function(x) {
    b <- coef(lm(y ~ x))[[2]]
    sign(b)
  })

  ## 2) Multivariate signs (OLS on all variables)
  # Use lm(y ~ ., data = as.data.frame(X)) for multivariate OLS
  ols <- lm(y ~ ., data = as.data.frame(X))
  beta <- coef(ols)[-1]  # drop intercept
  aliased <- is.na(beta) # NA => not estimable (rank deficiency)
  if (any(aliased)) {
    message("OLS is rank-deficient for these columns: ",
            paste(names(beta)[aliased], collapse = ", "))
    beta[aliased] <- 0   # treat as not selected
  }
  s_multi <- sign(beta); names(s_multi) <- names(beta)

  ## 3) Violations: univariate vs multivariate sign mismatch on selected vars
  viol <- names(which(s_multi != 0 & s_uni[names(s_multi)] != s_multi))

  ## 4) Get UniLasso selected features
  tryCatch({
    # Set up CV folds (same approach as your main analysis)
    set.seed(42)
    K <- 10
    n <- nrow(X)
    foldid <- sample(rep(1:K, length.out = n))
    
    unilasso_cv <- cv.uniLasso(
      X, y,
      family = "gaussian",
      loo = TRUE,
      lower.limits = 0,
      standardize = FALSE,
      foldid = foldid,
      nlambda = 100
    )
    
    beta_unilasso <- coef(unilasso_cv, s = "lambda.min")[-1]  # exclude intercept
    unilasso_selected <- colnames(X)[which(beta_unilasso != 0)]
    
  }, error = function(e) {
    message("UniLasso failed: ", e$message)
    unilasso_selected <<- character(0)
  })

  ## 5) Find violations that overlap with UniLasso selected features
  viol_unilasso_overlap <- intersect(viol, unilasso_selected)

  ## 6) Look for positively correlated, opposite-sign partners (counter-example pattern)
  R <- cor(X)
  pairs <- list()  
  for (j in viol) {
    opp <- names(which(s_multi * s_multi[j] < 0))   # opposite multivariate sign
    if (length(opp)) {
      cand <- opp[R[j, opp, drop = FALSE] > cor_cut & !is.na(R[j, opp, drop = FALSE])]
      if (length(cand)) {
        k <- cand[which.max(R[j, cand])]
        
        pairs[[j]] <- list(
          partner       = k,
          rho           = R[j, k],
          sign_uni_j    = s_uni[j],
          sign_multi_j  = s_multi[j],
          sign_multi_k  = s_multi[k],
          unilasso_selected_j = j %in% unilasso_selected,  # NEW: is j selected by UniLasso?
          unilasso_selected_k = k %in% unilasso_selected   # NEW: is k selected by UniLasso?
        )
      }
    }
  }

  list(
    violations = viol,
    violations_unilasso_overlap = viol_unilasso_overlap,  # NEW: violations that overlap with UniLasso
    evidence = pairs,
    s_uni = s_uni,
    s_multi = s_multi,
    unilasso_selected = unilasso_selected,  # NEW: features selected by UniLasso
    aliased = names(which(aliased))
  )
}

for (ds in dataset_names) {
  cat("\nDataset:", ds, "\n")
  X <- read.csv(paste0("/accounts/grad/aqwang/unilasso/datasets_12/", ds, "/X.csv"))
  y <- read.csv(paste0("/accounts/grad/aqwang/unilasso/datasets_12/", ds, "/y.csv"))

  
  # split into training and test set
  set.seed(123)
  n <- nrow(X)
  train_indices <- sample(1:n, size = round(0.5 * n), replace = FALSE)
  Xtr <- X[train_indices, ]
  ytr <- y[train_indices, ]
  Xte <- X[-train_indices, ]
  yte <- y[-train_indices, ]
  
  # check for counter example pattern in training set
  res <- diagnose_counterexample_ols(Xtr, ytr, cor_cut = 0.8)
  # store results in a named list for later inspection
  if (!exists("counterexample_results")) counterexample_results <- list()
  counterexample_results[[ds]] <- res
  print(res)
}
```



# process 22 datasets from unilasso. Run the below two chunks to process the 22 datasets from the uniLasso paper. Now it's all done.
```{r}
# load data22fromUnilasso.Rdata
load("/accounts/grad/aqwang/unilasso/analysis/22finaldatasets_unilasso_paper.Rdata")

#unpack finaldatasets list and save each as a csv file
#CHECK THE first datasets in finaldatasets list
finaldatasets[[1]]
# check if any of the datasets in the finaldasets list has missing values
for (i in seq_along(finaldatasets)) {
  cat("\nDataset", i, "\n")
  
  # check X
  X <- finaldatasets[[i]]$x
  y <- finaldatasets[[i]]$y
  
  # total missing counts
  cat("Missing in X:", sum(is.na(X)), "\n")
  cat("Missing in y:", sum(is.na(y)), "\n")
  cat("Dimensions of X:", dim(X), "\n")
  cat("Length of y:", dim(y), "\n")
  
  # if you want dataset-level details:
  if (sum(is.na(X)) > 0) {
    cat("Columns in X with NAs:\n")
    print(colSums(is.na(X)))
  }
  #if (sum(is.na(y)) > 0) {
   # cat("Positions in y with NAs:\n")
    #print(which(is.na(y)))
  #}
}

datanames2 <- c(
  "Auto MPG",
  "Automobile",
  "Liver Disorders",
  "Servo",
  "Forest Fires",
  "Concrete Compressive Strength",
  "Communities and Crime",
  "Parkinsons Telemonitoring",
  "Communities and Crime Unnormalized",
  "Bike Sharing",
  "Airfoil Self-Noise",
  "Combined Cycle Power Plant",
  "Facebook Metrics",
  "Appliances Energy Prediction",
  "Beijing PM2.5",
  "Stock Portfolio Performance",
  "Daily Demand Forecasting Orders",
  "Superconductivity Data",
  "Real Estate Valuation",
  "Metro Interstate Traffic Volume",
  "Power Consumption of Tetouan City",
  "Infrared Thermography Temperature"
)

# assign each of the name in datanames2 to each dataset in finaldatasets list
for (i in seq_along(finaldatasets)) {
  finaldatasets[[i]]$name <- datanames2[i]
}

# For datasets with more than one column in y dataframe, create separate datasets for each column in y
original_length <- length(finaldatasets)
new_datasets <- list()

for (i in 1:original_length) {
  y <- finaldatasets[[i]]$y
  
  # Check if y is a data.frame with multiple columns
  if (is.data.frame(y) && ncol(y) > 1) {
    cat("\nDataset", i, "(", datanames2[i], ") has", ncol(y), "y columns - separating...\n")
    
    # Keep the first column as the original dataset
    finaldatasets[[i]]$y <- y[, 1, drop = FALSE]
    
    # Create new datasets for columns 2, 3, etc.
    for (j in 2:ncol(y)) {
      new_dataset <- list(
        x = finaldatasets[[i]]$x,  # Copy the same X
        y = y[, j, drop = FALSE],  # Select the j-th column of y
        name = paste0(datanames2[i], " (Target ", j, ")")  # Modified name
      )
      new_datasets <- append(new_datasets, list(new_dataset))
      cat("  Created new dataset:", new_dataset$name, "\n")
    }
  }
}

# Append the new datasets to finaldatasets
finaldatasets <- c(finaldatasets, new_datasets)

# Update datanames2 to include the new dataset names
for (i in (original_length + 1):length(finaldatasets)) {
  datanames2 <- c(datanames2, finaldatasets[[i]]$name)
}

# Print summary of all datasets
cat("\nFinal dataset summary:\n")
for (i in seq_along(finaldatasets)) {
  name <- finaldatasets[[i]]$name
  X <- finaldatasets[[i]]$x
  y <- finaldatasets[[i]]$y
  
  cat("Dataset", i, ":", datanames2[i], "\n")
  cat("  X dimensions:", dim(X), "\n")
  cat("  y dimensions:", dim(y), "\n")
  cat("  Missing in X:", sum(is.na(X)), "\n")
  cat("  Missing in y:", sum(is.na(y)), "\n\n")
}

cat("Total datasets after separation:", length(finaldatasets), "\n")


# for each dataset in finaldatasets list, check if there is any missing values in y. if so, remove the rows with missing values in y from both X and y
for (i in seq_along(finaldatasets)) {
  name <- finaldatasets[[i]]$name
  y <- finaldatasets[[i]]$y
  X <- finaldatasets[[i]]$x 
  if (sum(is.na(y)) > 0) {
    cat("\nDataset", i, "(", name, ") has", sum(is.na(y)), "missing values in y - removing rows...\n")
    
    # Identify rows with missing y
    missing_rows <- which(is.na(y))
    
    # Remove these rows from both X and y
    finaldatasets[[i]]$y <- y[-missing_rows, , drop = FALSE]
    finaldatasets[[i]]$x <- X[-missing_rows, , drop = FALSE]
    
    cat("  Removed", length(missing_rows), "rows. New dimensions - X:", dim(finaldatasets[[i]]$x), ", y:", dim(finaldatasets[[i]]$y), "\n")
  }
}

# check the dimensions of each dataset in finaldatasets list again and missing values in y
cat("\nFinal dataset dimensions after removing missing y rows:\n")
for (i in seq_along(finaldatasets)) {
  name <- finaldatasets[[i]]$name
  X <- finaldatasets[[i]]$x
  y <- finaldatasets[[i]]$y
  cat("Dataset", i, ":", name, "\n")
  cat("  X dimensions:", dim(X), "\n")
  cat("  y dimensions:", dim(y), "\n\n")  
  cat("Missing in X:", sum(is.na(X)), "\n")
  cat("Missing in y:", sum(is.na(y)), "\n\n")
}

#for each name in finaldatasets list (finaldatasets[[i]]$name), replace spaces with underscores and make all lowercase, maybe write a loop
datanames2 <- tolower(gsub(" ", "_", datanames2))
print(datanames2)

# replace each name in finaldatasets list with the corresponding name in datanames2
for (i in seq_along(finaldatasets)) {
  finaldatasets[[i]]$name <- datanames2[i]
}
```


```{r}
# save each dataset in finaldatasets list to be in a folder in /accounts/grad/aqwang/unilasso/datasets_22, and name the folder as datanames2
for (i in seq_along(finaldatasets)) {
  name <- finaldatasets[[i]]$name
  X <- finaldatasets[[i]]$x
  y <- finaldatasets[[i]]$y
  
  # Create directory if it doesn't exist
  dir_path <- file.path("/accounts/grad/aqwang/unilasso/datasets_22", name)
  if (!dir.exists(dir_path)) {
    dir.create(dir_path, recursive = TRUE)
  }
  
  # Save X and y as CSV files
  write.csv(X, file = file.path(dir_path, "X.csv"), row.names = FALSE)
  write.csv(y, file = file.path(dir_path, "y.csv"), row.names = FALSE)
  
  cat("Saved dataset", i, "as", dir_path, "\n")
}


```

# process y in some datasets. already done below, no need to run it again 
```{r}
# convert y in stock_portfolio_perfromance, .._target_2,4,5,6, from percentge to decimal
# stock_portfolio_performance (target is in percentage, convert to decimal)
stock_path <- "/accounts/grad/aqwang/unilasso/datasets_22/stock_portfolio_performance"
y_stock <- read.csv(file.path(stock_path, "y.csv"))
# each row has number%
# remove % sign and convert to numeric
y_stock <- as.numeric(gsub("%", "", y_stock[,1]))
# convert to decimal
y_stock <- y_stock / 100
write.csv(data.frame(y = y_stock), file.path(stock_path, "y.csv"), row.names = FALSE)

# stock_portfolio_performance_(target_2)
stock2_path <- "/accounts/grad/aqwang/unilasso/datasets_22/stock_portfolio_performance_(target_2)"
y_stock2 <- read.csv(file.path(stock2_path, "y.csv"))
# each row has number%
# remove % sign and convert to numeric
y_stock2 <- as.numeric(gsub("%", "", y_stock2[,1]))
# convert to decimal
y_stock2 <- y_stock2 / 100
write.csv(data.frame(y = y_stock2), file.path(stock2_path, "y.csv"), row.names = FALSE)

# stock_portfolio_performance_(target_4)
stock4_path <- "/accounts/grad/aqwang/unilasso/datasets_22/stock_portfolio_performance_(target_4)"
y_stock4 <- read.csv(file.path(stock4_path, "y.csv"))
# each row has number%  
# remove % sign and convert to numeric
y_stock4 <- as.numeric(gsub("%", "", y_stock4[,1]))
# convert to decimal
y_stock4 <- y_stock4 / 100
write.csv(data.frame(y = y_stock4), file.path(stock4_path, "y.csv"), row.names = FALSE)
# stock_portfolio_performance_(target_5)
stock5_path <- "/accounts/grad/aqwang/unilasso/datasets_22/stock_portfolio_performance_(target_5)"
y_stock5 <- read.csv(file.path(stock5_path, "y.csv"))
# each row has number%  
# remove % sign and convert to numeric
y_stock5 <- as.numeric(gsub("%", "", y_stock5[,1])) 
# convert to decimal
y_stock5 <- y_stock5 / 100
write.csv(data.frame(y = y_stock5), file.path(stock5_path, "y.csv"), row.names = FALSE)
# stock_portfolio_performance_(target_6)
stock6_path <- "/accounts/grad/aqwang/unilasso/datasets_22/stock_portfolio_performance_(target_6)"
y_stock6 <- read.csv(file.path(stock6_path, "y.csv"))
# each row has number%  
# remove % sign and convert to numeric
y_stock6 <- as.numeric(gsub("%", "", y_stock6[,1]))
# convert to decimal
y_stock6 <- y_stock6 / 100
write.csv(data.frame(y = y_stock6), file.path(stock6_path, "y.csv"), row.names = FALSE)
```